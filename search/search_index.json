{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"CivRealm: A Learning and Reasoning Odyssey in Civilization for Decision-Making Agents","text":"<p>CivRealm is an interactive environment for the open-source strategy game Freeciv-web based on Freeciv, a Civilization-inspired game. Within CivRealm, we provide interfaces for two typical agent types: tensor-based reinforcement learning agents based on the Gymnasium API, and language-based agents powered by language models.</p> <p>Example</p> Getting Started <p>New to Civrealm? Start with our Beginner's Guide. This guide offers an overview of CivRealm's core concepts and provides links to further tutorials.</p> To the beginner Advanced Materials <p>The advanced materials offer comprehensive insights into Civrealm's essential concepts, complemented by valuable background details.</p> To the old hand API Reference <p>The reference guide provides an in-depth explanation of the functions and objects incorporated within Civrealm. It elaborates on the function APIs.</p> To the reference Releases <p>The official versions of CivRealm, along with their associated dependencies and downstream repositories.</p> Align your version Contribute <p>How to Contribute to CivRealm: This guide will help you create or customize the environment. </p> Contribute to CivRealm FAQ &amp; Resources <p>If you have any further questions, the FAQ page and resources may assist you.        </p> Find your answer <p>We also provide a set of tools for training and evaluating agents, as well as a set of baselines for both agent types. We hope that CivRealm can serve as a testbed for developing and evaluating agents that can learn and reason in complex environments.</p>"},{"location":"advanced_materials/architecture.html","title":"System Architecture","text":"<p>The following figure shows the communication process between CivRealm and Freeciv.</p> <pre><code>sequenceDiagram\n    Freeciv -&gt;&gt; Freeciv : metaserver.build()\n    Freeciv-Web --&gt;&gt; Freeciv-Web : webserver.build()\n    alt Docker Image Existed\n        Freeciv-Web-&gt;&gt;Freeciv-Web: docker load -i $image\n        Freeciv-Web -&gt;&gt; CivRealm : read docker config\n        CivRealm -&gt;&gt; Freeciv-Web : docker compose up -d\n    else Docker Image Not Existed\n        Freeciv-Web -&gt;&gt; CivRealm : copy docker config\n        Freeciv-Web -&gt;&gt; Freeciv-Web: docker compose up -d\n    end\n    Freeciv-Web -&gt;&gt; + Freeciv : send setting message\n    Freeciv -&gt;&gt; - Freeciv-Web : recieve setting response\n    opt set agent\n        Note over CivRealm : Civrealm-tensor-baseline\n        Note over CivRealm : Civrealm-llm-baseline\n    end\n    CivRealm -&gt;&gt; CivRealm : agent.init()\n    opt set minigame\n        Note over CivRealm : CivRealm-sav: load_minigame()\n    end\n    CivRealm --&gt;&gt; CivRealm : env.reset()\n        CivRealm -&gt;&gt; + Freeciv : send metaserver setting message\n        Freeciv -&gt;&gt;  CivRealm : receive metaserver setting message\n        Freeciv -&gt;&gt; - Freeciv-Web : receive metaserver setting message\n        CivRealm -&gt;&gt; + Freeciv-Web : post webserver setting message\n        Freeciv-Web -&gt;&gt; - CivRealm : recieve webserver setting response\n        CivRealm -&gt;&gt; + Freeciv-Web : request to get webserver status\n        Freeciv-Web -&gt;&gt; - CivRealm : recieve webserver status\n    loop not done\n        CivRealm -&gt;&gt; CivRealm : agent.act()\n        CivRealm --&gt;&gt; CivRealm : env.step()\n        CivRealm -&gt;&gt; + Freeciv : send pid package contained actions\n        Freeciv -&gt;&gt;   CivRealm : receive raw observation and info\n        Freeciv -&gt;&gt; - Freeciv-Web : receive action commands\n    end\n    CivRealm -&gt;&gt; CivRealm : env.close()\n</code></pre>"},{"location":"advanced_materials/architecture.html#freecivfreeciv-web-workflow-architecture","title":"Freeciv&amp;Freeciv-web Workflow Architecture","text":"<p>The following figure shows the development workflow between Freeciv and Freeciv-web.</p>"},{"location":"advanced_materials/fullgame_action.html","title":"Action Details","text":""},{"location":"advanced_materials/fullgame_action.html#actions","title":"Actions","text":"<p>In every step, an agent receives an observation and takes action in response to the observation. The agent can use any decision-making algorithm to make the choice of the action as long as the format of the action conforms with the prescribed format. In the base environment of Civrealm, an action is a tuple consisting of the type of actor, the index of the actor, and the name of the action, respectively. The type of actor specifies which type of actor the agent wants to control in this step. This type could be:</p> <ul> <li><code>unit</code> - The 'unit' actor handles many fine-grained operations. They can be categorized into three main types: engineering actions, which handle tasks like city construction, planting, mining, and more; movement actions, including moving, transportation, embarking, and so on; and military actions, such as attacking, fortifying, bribing, etc.</li> <li><code>city</code> - The 'city' actor develops and manages cities. Their actions include unit production, building construction, city worker assignment, and more. </li> <li><code>dipl</code> - The 'dipl' actor is in charge of diplomacy actions including trading technologies, negotiating ceasefires, forming alliances, etc.</li> <li><code>gov</code> - The 'gov' actor allows the agent to change the government type to gain corresponding political benefits, adjust tax rates to balance economic expansion and citizen happiness, etc. </li> <li><code>tech</code> - The 'tech' actor sets immediate or long-term goals for their technology research.</li> </ul> <p>The index of the actor specifies which actor of the specified type the agent wants to control. The name of the action denotes the specific action the agent requires the specified actor to take. For instance, if the agent wants to let a unit whose index is 111 plant trees, the action will be of the format <code>('unit', 111, 'plant')</code>. </p> <p>Note</p> <p>The observations returned by the environment include the indexes of the actors who can take actions in this step and the names of their actions that are allowed to be taken in the current state.</p> <p>For more details about the actions that each type of actor can take, please refer to the following tables.</p>"},{"location":"advanced_materials/fullgame_action.html#unit-actions","title":"Unit Actions","text":"Action Class Action Description Parameter ActGoto Go to a target tile the target tile ActHutEnter Enter a hut in the target tile for random events ActEmbark Embark on a target boat mooring in an ocean tile the target boat unit ActDisembark Disembark from a target boat mooring in an ocean tile ActUnloadUnit Unload all units carried by the transporter unit - ActBoard Board a boat mooring in the city of the current tile ActDeboard Deboard a boat mooring in the city of the current tile ActFortify Fortify in the current tile ActAttack Attack the unit in a target tile the target tile ActSpyBribeUnit Bribe a unit of other players to join us the target unit ActConquerCity Conquer a city belongs to other players the target city ActSpySabotageCity Sabotage a city belongs to other players ActSpyStealTech Steal technology from a city belongs to other players ActMine Mine in the current tile - ActIrrigation Irrigate in the current tile ActBuildRoad Build road in the current tile ActBuildRailRoad Build railroad in the current tile ActPlant Plant trees in the current tile ActBuildCity Build a city in the current tile ActAirbase Build airbase in the current tile ActFortress Build fortress in the current tile ActTransform Transform the terrain of the current tile ActPillage Pillage an infrastructure in the current tile ActCultivate Cultivate the forest in the current tile into a plain ActUpgrade Upgrade the unit ActDisband Disband the unit itself to save cost ActKeepActivity Keep the current activity in this turn ActHomecity Set the unit's home city as the city in the current tile ActJoinCity Join the city in the current tile (increase city population) ActMarketplace Sell goods in the target city's marketplace the target city ActInvestigateSpend Investigate a target city belongs to other players ActEmbassyStay Establish embassy in a target city belongs to other players ActTradeRoute Establish a trade route from the unit's home city to the target city"},{"location":"advanced_materials/fullgame_action.html#city-actions","title":"City Actions","text":"Action Class Action Description Parameter CityWorkTile Choose a working tile for city the target tile CityUnworkTile Do not work on a tile CityBuyProduction Buy building or unit - CityChangeSpecialist Change the type of a specialist type of the target specialist CitySellImprovement Sell a building the target building CityChangeImprovementProduction Construct a building CityChangeUnitProduction Produce a unit the target unit"},{"location":"advanced_materials/fullgame_action.html#diplomacy-actions","title":"Diplomacy Actions","text":"Action Class Action Description Parameter StartNegotiate Start a negotiation target player ID StopNegotiate End a negotiation AcceptTreaty Accept treaties CancelTreaty Cancel a treaty CancelVision Cancel sharing vision AddClause Add a basic clause target player ID + target basic clause type AddTradeTechClause Add a trading tech clause target player ID + giver ID + target technology ID AddTradeGoldClause Add a trading gold clause target player ID + giver ID + how much gold AddTradeCityClause Add a trading city clause target player ID + giver ID + target city ID RemoveClause Remove a clause target player ID + parameters of the target clause"},{"location":"advanced_materials/fullgame_action.html#government-actions","title":"Government Actions","text":"Action Class Action Description Parameter ChangeGovernment Revolution the target Government ID SetSciLuxTax Set rates of tax + science + luxury rates of tax + science + luxury"},{"location":"advanced_materials/fullgame_action.html#technology-actions","title":"Technology Actions","text":"Action Class Action Description Parameter ActChooseResearchTech Set a current research goal the target technology ID ActChooseResearchGoal Set a future research goal the target technology ID"},{"location":"advanced_materials/fullgame_description.html","title":"Full-Game Characteristics","text":"<p>In the full-game, each player acts as a civilization leader. The objective of players is to guide their civilization from its humble beginnings to the greatest civilization. Civilizations evolve through eras from the Bronze Age to the Space Age and the number of controllable objects (units, cities, diplomatic relations, etc.) explodes as the game progresses. In addition, each decision made typically carries a multi-faceted impact, encompassing both long-term strategic consequences and short-term tactical outcomes. It is worth noting that a favorable tactical outcome may not necessarily translate into a positive strategic outcome. For instance, the immediate construction of a city at the beginning of the game can yield greater resources in the early stages (a tactical advantage). In contrast, settling in a resource-rich area after thorough exploration may result in substantial resource accumulation over the long haul (a strategic advantage). </p> <p>Besides the long decision-making horizon, multi-faceted decision impacts, and huge state-action spaces, the full-game exhibits additional characteristics that elevate its complexity: </p> <p>Imperfect info. Players typically only gain the information discovered by their own units and cities, resulting in partially observable states. Players may also obtain others\u2019 vision by diplomatic actions.</p> <p>Stochastic. The dynamics of the environment is stochastic. Moreover, there exist random events and crises that can disrupt plans, forcing players to adapt on the fly and make tough decisions. </p> <p>Multi-goal. There are multiple victory paths, i.e., (1) military: conquering all other civilizations; (2) science: being the first civilization that launches a spacecraft destined for Alpha Centauri; and (3) time: obtaining the highest score, computed based on criteria such as civilization size, wealth, cultural accomplishments, and scientific advancements, before reaching a predetermined number of turns, in case the first two conditions are not met. These paths necessitate a delicate balance between economic expansion, military development, diplomatic influence, cultural achievements, and technological research, which poses a high requirement for learning and reasoning. </p> <p>Dynamic space. As the game unfolds, players continuously produce new units, construct additional cities, engage in battles, and conquer other players. Consequently, the state and action space of a player undergo dynamic changes throughout the gameplay. Designing an effective decision model for the agent to adapt to this evolving space presents a significant challenge. </p> <p>Multi-agent. Multiple players can interact with one another, including hand-crafted AI players provided by Freeciv on the server side. CivRealm allows multiple agents to connect to the same game simultaneously, facilitating self-play training. </p> <p>General-sum. Players are free to form alliances or wage war against others, rendering the full game a general-sum game that necessitates considerations of both cooperative and competitive strategies. </p> <p>Changing players. The number of players can fluctuate during a game due to factors like revolts or civilization conquests, introducing new players controlled by built-in AI or removing existing ones. Such changes often result in significant alterations to the state-action space. </p> <p>Communication. Players can communicate explicitly using two types of communication: diplomatic actions (e.g., adding a clause) and natural language chat through a chat box. This feature enriches player interactions and enables LLM agents to fully leverage their natural language processing capabilities.</p> <p>To implement an agent that plays the full-game, it is important to understand the content of the observations returned by the environment and the format of the actions required by the environment. Please check Observations and Actions for more details.</p>"},{"location":"advanced_materials/fullgame_observation.html","title":"Observation Details","text":"<p>During the initialization of the environment:</p> <p><pre><code>observations, info = env.reset(client_port=fc_args['client_port'])\n</code></pre> and every step of the game:</p> <p><pre><code>observations, reward, terminated, truncated, info = env.step(action)\n</code></pre> The environment provides essential information about the game state, with the most crucial details being <code>observations</code> and <code>info</code>.</p>"},{"location":"advanced_materials/fullgame_observation.html#info","title":"Info","text":"<p>The <code>info</code> returned includes details about the current turn of the game and the actions available to the agent at this step. The dictionary \"info['available_actions']\" encompasses keys such as 'unit', 'city', 'dipl', 'gov', and 'tech', signifying the types of actors the agent can control. Within each actor type, sub-dictionaries exist, where the keys represent possible actions for the respective actor type, and the values are boolean indicators of action availability. Using this information, the agent can make informed decisions by selecting appropriate actions from the available set.</p>"},{"location":"advanced_materials/fullgame_observation.html#observations","title":"Observations","text":"<p>The <code>observations</code> returned reflects the game state in the current time step. It is a dictionary whose keys correspond to different aspects of the decision-making in the game. The keys of <code>observations</code> useful for training include:</p> <ul> <li><code>map</code> - Overview on the map, i.e., status (known, visible, etc.), terrain types and potential extras.</li> <li><code>unit</code> - Overview of the status (health, activity, moves left, etc.) of units. Using this key on observation (i.e., observations['unit']) will retrieve a dictionary whose keys are the indexes of units, and the content under each unit index is the status of the corresponding unit.</li> <li><code>city</code> - Overview of the status of cities (improvements, production, etc.). Using this key on observation (i.e., observations['city']) will retrieve a dictionary whose keys are the indexes of cities, and the content under each city index is the status of the corresponding city.</li> <li><code>player</code> - Overview of the status of players. Using this key on observation (i.e., observations['player']) will retrieve a dictionary whose keys are the indexes of players, and the content under each player index is the status of the corresponding player. The status of each player conveys information about multiple aspects, including diplomacy, government, and technology.</li> </ul> <p>For additional details regarding the observations, kindly consult the tables provided below. It's important to note that information pertaining to diplomacy, government, and technology within the observations' 'player' data is described separately.</p> <p>Note</p> <p>There exist other keys besides the above keys. However, the information under those keys is irrelevant to training, so we do not describe them here.</p>"},{"location":"advanced_materials/fullgame_observation.html#observations-of-map","title":"Observations of Map","text":"Fields Attributes Value domains Descriptions Basic map Status [0, 2] Size: M * N Type of terrain [0, 13] Owner of tiles [0, 255] Infrastructures 0 or 1 34 layers of size M * N Output 6 layers of size M * N for 6 output types Units and city on each tile Unit owner [0, 255] Size: M * N City owner Unit distribution 52 layers of size M * N for 52 unit types"},{"location":"advanced_materials/fullgame_observation.html#observations-of-unit","title":"Observations of Unit","text":"Fields Attributes Value domains Descriptions Common unit field X [0, M] X-coordinate Y [0, N] Y-coordinate Owner [0, 255] Player the unit belongs to HP [0, 65535] Health point of the unit Produce cost Cost needed to produce this type of unit Veteran 0 or 1 Whether the unit is veteran Can transport Whether the unit can transport other units Unit type [0, 51] One of 52 unit types Obsoleted by The unit type this unit can upgrade to Attack strength [0, 65535] Affect the attack success rate Defense strength Firepower The damage of a successful attack My unit field Unit ID [0, 32767] The ID of the unit Moves left Actions the unit can take in this turn Home city City that supports this unit Upkeep shield Resources needed to support this unit Upkeep gold Upkeep food"},{"location":"advanced_materials/fullgame_observation.html#observations-of-city","title":"Observations of City","text":"General Attributes Value domains Descriptions Common city field City name text The name of city X [0, M] X-Coordinate Y [0, N] Y-Coordinate Owner [0, 255] Player this city belongs to Size The size of this city My city field City ID [0, 32767] The ID of the city Food stock The food stock of the city Shield stock The shield stock of the city Granary size The granary size of the city Buy cost Cost to buy the undergoing production Turns to complete Number of turns to finish the current production Luxury Resource outputs in each turn Science Food Gold Shield Trade Bulbs City waste The waste of the city City corruption The corruption of the city City pollution The pollution of the city Growth in text Number of turns for city population to grow State [0, 2] City state: disorder, peace, etc. Production kind [0, 1] Unit or building Production value [0, 67] Unit or building type being produced People angry [0, 127] Number of people of each mood People unhappy People content People happy Surplus food [-32768, 32767] The surplus of the resource Surplus gold Surplus shield Surplus trade Can build unit 0 or 1 Binary vectors corresponding to units or buildings Can build building Having Buildings Last completion turn [0,32767] Turn Number when the city completed the last production"},{"location":"advanced_materials/fullgame_observation.html#observations-of-diplomacy","title":"Observations of Diplomacy","text":"General Attributes Values Descriptions Common player field Player ID [0, 255]  The ID of player Team  The ID of team Name text The name of the player Is alive 0 or 1  Whether the player is alive or not Score [0, 65535] The score of the player Turns alive How many turns the player has lived for Nation [0, 559] The nation of the player Embassy text text Describe if there are embassies between players Love Describe players\u2019 attitudes to others My player field Mood 0 or 1 Peaceful or Combat Diplomacy state [0, 6] A categorical vector of my diplomacy states with other players: armistice, war, ceasefire, etc."},{"location":"advanced_materials/fullgame_observation.html#observations-of-government","title":"Observations of Government","text":"General Attributes Values Descriptions Common government fields Government ID [0, 6] The ID of the government Government name text The name of the government My government fields Goal government [0, 6] The goal of revolution Gold [0, 65535] Gold in treasury Revolution finishes Number of turns for current revolution to complete Science [0, 100] Government investment for each aspect. Sum to 100. Tax Luxury"},{"location":"advanced_materials/fullgame_observation.html#observations-of-technology","title":"Observations of Technology","text":"General Attributes Values Descriptions Common technology fields Research name text The name of research Researching [0, 87] The technology being researched Tech of each type 0 or 1 If each technology has been researched My technology fields Bulbs researched [0, 65535] Accumulated technology bulbs Tech upkeep Cost to keep current technologies Science cost - Researching cost - Tech goal [0, 87] The long-term research goal Techs researched Last researched technology"},{"location":"advanced_materials/fullgame_usage.html","title":"Initialize a Full-Game","text":"<p>By default, an environment specified by <code>civrealm/FreecivBase-v0</code> will run the full-game.</p> <pre><code>from civrealm.agents import ControllerAgent\nimport gymnasium\n\nenv = gymnasium.make('civrealm/FreecivBase-v0')\nagent = ControllerAgent()\nobservations, info = env.reset(client_port=fc_args['client_port'])\ndone = False\nstep = 0\nwhile not done:\n    try:\n        action = agent.act(observations, info)\n        observations, reward, terminated, truncated, info = env.step(\n            action)\n        print(\n            f'Step: {step}, Turn: {info[\"turn\"]}, Reward: {reward}, Terminated: {terminated}, '\n            f'Truncated: {truncated}, action: {action}')\n        step += 1\n        done = terminated or truncated\n    except Exception as e:\n        fc_logger.error(repr(e))\n        raise e\nenv.close()\n</code></pre>"},{"location":"advanced_materials/game_settings.html","title":"Game Settings","text":"<p>The game setting is specified in the <code>default_settings.yaml</code> file under the civrealm folder. To overwrite a setting, you can do either of the following:</p> <ul> <li>Directly change the value in the <code>default_settings.yaml</code> file. Or</li> <li>Use the <code>--setting</code> argument. For example, to set the maximum number of turns to 5 for a quick test, you can use the following command:</li> </ul> <pre><code>test_civrealm --max_turns 5\n</code></pre> <p>The details of the game setting are as follows:</p>"},{"location":"advanced_materials/game_settings.html#basic-settings-for-game-play","title":"Basic Settings for Game Play","text":"Argument Default value Description username myagent The user name used to log in the game. Spaces and underscores are not allowed. max_turns 1000 The maximum number of turns per game. The game will end after the turn number reaches this limit. host localhost The URL that hosts the game. client_port 6001 The port to be connected by the client. Used in the single-thread mode. For parallel running, the client port is chosen from available ports. multiplayer_game True Whether to start a multiplayer game or single-player game. hotseat_game False Whether to use the hotseat mode in a single-player game. wait_for_observer False Whether to wait for an observer to join before starting the game. If set to True, the game will not start until a user observes the game through the browser. server_timeout 30 The duration in seconds before considering the server as timed out. In pytest, we automatically set it to be 5 in conftest.py. wait_for_timeout 10000 Sometimes we perform an invalid action and cannot receive the response to wait_for_packs. We wait for wait_for_timeout seconds and clear the wait_for_packs to prevent the process from sticking. begin_turn_timeout 30 Sometimes, the server is stuck for unknown reasons and will not return a begin_turn packet. We wait for begin_turn_timeout seconds before we close the environment. This configuration should be carefully set when playing with human or AI agents because they may take more than 60 seconds for each of their turns. In those cases, the server will send a begin_turn packet only after they finish their turns. pytest False Whether in pytest mode. In pytest, we automatically set it as True in conftest.py. score_window 10 The number of episode scores maintained in the ParallelTensorEnv. aifill 4 The number of AI players to be initialized when a game starts. maxplayers 10 The maximum number of players allowed to join a game. self_play True Whether to start multiple clients for self-play. When it is true, the following clients will add an increasing index to their username for login to the same game. Note that when running pytest, we automatically set this as False. By doing so, different tests connecting to the same port will raise an exception and force one test to re-select a random new port. minp 1 The minimum number of players needed for starting a game. allowtake HAhadOo Decides whether one can take control/observe a player. Please check the details of this setting in the Freeciv instruction. autotoggle disabled Whether to allow an AI to control a player when the previous player disconnects. endvictory enabled Whether to end the game when some players succeed under victory conditions. Options: enabled, disabled. victories SPACERACE|ALLIED Victory condition options: SPACERACE|ALLIED|CULTURE. If a certain victory condition is not set, the calculation logic for that victory condition will be skipped. openchatbox enabled Whether to open the chatbox in the web interface. Options: enabled, disabled. ruleset classic The ruleset to be used. runner_type parallel The type of runner."},{"location":"advanced_materials/game_settings.html#settings-for-parallel-running","title":"Settings for parallel running","text":"Argument Default value Description batch_size_run 5 Number of environments running simultaneously to sample experience. epoch_num 1 Number of epochs to run. Each epoch runs batch_size_run environments. port_start 6300 The port used by the first environment; other parallel environments use ports following this port."},{"location":"advanced_materials/game_settings.html#settings-for-debug","title":"Settings for debug","text":"Argument Default value Description record_action_and_observation False Records the game state and available actions at every step. Warning: generates many log files if True. Turned off by default. take_screenshot False Take screenshots during playing. wait_for_observer flag should be set to True if enabling screenshots. You can execute the 'update_javascript_for_clean_screenshot' command first for generating cleaner screenshots. Warning: generates many log files if True. Turned off by default. global_view_screenshot True Global view screenshot. sleep_time_after_turn 0.0 The sleep time after each turn. headless False The headless mode for the browser when take_screenshot is true. window_size_x null The window size (width) for screenshot. window_size_y null The window size (height) for screenshot. get_webpage_image null Get webpage image data by locating elements by ID on the web page. wait_for_observer flag should be set to 'True' if enabling screenshots. Options include, but are not limited to: ['cities_tab', 'tech_tab', 'players_tab', 'civ_tab', 'map_tab']. autosave True If true, auto save the game at the beginning of every turn. The save will be deleted at the end of that turn unless the program finds issues in that turn. interrupt_save False If true, will save the game when using KeyboardInterrupt. Note that when using this, autosave should be disabled. Otherwise, the game will be saved at the beginning of every turn and cannot be saved again when using KeyboardInterrupt. password civrealm Password used to log in to the Freeciv-web account. load_game The name of the saved game to be loaded. randomly_generate_seeds True Whether to use randomly generated seeds for running games. If True, the following random seeds (mapseed, gameseed, agentseed) are ignored. mapseed 88 The seed for generating a map. The same seed leads to the same map. gameseed 1729 The seed for fixing the behavior of random outputs. agentseed 1729 The seed for fixing the action sequence when the game/map is fixed. tensor_debug False Whether to print debug information for tensor env. logging_path null The path to the directory that stores the log files. Use null for the default path 'civrealm/logs'."},{"location":"advanced_materials/llm_agent.html","title":"LLM Agent","text":"<p>Welcome to Civrealm LLM Agent\uff01 This documentation will guide you through the process of building LLM agents in CivRealm Environment. We will first provide an overview of CivRealm LLM Env, followed by instruction on how to use the civrealm-llm-baseline repository to build llm agents Mastaba and BaseLang on this environment.</p>"},{"location":"advanced_materials/llm_agent.html#civrealm-llm-environment","title":"\ud83c\udf0f Civrealm LLM Environment","text":"<p>The Civrealm LLM Environment is a LLM environment wrapped upon Civrealm Base Env specifically designed for building LLM agents. This environment</p> <ul> <li>provides observations of each actor in natural language</li> <li>provides valid actions of each actor in natural language</li> <li>restricts valid actions in order to reduce meaningless actions</li> <li>executes actions described by natural language</li> </ul> <p>Besides, a LLM wrapper is open to customize your own environment.</p>"},{"location":"advanced_materials/llm_agent.html#quick-start","title":"Quick Start","text":"<p>Start a single FreecivLLM environment :</p> <pre><code>env = gymnasium.make('civrealm/FreecivLLM-v0')\nobs, info = env.reset(client_port=fc_args['client_port'])\n</code></pre> <p>Use LLM Wrapper to customize an environment :</p> <pre><code>env = gymnasium.make('civrealm/FreecivBase-v0')\nenv = LLMWrapper(env)\nobs, info = env.reset(client_port=fc_args['client_port'])\n</code></pre>"},{"location":"advanced_materials/llm_agent.html#llm-info","title":"LLM Info","text":"<p>Observations and actions in natural language are stored in llm_info as:</p> <pre><code>info[\"llm_info\"]\n</code></pre> <p>llm_info is a Dict consisting of 6 subspaces with keys \"player\", \"city\", tech\", \"unit\", \"dipl\", and \"gov\". Subspace of \"unit\" is a Dict with keys of unit_id, and subspace of \"city\" is a Dict with keys of city_id, describing \"name\", \"available_actions\", and local \"observations\" of the corresponding unit and city. Subspaces of \"player\", tech\", \"dipl\", and \"gov\" are currently empty, and will be completed in the future, meaning that LLM Env only support controlling units and cities by natural language at this stage.</p> <p>Read llm_info of \"unit 121\" by:</p> <pre><code>info[\"llm_info\"]['unit']['121']\n</code></pre> <p>Choose an existing unit or city</p> <p>You should read llm_info of an currently existing unit or city</p> <pre><code>unit_id = random.choice(info['llm_info']['unit'].keys())\ncity_id = random.choice(info['llm_info']['city'].keys())\n</code></pre>"},{"location":"advanced_materials/llm_agent.html#observation","title":"Observation","text":"<p>Read observations of \"unit 121\" by:  </p> <pre><code>info['llm_info']['unit']['121']['observations']\n</code></pre>"},{"location":"advanced_materials/llm_agent.html#action","title":"Action","text":"<p>Read valid action of \"unit 121\" by:</p> <pre><code>info['llm_info']['unit']['121']['available_actions']\n</code></pre>"},{"location":"advanced_materials/llm_agent.html#architecture-of-baselang-and-mastaba","title":"\ud83e\udd16 Architecture of BaseLang and Mastaba","text":""},{"location":"advanced_materials/llm_agent.html#baselang","title":"BaseLang","text":"<p>BaseLang consists of three components: observation, reasoning, and commands. For observation, a 5 * 5 tile-based observation is employed, centered on each unit's location, optimizing tactical information provision while accommodating strategic depth. The reasoning module mimics AutoGPT and outputs in three stages: thought, reasoning, and command. Commands empower the agent with the choice between \"manual and history search\" and \"final decision\" commands, enabling data retrieval from a vector database or selecting available actions to execute based on environmental and historical context. Finally, individual LLMs are assigned to each unit, with their context histories, to facilitate detailed planning. </p>"},{"location":"advanced_materials/llm_agent.html#mastaba","title":"Mastaba","text":"<p>To facilitate cooperation between independent entities, Mastaba introduces a hierarchical structure, organizing LLM workers, observations, and decision-making into a pyramid-like structure.</p> <p>LLM Workers.  Within Mastaba, LLM workers are structured as two layers. At the pinnacle is the \"advisor\", tasked with overseeing all other LLM workers. The advisor monitors the holistic nationwide perspective, including unit counts, city metrics, and enemy player information. At the operational level, Mastaba maintains LLM workers that resemble BaseLang's structure.</p> <p>Observation.  Mastaba adopts a pyramid-like map view, condensing data from a 15 * 15 tile region into 9 blocks, each spanning 5 * 5 tiles. This design enables entities to grasp information within a broader range while managing prompt loads effectively, thereby elevating map awareness.</p> <p>Decision-making.  Mastaba's decision-making workflow follows its agent structure. The advisor initiates each turn with a nationwide assessment, encompassing cities, units, and potential threats. It generates suggestions during each turn and communicates them to other LLM workers, who independently select actions for their entities. Additionally, workers possess the capability to query a vector database for knowledge, enabling informed decisions based on manual or stored experiences.</p>"},{"location":"advanced_materials/llm_agent.html#using-civrealm-llm-baseline-repository","title":"\ud83c\udfc3 Using civrealm-llm-baseline Repository","text":"<p>The civrelam-llm-baseline repository is a collection of code and utilities that provide a baseline implementation for building llm agents. It includes two agents: Mastaba and BaseLang, in the Civrealm LLM Environment.</p>"},{"location":"advanced_materials/llm_agent.html#getting-started","title":"\ud83c\udfcc\ufe0f Getting Started","text":"<p>To get started, follow these steps:</p> <ol> <li> <p>Clone the civrealm-llm-baseline repository from GitHub and enter the directory:</p> <pre><code>cd civrealm-llm-baseline\n</code></pre> </li> <li> <p>Set environment variables. The following groups are independent. Set only one group and use that group. OpenAI GPT is preferred.</p> <pre><code># Group 1\nexport OPENAI_API_TYPE=&lt;api-type&gt;                           # e.g. 'azure'\nexport OPENAI_API_VERSION='&lt;openai-api-version&gt;'\nexport OPENAI_API_BASE=&lt;openai-api-base&gt;                    # e.g. 'https://xxx.openai.azure.com'\nexport OPENAI_API_KEY=&lt;openai-api-key&gt;\nexport DEPLOYMENT_NAME=&lt;deployment-name&gt;                    # e.g. 'gpt-35-turbo-16k'\n</code></pre> <pre><code># Group 2\nexport AZURE_OPENAI_API_TYPE=&lt;azure-openai-api-type&gt;        # e.g. 'azure'\nexport AZURE_OPENAI_API_VERSION=&lt;azure-openai-api-version&gt;  # e.g. '2023-05-15'\nexport AZURE_OPENAI_API_BASE=&lt;azure-openai-api-base&gt;\nexport AZURE_OPENAI_API_KEY=&lt;azure-openai-api-key&gt;\n</code></pre> <pre><code># Group 3\nexport LOCAL_LLM_URL=&lt;local-llm-url&gt;                        # You may choose to use local LLM.\n# Pinecone\nexport MY_PINECONE_API_KEY=&lt;pinecone-api-key&gt;               # Necessary. Free account is enough.\nexport MY_PINECONE_ENV=&lt;pinecone-env&gt;                       # e.g. 'gcp-starter'\n</code></pre> </li> <li> <p>Install the required dependencies by running:</p> <pre><code>pip install -e .\n</code></pre> </li> <li> <p>Run Mastaba     <pre><code>python main.py\n</code></pre></p> </li> </ol>"},{"location":"advanced_materials/llm_agent.html#switch-agents","title":"Switch Agents","text":"<p>Choose BaseLang agent:</p> <pre><code>import gymnasium\nfrom agents import BaseLangAgent\nfrom civrealm.freeciv.utils.freeciv_logging import fc_logger\n\n\ndef main():\n    env = gymnasium.make('civrealm/FreecivLLM-v0')\n    agent = BaseLangAgent()\n\n    observations, info = env.reset()\n\n    done = False\n    step = 0\n    while not done:\n        try:\n            action = agent.act(observations, info)\n            observations, reward, terminated, truncated, info = env.step(\n                action)\n            done = terminated or truncated\n\n            step += 1\n            print(\n                f'Step: {step}, Turn: {info[\"turn\"]}, Reward: {reward}, Terminated: {terminated}, '\n                f'Truncated: {truncated}, action: {action}')\n        except Exception as e:\n            fc_logger.error(repr(e))\n            raise e\n    env.close()\n\n\nif __name__ == '__main__':\n    main()\n</code></pre> <p>Choose Mastaba agent:</p> <pre><code>import gymnasium\nfrom agents import MastabaAgent\nfrom civrealm.freeciv.utils.freeciv_logging import fc_logger\n\n\ndef main():\n    env = gymnasium.make('civrealm/FreecivLLM-v0')\n    agent = MastabaAgent(max_deconflict_depth=3)\n\n    observations, info = env.reset()\n\n    done = False\n    step = 0\n    while not done:\n        try:\n            action = agent.act(observations, info)\n            observations, reward, terminated, truncated, info = env.step(\n                action)\n            done = terminated or truncated\n\n            step += 1\n            print(\n                f'Step: {step}, Turn: {info[\"turn\"]}, Reward: {reward}, Terminated: {terminated}, '\n                f'Truncated: {truncated}, action: {action}')\n        except Exception as e:\n            fc_logger.error(repr(e))\n            raise e\n    env.close()\n\n\nif __name__ == '__main__':\n    main()\n</code></pre> <p>Customize Env by LLM Wrapper</p> <p>You can also make a LLM Env by LLM Wrapper</p> <pre><code>env = gymnasium.make('civrealm/FreecivBase-v0')\nenv = LLMWrapper(env)\nagent = BaseLang()\n</code></pre> <pre><code>env = gymnasium.make('civrealm/FreecivBase-v0')\nenv = LLMWrapper(env)\nagent = MastabaAgent(max_deconflict_depth=3)\n</code></pre>"},{"location":"advanced_materials/llm_agent.html#conclusion","title":"Conclusion","text":"<p>In this guide, we introduced the CivRealm LLM Environment and explained how to use the civrealm-llm-baseline repository to build llm agents on this environment. We encourage you to experiment with different LLM frameworks to further enhance your agent's performance.</p>"},{"location":"advanced_materials/minigame_create.html","title":"Create new Mini-Game","text":"<p>The general pipeline of creating new mini-game is as follows:</p> <pre><code>graph TD\n    A(&lt;a href=\"#be-clear-about-what-to-do\"&gt;Be clear about \\nwhat to do&lt;a&gt;) --&gt; D(&lt;a href=\"#use-gtk-tool-to-generate-basic-archive\"&gt;Use gtk tool to generate basic archive&lt;/a&gt;)\n    D --&gt; F(&lt;a href=\"#set-mini-game-messages-by-lua-script\"&gt;Set mini-game messages by lua script&lt;/a&gt;)\n    F --&gt; E(&lt;b&gt;&lt;a href=\"#large-batch-auto-random-generation\"&gt;Large batch auto random generation&lt;/a&gt;&lt;/b&gt;)\n    E --&gt; H{&lt;a href=\"#mini-game-validation\"&gt;Mini-Game Validation&lt;/a&gt;}\n    H --&gt; |Not Pass| J{Bug from \\nCivrealm}\n    J --&gt; |Yes| K[Contribute bugfix for Civrealm]\n    J --&gt; |No| D\n    H --&gt; |Pass| I[Create new Mini-Game successfully]</code></pre>"},{"location":"advanced_materials/minigame_create.html#be-clear-about-what-to-do","title":"Be clear about what to do","text":"<p>The basic design mechanisms of mini-game are:</p> <ul> <li> <p>Single Goal. Don't consider multiple learning objectives at the same time, otherwise the game will become less mini after more influences are introduced.</p> </li> <li> <p>Feasible Action. In the huge space of action, be clear about which actions are relevant to your goal, and avoid too many unrelated or paradoxical actions in actionable actions.</p> </li> <li> <p>Computable Reward. In addition to the final score at the end of the game, the reward for each step or turn can be defined and calculated.</p> </li> </ul> <p>At the beginning of designing a mini-game, you have to answer the following questions:</p> <ul> <li> <p>What type of the mini-game do you want to design?</p> </li> <li> <p>When does the mini-game end?</p> </li> <li> <p>How to calculate the reward for each step?</p> </li> <li> <p>How to set the difficulty of the game?</p> </li> </ul> <p>These questions will be given appropriate suggestions to some extent below.</p>"},{"location":"advanced_materials/minigame_create.html#use-gtk-tool-to-generate-basic-archive","title":"Use gtk tool to generate basic archive","text":"<p>The tool of freeciv-gtk is provided by freeciv official team to help us design the very basic version of each mini-game. Please follow the instructions in ((https://github.com/freeciv/freeciv/tree/main/doc)) to install the tool and run it, specify the game settings and ruleset, which would be like:</p> <p>After start a new game, use 'Edit -&gt; Edit Mode'  to design the scenario as you expect and then finish making an initial version of savegame. Save the edited scenario so that you can further edit or load it in the game. After that, you can continue to add messages and generate random maps based on it, which is introduced as followed.</p>"},{"location":"advanced_materials/minigame_create.html#set-mini-game-messages-by-lua-script","title":"Set mini-game messages by lua script","text":"<p>Warning</p> <p>Donot modify sav file directly in general. Because the fields in the sav file have dependencies on each other, if you modify a field without noticing some other fields that need to be modified at the same time, it will cause the server to load the sav file unsuccessfully.</p> <p>The lua script is used to send mini-game messages to the agent. Before adding the lua script for basic sav file, you need to understand the archive format of freeciv and how it defines the game state internally.</p> <ul> <li> <p>The suffix of the game archive file is <code>.sav</code>, and usually compressed as a compressed file with <code>.xz</code> or <code>.zst</code> suffix. If the archive file is compressed, you need to use the corresponding component to decompress it to get the sav file.</p> </li> <li> <p>In the sav file, there are many key-value structures to describe the current game state. Here, We list the main tags and their explanations:</p> </li> </ul> Tag Description savefile A set of definition rules for common elements, including activity, technology, etc. game The base state values of the game, such as turn, launch order and year. script The script of lua. At the inherent or designed trigger points of the game, obtain the internal data of the game, calculate the custom game state values, and send out event messages. settings The setting of freeciv server. map The global map of world, and distribution information of resources, cities, and land development. player0 The game status of a player with an id of 0, including information such as how many units and cities the player0 have.  score0 The scores of a player with an id of 0, including information such as total score and unhappy degree. research The progress of research for each player.  <p>Here, we focus on the implementation of <code>script</code> tag. In the sav file, the format of <code>script</code> as below:</p> <pre><code>[script]\ncode=${lua code}$\n</code></pre> <p><code>{lua code}</code> is the code of lua language that implements to send mini-game messages.</p> <p>Firstly, you need to consider which trigger points to set during the game in order to change the status value of the mini-game, and set up the end conditions of the game. All trigger action functions can be referred to the Lua Reference manual. We list the common trigger action functions as follows:</p> (return) type function name/variable arguments comments Boolean turn_begin (Number turn, Number year) Trigger at each turn begining. Boolean city_built (City city) Trigger at city built. Boolean unit_lost (Unit unit, Player loser, String reason) Trigger at unit lost. Boolean city_destroyed (City city, Player loser, Player destroyer) Trigger at city destroyed. <p>In addition, we developed the following trigger action function to enhance the perception of the freeciv-server game process:</p> (return) type function name/variable arguments comments Boolean game_started (Player player) Trigger at game started. The `game_started` supports to display the welcome message at the beginning of the game, if you use the `turn_begin` to set turn=1 to display the welcome message, it will not take effect, because the game thinks that it is already in the current turn running state, and will not trigger the judgment of the `turn_begin`, although this function can be achieved by setting the technique of phase=1 additionally, but the setting will cause other players to act first, which will bring unexpected problems. Boolean game_ended (Player player) Trigger at game ended. Since freeciv-server has many internal conditions for ending the game, all the end states of the game can be recycled by using game_ended. If game ended, set mini-game `status`=1(MinitaskGameStatus.MGS_END_GAME). Boolean action_finished_worker_build (City city) Trigger at activity finished by worker. Boolean action_started_worker_build (City city) Trigger at activity started by worker. <p>Secondly, calculate the mini-score and mini-goal.</p> <p>Taking mini-game <code>battle</code> as an example, the formula for calculating the <code>mini-score</code> is as follows:</p> <p>\\(\\text{mini_score}=\\text{unit_cnt_of_human_player} - \\text{unit_cnt_of_ai_player}\\)</p> <p>The larger the mini_score is, the more units of human player survives, the better, and the more units of ai player is destroyed, the better. The <code>mini-goal</code> is setting to</p> <p>\\(\\text{mini_goal}=\\text{unit_cnt_of_human_player}\\)</p> <p>It means that if you want to satisfy mini_score&gt;=mini_goal to succeed, you need to destroy all units of ai player.</p> <p>Finally, wrap your message of mini-game and send it out throught E.SCRIPT event. The event function is:</p> <pre><code>notify.event(nil, nil, E.SCRIPT, _(${message}))\n</code></pre>"},{"location":"advanced_materials/minigame_create.html#large-batch-auto-random-generation","title":"Large batch auto random generation","text":"<p>The auto random generation is supported by the <code>civrealm-sav</code> module. To implement a new mini-game dependently, you should inherit class <code>SavTaskGenerator</code>. For example,</p> <pre><code>from freeciv_sav.tasks.sav_task import SavTaskGenerator\n\nclass NewMiniGameGenerator(SavTaskGenerator):\n    def create_new_game(self, lua_conf:str, *args, **kwargs):\n        \"\"\"\n        Create new game.\n\n        Parameters\n        ----------\n        lua_conf : str\n            The lua script designed.\n        \"\"\"\n        while True:\n            {Call the functions from tools to implement randomization}\n            break\n        return\n</code></pre> <p>The tools contains <code>map_op</code> <code>unit_op</code>, <code>player_op</code>, <code>game_op</code>, etc. The main functions of tools are as follows:</p> OP function name comments map_op gen_random_walk_map Randomly generate mini-game map by random walk with modifying the terrain, resource and shape of land. unit_op set_location_with_cluster Randomly set location for units. player_op set_name Assignment the name of mini-game. game_op set_init_status Set game status initially. <p>Use these functions to help you to implement large batch auto random generation of mini-game.</p>"},{"location":"advanced_materials/minigame_create.html#mini-game-validation","title":"Mini-Game Validation","text":"<p>Check your mini-game inside <code>freeciv-web</code>, and test the mini-game to follow the section <code>Play mini-game as a random agent</code>. If the tests pass, congratulations on completing the task for creating new mini-game.</p>"},{"location":"advanced_materials/minigame_setting.html","title":"Setting","text":""},{"location":"advanced_materials/minigame_setting.html#game-status","title":"\ud83c\udfc1 Game Status","text":"<p>To describe whether a mini-game is over, the game-ending conditions include:</p> <ul> <li>The game score being greater than or equal to the goal score</li> <li>Reaching the maximum number of rounds set for the game</li> </ul> <p>The enumerated values are as follows:</p> src/civrealm/envs/freeciv_minitask_env.py<pre><code>@unique\nclass MinitaskGameStatus(ExtendedEnum):\n    MGS_END_GAME = 1\n    MGS_IN_GAME = 0\n</code></pre>"},{"location":"advanced_materials/minigame_setting.html#game-difficulty","title":"\ud83d\udd25 Game Difficulty","text":"<p>Based on the richness of terrain resources, the comparison of unit quantities, and other information, we designed the difficulty level of the mini-game.</p> <p>The enumerated values are as follows:</p> src/civrealm/envs/freeciv_minitask_env.py<pre><code>@unique\nclass MinitaskDifficulty(ExtendedEnum):\n    MD_EASY = 'easy'\n    MD_NORMAL = 'normal'\n    MD_HARD = 'hard'\n</code></pre>"},{"location":"advanced_materials/minigame_setting.html#victory-status","title":"\ud83c\udfc6 Victory Status","text":"<p>In the mini-game, the player\u2019s current victory status can be represented as: failure, success, and unknown. The unknown state signifies that the game has not yet concluded, while the determination of failure and success only occurs after the game ends.</p> <p>The enumerated values are as follows:</p> src/civrealm/envs/freeciv_minitask_env.py<pre><code>@unique\nclass MinitaskPlayerStatus(ExtendedEnum):\n    MPS_SUCCESS = 1\n    MPS_FAIL = 0\n    MPS_UNKNOWN = -1\n</code></pre>"},{"location":"advanced_materials/minigame_setting.html#supported-types","title":"\ud83d\uddfa\ufe0f Supported Types","text":"<p>We have designed the following 14 types of mini-games:</p> Category ID Name Introduction Development 1 development_build_city Move settler to suitable areas for building a city. 2 development_build_infra Command workers to build infrastructures for improving cities. 3 development_citytile_wonder Arrange work tiles to speed up producing a world wonder. 4 development_transport Transport settlers by ships to another continent and build cities. Battle 5 battle_ancient_era Defeat enemy units on land tiles in ancient era. 6 battle_industry_era Defeat enemy units on land tiles in industry era. 7 battle_info_era Defeat enemy units on land tiles in infomation era. 8 battle_medieval Defeat enemy units on land tiles in medieval. 9 battle_modern_era Defeat enemy units on land tiles in modern era. 10 battle_attack_city Conquer an enemy city. 11 battle_defend_city Against enemy invasion for a certain number of turns. 12 battle_naval Defeat enemy fleet on the ocean (with Middle Times frigates). 13 battle_naval_modern Defeat enemy fleet on the ocean (with several classes of modern ships). Diplomacy 14 diplomacy_trade_tech Trade technologies with another civilization. <p>The enumerated values are as follows:</p> src/civrealm/envs/freeciv_minitask_env.py<pre><code>@unique\nclass MinitaskType(ExtendedEnum):\n    MT_DEVELOPMENT_BUILD_CITY = \"development_build_city\"\n    MT_DEVELOPMENT_CITYTILE_WONDER = \"development_citytile_wonder\"\n    MT_DEVELOPMENT_BUILD_INFRA = \"development_build_infra\"\n    MT_DEVELOPMENT_TRANSPORT = \"development_transport\"\n    MT_BATTLE_ANCIENT = \"battle_ancient_era\"\n    MT_BATTLE_INDUSTRY = \"battle_industry_era\"\n    MT_BATTLE_INFO = \"battle_info_era\"\n    MT_BATTLE_MEDIEVAL = \"battle_medieval\"\n    MT_BATTLE_MODERN = \"battle_modern_era\"\n    MT_BATTLE_NAVAL_MODERN = \"battle_naval_modern\"\n    MT_BATTLE_NAVAL = \"battle_naval\"\n    MT_BATTLE_ATTACK_CITY = \"battle_attack_city\"\n    MT_BATTLE_DEFEND_CITY = \"battle_defend_city\"\n    MT_DIPLOMACY_TRADE_TECH = \"diplomacy_trade_tech\"\n</code></pre>"},{"location":"advanced_materials/minigame_usage.html","title":"Mini-Game","text":"<p>Due to the multifaceted aspects of a full game, including economic expansion, military development, diplomatic negotiations, cultural construction, and technological research, we have devised mini games to address each component individually. Each mini-game is designed with specific objectives, varying difficulty levels, step-based rewards, and an overall game score. The designed details could be found in the paper.</p> <p>By the end of this tutorial, you will be able to use API to play the mini-game.</p>"},{"location":"advanced_materials/minigame_usage.html#load-mini-game-by-freeciv-web","title":"Load Mini-Game by freeciv-web","text":"Prepare Dataset For Freeciv-web version == 1.3 <p>Before you start the mini-game, you need to load the mini-game designed archives into the server\u2019s laoding archive path.</p> <p>The steps are as follows:</p> <p>Step 1:  find your used version on the releases page, and download the data files for the mini-game to your local path such as <code>/tmp/minigame/</code></p> <p>Step 2:  copy the data files, and extract them into the corresponding docker savegame path. If the docker image is <code>freeciv-web</code>, and the tomcat version is <code>10</code>, then execute the following commands:</p> <pre><code>#!/bin/bash\nimage=\"freeciv-web\"\ntomcat_version=\"tomcat10\"\nlocal_path=\"/tmp/minigame/\"\n\nmkdir $local_path\ncd $local_path\ndocker exec -it $image rm -r /var/lib/$tomcat_version/webapps/data/savegames/minitask/\ndocker exec -it $image mkdir -p /var/lib/$tomcat_version/webapps/data/savegames/minitask/\nfor minitask_zip in `ls`\ndo\n    docker cp $minitask_zip $image:/var/lib/$tomcat_version/webapps/data/savegames/minitask/\n    docker exec -it $image unzip -o /var/lib/$tomcat_version/webapps/data/savegames/minitask/$minitask_zip -d /var/lib/$tomcat_version/webapps/data/savegames/minitask/\n    docker exec -it $image rm /var/lib/$tomcat_version/webapps/data/savegames/minitask/$minitask_zip\ndone\n</code></pre> <p>To load the mini-game sav file <code>MINIGAME_FILE_NAME</code> by the freeciv-web service, follow these steps:</p> <ol> <li> <p>Login by the Player name <code>minitask</code>, and click the <code>Customize Game</code> button; </p> </li> <li> <p>Enter the command <code>/load MINIGAME_FILE_NAME</code> in the input box at the bottom; </p> </li> <li> <p>Click the <code>Start Game</code> button to start the mini-game. </p> </li> </ol>"},{"location":"advanced_materials/minigame_usage.html#initialize-random-mini-game","title":"Initialize Random Mini-Game","text":"<p><code>civrealm/FreecivMinitask-v0</code> is the environment of mini-game. When the mini game is launched, its internal design will randomly select a game of any type and any difficulty.</p> <pre><code>from civrealm.agents import ControllerAgent\nimport gymnasium\n\nenv = gymnasium.make('civrealm/FreecivMinitask-v0')\nagent = ControllerAgent()\nobservations, info = env.reset()\n</code></pre>"},{"location":"advanced_materials/minigame_usage.html#choose-specific-mini-game","title":"Choose Specific Mini-Game","text":"<p>Inside <code>reset</code> method of environment, you can use the parameter <code>minitask_pattern</code> to choose specific mini-game. The fields are as follows:</p> <p><code>type</code>: the type of mini-game, see the available options MinitaskType</p> <p><code>level</code>: the difficulty of mini-game, see the available options MinitaskDifficulty</p> <p><code>id</code>: the id of mini-game, the available range is 0 to MAX_ID</p> <p>For example, if you want to set the type as <code>development_build_city</code> and the difficulty as <code>easy</code>, then the code is as follows:</p> <pre><code>from civrealm.agents import ControllerAgent\nimport gymnasium\n\nenv = gymnasium.make(\"civrealm/FreecivMinitask-v0\")\nobservations, info = env.reset(minitask_pattern={\n    \"type\": \"development_build_city\", \n    \"level\": \"easy\"})\n</code></pre>"},{"location":"advanced_materials/minigame_usage.html#definition-of-mini-game-messages","title":"Definition of Mini-game messages","text":"<p>The messages of mini-game are passed from the server to the agent at each trigger point by lua script setting. The general json structure of message is:</p> <pre><code>{\n    \"task\": \"minitask\",\n    \"name\": \"${name of minitask}\",\n    \"status\": ${MinitaskGameStatus},\n    \"turn\": ${turn of game},\n    \"metrics\": [{\n        \"mini_score\": ${mini_score},\n        \"mini_goal\": ${mini_goal},\n        \"max_turn\": ${max_turn},\n        \"is_mini_success\": ${MinitaskPlayerStatus},\n    }]\n}\n</code></pre> <ul> <li> <p>The <code>task</code> is used to label the source of message. The <code>task</code> for messages from mini-game is set to be <code>minitask</code>.</p> </li> <li> <p>The final element of <code>metrics</code> records the final game review status for each trigger action, which is actually used in civrealm. In the dict structure of <code>metrics</code> elements, we can  define other useful auxiliary information</p> </li> <li> <p>The <code>metrics.mini_score</code> is used to record the agent's mini-game score.</p> </li> <li> <p>The <code>metrics.mini_goal</code> is used to record the agent's mini-game goal, which is to set the game victory score threshold.</p> </li> <li> <p>The <code>metrics.max_turn</code> is limited to a certain number of turns. If the maximum number of turns is exceeded, failure is returned in civrealm.</p> </li> <li> <p>The <code>metrics.is_mini_success</code> is used to record the player succeed status of player, which is the same as <code>success</code> defined of minitask info in civrealm. If succeed, it requires that <code>mini_score&gt;=mini_goal</code>.</p> </li> </ul>"},{"location":"advanced_materials/minigame_usage.html#play-mini-game-as-a-random-agent","title":"Play mini-game as a random agent","text":"<p>Generally speaking, it is difficult for random agents to win the battle and diplomacy mini-game, and in the development mini-game, the game victory condition will be met with a certain probability.</p> <p>The commands are as follows:</p> <pre><code>cd civrealm/\npython src/civrealm/random_game_minitask.py\n</code></pre> <p>After executing the commands, the log will be like:</p> <p>Success</p> <pre><code>Step: 0, Turn: 1, Reward: 0.0, Terminated: False, Truncated: False, Action: ('tech', 'cur_player', 'set_tech_goal_Conscription_18')\n        Minitask Info: {'status': 0, 'success': -1, 'human_cnt': 11.0, 'ai_cnt': 12.0, 'mini_score': -1.0, 'mini_goal': 11.0, 'max_turn': 50, 'human_leader_alive': 1, 'ai_leader_alive': 1, 'is_mini_success': -1}\nStep: 1, Turn: 1, Reward: 0.0, Terminated: False, Truncated: False, Action: ('unit', 108, 'goto_1')\n        Minitask Info: {'status': 0, 'success': -1, 'human_cnt': 11.0, 'ai_cnt': 12.0, 'mini_score': -1.0, 'mini_goal': 11.0, 'max_turn': 50, 'human_leader_alive': 1, 'ai_leader_alive': 1, 'is_mini_success': -1}\n</code></pre> <p>In the log, We can see that each step displays some fields from the above definitions as <code>Definition of Mini-game messages</code>, and some are auxiliary fields designed by mini-game itself such as <code>human_leader_alive</code>.</p>"},{"location":"advanced_materials/minigame_usage.html#play-mini-game-as-a-ai-assistant-agent","title":"Play mini-game as a AI-assistant agent","text":"<p>Warning</p> <p>The AI-assistant agent only supports <code>development_build_city</code>.</p> <p>To engage in a dialogue with the rule-based AI assistant integrated within the freeciv server, please configure the following command: <pre><code>fc_args['advisor'] = 'enabled'\n</code></pre></p> <p>The comprehensive script for invoking the AI assistant within the minigame setting is outlined below: <pre><code>import time\nfrom civrealm.freeciv.utils.freeciv_logging import fc_logger\nfrom civrealm.envs.freeciv_wrapper import LLMWrapper\nfrom civrealm.configs import fc_args\nfrom civrealm.freeciv.utils.port_utils import Ports\nimport civrealm\nimport gymnasium\n\n# enabled AI-assistant\nfc_args['advisor'] = 'enabled'\n\ndef main():\n    env = gymnasium.make('civrealm/FreecivMinitask-v0', client_port=Ports.get())\n    step = 0\n    observations, info = env.reset(minitask_pattern={\n        \"type\": [\n            \"development_build_city\"]\n    })\n    done = False\n    while not done:\n        try:\n            # get AI-assistant action\n            action = env.civ_controller.get_assistant_action()\n            fc_logger.info(f\"Prepare to act: {action}\")\n            # env step\n            observations, reward, terminated, truncated, info = env.step(action)\n            print(\n                f'Step: {step}, Turn: {info[\"turn\"]}, Reward: {reward}, Terminated: {terminated}, '\n                f'Truncated: {truncated}, action: {action}')\n            step += 1\n            done = terminated or truncated\n        except Exception as e:\n            fc_logger.error(repr(e))\n            raise e\n\n    env.close()\n\nif __name__ == '__main__':\n    main()\n</code></pre></p>"},{"location":"advanced_materials/parallel_training.html","title":"Parallel Training","text":"<p>Civrealm supports parallel training to speed up the learning process. Concretely, we use Ray to implement the parallel training function in the <code>FreecivParallelEnv</code> class located in <code>src/civrealm/envs/freeciv_parallel_env.py</code>. To initialize the parallel running environments, simply create multiple <code>FreecivParallelEnv</code>objects:</p> <pre><code>def __init__(self, env_name, agent):\n    # Number of envs that run simultaneously\n    self.batch_size_run = fc_args['batch_size_run']\n    # Initialize envs\n    self.envs = []\n    for _ in range(self.batch_size_run):\n        env = FreecivParallelEnv.remote(env_name)\n        self.envs.append(env)\n</code></pre> <p>To reset the environments to get initial observations, we can call the reset() method of each <code>FreecivParallelEnv</code>object. Each <code>FreecivParallelEnv</code>object will run its reset process simultaneously and we can retrieve the results based on the result ids.</p> <pre><code>def reset(self):\n    observations = []\n    infos = []\n    # Reset the envs\n    result_ids = [self.envs[i].reset.remote()\n                    for i in range(self.batch_size_run)]\n    results = ray.get(result_ids)\n\n    for i in range(self.batch_size_run):\n        observations.append(results[i][0])\n        infos.append(results[i][1])\n</code></pre> <p>After the environments are reset, we call the step() method of each <code>FreecivParallelEnv</code>object to play the game. Similar to reset, each <code>FreecivParallelEnv</code>object runs its step process simultaneously and we can retrieve the results based on the result ids. After all parallel running environments are terminated, we call the close() method of <code>FreecivParallelEnv</code>objects to close them.</p> <pre><code>def run(self):\n    self.reset()\n    all_terminated = False\n    # Store whether an env has terminated\n    dones = [False]*self.batch_size_run\n    # Store whether an env has closed its connection\n    closed_envs = [False]*self.batch_size_run\n\n    while True:\n        observations = [None] * self.batch_size_run\n        infos = [None] * self.batch_size_run\n        rewards = [0]*self.batch_size_run\n        # Start the parallel running\n        result_ids = []\n        # key: index of result_ids, value: id of env\n        id_env_map = {}\n        # Make a decision and send action for each parallel environment\n        for i in range(self.batch_size_run):\n            if not dones[i]:\n                observation = self.batchs[self.t][0][i]\n                info = self.batchs[self.t][1][i]\n                if random.random() &lt; 0.1:\n                    action = None\n                else:\n                    action = self.agent.act(observation, info)\n                print(f\"Env ID: {i}, turn: {info['turn']}, action: {action}\")\n                id = self.envs[i].step.remote(action)\n                result_ids.append(id)\n                id_env_map[id] = i\n\n        finished = False\n        unready = result_ids\n        # Get the result of each environment one by one\n        while not finished:\n            # The num_returns=1 ensures ready length is 1.\n            ready, unready = ray.wait(unready, num_returns=1)\n            # Get the env id corresponding to the given result id\n            env_id = id_env_map[ready[0]]\n            try:\n                result = ray.get(ready[0])\n                observations[env_id] = result[0]\n                rewards[env_id] = result[1]\n                terminated = result[2]\n                truncated = result[3]\n                infos[env_id] = result[4]\n                dones[env_id] = terminated or truncated\n                print(f'Env ID: {env_id}, reward: {rewards[env_id]}, done: {dones[env_id]}')\n            except Exception as e:\n                print(str(e))\n                self.logger.warning(repr(e))\n                dones[env_id] = True\n            if not unready:\n                finished = True\n        self.batchs.append(\n            (observations, infos, rewards, dones))\n\n        result_ids = []\n        # Close the terminated environment\n        for i in range(self.batch_size_run):\n            if dones[i] and not closed_envs[i]:\n                result_ids.append(self.envs[i].close.remote())\n                closed_envs[i] = True\n        ray.get(result_ids)\n        all_terminated = all(dones)\n        if all_terminated:\n            break\n        # Move onto the next timestep\n        self.t += 1\n\n    return self.batchs\n</code></pre> <p>For a complete example, you may refer to the <code>ParallelRunner</code> class located in <code>src/civrealm/runners/parallel_runner.py</code>. You can run <code>src/civrealm/random_game_parallel.py</code> to test <code>ParallelRunner</code>. In addition, you can also regard the <code>ParallelTensorEnv</code> class located in <code>src/civrealm/envs/parallel_tensor_env.py</code> as an example. The <code>TensorBaselineEnv</code> class in the <code>civtensor</code> package uses the <code>ParallelTensorEnv</code> class to achieve parallel training.</p>"},{"location":"advanced_materials/tensor_agent.html","title":"Tensor Agent","text":"<p>Welcome to Civrealm Tensor Agent! This documentation will guide you through the process of training tensor-based agents, specifically using the Proximal Policy Optimization (PPO), in the Civrealm Environment. We will first provide an overview of the Civrealm Tensor Env, followed by instructions on how to use the civrealm-tensor-baseline repository to train a PPO agent on this environment.</p>"},{"location":"advanced_materials/tensor_agent.html#civrealm-tensor-environment","title":"\ud83c\udf0f Civrealm Tensor Environment","text":"<p>The Civrealm Tensor Environment is a reinforcement learning environment wrapped upon Civrealm Base Env specifically designed for training agents using tensor-based algorithms. This environment</p> <ul> <li>offer immutable spaces for mutable observation and actions,</li> <li>provides flattened, tensorized observation and action spaces,</li> <li>restrict available actions in order to reduce meaningless actions,</li> <li>offers delta game score as a basic reward for RL agents,</li> <li>provide parallel environments with batched inputs and outputs for efficient training,</li> </ul> <p>and various modular wrappers which are open to customize your own environment.</p>"},{"location":"advanced_materials/tensor_agent.html#quick-start","title":"Quick Start","text":"<p>Start a single FreecivTensor environment :</p> <pre><code>env = gymnasium.make(\"freeciv/FreecivTensor-v0\", client_port=Ports.get())\nobs, info = env.reset()\n</code></pre> <p>Start a parallel tensor environment with 8 parallel FreecivTensor envs:</p> <pre><code># Training Fullgame\nenv = gymnasium.make(\"civtensor/TensorBaselineEnv-v0\", parallel_number=8,task=\"fullgame\")\n# Training Minitasks\n# env = gymnasium.make(\"civtensor/TensorBaselineEnv-v0\", parallel_number=8,task=\"development_build_city normal\")\nobs, info = env.reset()\n</code></pre>"},{"location":"advanced_materials/tensor_agent.html#observation","title":"Observation","text":"<p>The observation space is a gymnasium.Dict() consisting of 9 subspaces with keys listed below.</p> <p>Observations can be immutable and mutable.</p> <p>Immutable Obs: <code>map</code>, <code>player</code>, <code>rules</code>.</p> <p>hey have fixed dimensions through the game-play.</p> Immutable Observations <p> Immutables Field Dimension rules build_cost (120,) map status (84, 56, 3) terrain (84, 56, 14) extras (84, 56, 34) output (84, 56, 6) tile_owner (84, 56, 1) city_owner (84, 56, 1) unit (84, 56, 52) unit_owner (84, 56, 1) player score (1,) is_alive (1,) turns_alive (1,) government (6,) target_government (7,) tax (1,) science (1,) luxury (1,) gold (1,) culture (1,) revolution_finishes (1,) science_cost (1,) tech_upkeep (1,) techs_researched (1,) total_bulbs_prod (1,) techs (87,) </p> <p>Mutable Obs: <code>unit</code>, <code>city</code>, <code>others_unit</code>, <code>others_city</code>, <code>others_player</code>, <code>dipl</code>.</p> <p>The number of units, cities, and other mutable observations are constantly changing. Nevertheless, we truncate or pad mutable entities to a fixed size.</p> Mutables Size unit 128 city 32 others_unit 128 others_city 64 others_player 10 dipl 10 Mutable Observations for a Single Entity <p> Mutables Field Dimension per Entity city owner (1,) size (1,) x (1,) y (1,) food_stock (1,) granary_size (1,) granary_turns (1,) production_value (120,) city_radius_sq (1,) buy_cost (1,) shield_stock (1,) disbanded_shields (1,) caravan_shields (1,) last_turns_shield_surplus (1,) improvements (68,) luxury (1,) science (1,) prod_food (1,) surplus_food (1,) prod_gold (1,) surplus_gold (1,) prod_shield (1,) surplus_shield (1,) prod_trade (1,) surplus_trade (1,) bulbs (1,) city_waste (1,) city_corruption (1,) city_pollution (1,) state (5,) turns_to_prod_complete (1,) prod_process (1,) ppl_angry (6,) ppl_unhappy (6,) ppl_content (6,) ppl_happy (6,) before_change_shields (1,) unit owner (1,) health (1,) veteran (1,) x (1,) y (1,) type_rule_name (52,) type_attack_strength (1,) type_defense_strength (1,) type_firepower (1,) type_build_cost (1,) type_convert_time (1,) type_obsoleted_by (53,) type_hp (1,) type_move_rate (1,) type_vision_radius_sq (1,) type_worker (1,) type_can_transport (1,) home_city (1,) moves_left (1,) upkeep_food (1,) upkeep_shield (1,) upkeep_gold (1,) others_city owner (1,) size (1,) improvements (68,) style (10,) capital (1,) occupied (1,) walls (1,) happy (1,) unhappy (1,) others_unit owner (1,) veteran (1,) x (1,) y (1,) type (52,) occupied (1,) transported (1,) hp (1,) activity (1,) activity_tgt (1,) transported_by (1,) others_player score (1,) is_alive (2,) love (12,) diplomatic_state (8,) techs (87,) dipl type (20,) give_city (32,) ask_city (64,) give_gold (16,) ask_gold (16,) </p>"},{"location":"advanced_materials/tensor_agent.html#action","title":"Action","text":"<p>In tensor environment, the complete action space is</p> <pre><code>spaces.Dict(\n            {\n                \"actor_type\": spaces.Discrete(len(self.actor_type_list)),\n                \"city_id\": spaces.Discrete(self.action_config[\"resize\"][\"city\"]),\n                \"city_action_type\": spaces.Discrete(\n                    sum(self.action_config[\"action_layout\"][\"city\"].values())\n                ),\n                \"unit_id\": spaces.Discrete(self.action_config[\"resize\"][\"unit\"]),\n                \"unit_action_type\": spaces.Discrete(\n                    sum(self.action_config[\"action_layout\"][\"unit\"].values())\n                ),\n                \"dipl_id\": spaces.Discrete(self.action_config[\"resize\"][\"dipl\"]),\n                \"dipl_action_type\": spaces.Discrete(\n                    sum(self.action_config[\"action_layout\"][\"dipl\"].values())\n                ),\n                \"gov_action_type\": spaces.Discrete(\n                    sum(self.action_config[\"action_layout\"][\"gov\"].values())\n                ),\n                \"tech_action_type\": spaces.Discrete(\n                    sum(self.action_config[\"action_layout\"][\"tech\"].values())\n                ),\n            }\n        )\n</code></pre> <p>The <code>actor_type</code> indicate which actor type this action belongs to, the value \\(\\in [0\\dots5]\\) indicating <code>city</code>,<code>unit</code>,<code>gov</code>,<code>dipl</code>,<code>tech</code>,<code>end-turn</code> respectively.</p> <p>For a mutable type <code>$mutable</code>, <code>${mutable}_id</code> indicates the position of the unit to take this action in the list of entities. For example, <code>unit_id=0</code> might indicate a <code>Settler</code> located at a specific tile.</p> <p><code>${actor_type}_action_type</code> is an action index which can be translated into a specific action, for example <code>goto_8</code> or <code>stop_negotiation</code>.</p> Tip <p>Although the full action space is a Cartesion product of 9 subspaces, the <code>actor_type</code> will determine which category of entity should execute this action, and <code>${actor_type}_id</code> will determine which entity should execute a specific action <code>${actor_type}_action_type</code>.</p> <p>Thus it suffices for the env to only look at 3 tuples: <code>(actor_type, ${actor_type}_id, ${actor_type}_action_type)</code>, and it's legitimate to pass a 3-tuple if their values and types are compatible.</p> Action Space Details <p> Category Actions Count city city_work_None_ 4 city_unwork_None_ 4 city_work_ 20 city_unwork_ 20 city_buy_production 1 city_change_specialist_ 3 city_sell 35 produce 120 unit transform_terrain 1 mine 1 cultivate 1 plant 1 fortress 1 airbase 1 irrigation 1 fallout 1 pollution 1 keep_activity 1 paradrop 1 build_city 1 join_city 1 fortify 1 build_road 1 build_railroad 1 pillage 1 set_homecity 1 airlift 1 upgrade 1 deboard 1 board 1 unit_unload 1 cancel_order 1 goto_ 8 attack_ 8 conquer_city_ 8 spy_bribe_unit_ 8 spy_steal_tech_ 8 spy_sabotage_city_ 8 hut_enter_ 8 embark_ 8 disembark_ 8 trade_route_ 9 marketplace_ 9 embassy_stay_ 8 investigate_spend_ 8 dipl stop_negotiation_ 1 accept_treaty_ 1 cancel_treaty_ 1 cancel_vision_ 1 add_clause_ShareMap_ 2 remove_clause_ShareMap_ 2 add_clause_ShareSeaMap_ 2 remove_clause_ShareSeaMap_ 2 add_clause_Vision_ 2 remove_clause_Vision_ 2 add_clause_Embassy_ 2 remove_clause_Embassy_ 2 add_clause_Ceasefire_ 2 remove_clause_Ceasefire_ 2 add_clause_Peace_ 2 remove_clause_Peace_ 2 add_clause_Alliance_ 2 remove_clause_Alliance_ 2 trade_tech_clause_Advance_ 174 remove_clause_Advance_ 174 trade_gold_clause_TradeGold_ 30 remove_clause_TradeGold_ 30 trunc_trade_city_clause_TradeCity_ 96 trunc_remove_clause_TradeCity_ 96 gov change_gov_Anarchy 1 change_gov_Despotism 1 change_gov_Monarchy 1 change_gov_Communism 1 change_gov_Republic 1 change_gov_Democracy 1 set_sci_luax_tax 66 tech research 87 </p> <p>You can copy the above HTML table and use it in your HTML file or any other HTML-supported platform.</p>"},{"location":"advanced_materials/tensor_agent.html#network-architecture-for-a-tensor-agent","title":"\ud83e\udd16 Network Architecture for a Tensor Agent","text":"<p>To effectively handle multi-source and variable-length inputs, we draw inspiration from AlphaStar and implement a serialized hierarchical feature extraction and action selection approach, as shown above. This method involves generating layered actions and predicting value function outputs, and our neural network architecture comprises three main components: representation learning, action selection, and value estimation.</p> <p>Representation. At the representation level, we adopt a hierarchical structure. In the lower layer, we extract controller features using various models like MLP, Transformer, and CNN, depending on whether the input is a single vector, sequence, or image-based. These extracted features are then fed into a transformer to facilitate attention across different entities, creating globally meaningful representations. Additionally, we utilize an RNN to combine the current-state features with the memory state, enabling conditional policy decisions based on the state history.</p> <p>Action selection. At the action selection level, we leverage the learned representations to make decisions. In the actor selection module, we determine the primary action category to be executed, including options like unit, city, government, technology, diplomacy, or termination. Subsequently, we employ a pointer network to select the specific action ID to be executed, followed by the determination of the exact action to be performed.</p> <p>Value estimation. To enable the use of an actor-critic algorithm, we incorporate a value prediction head after the representation learning phase. This shared representation part of the network benefits both the actor and critic, enhancing training efficiency.</p> <p>Training. We use the Proximal Policy Optimization (PPO) algorithm to train the agent. To mitigate the on-policy sample complexity of PPO, we harness Ray for parallelizing tensor environments, optimizing training speed and efficiency.</p>"},{"location":"advanced_materials/tensor_agent.html#using-civrealm-tensor-baseline-repository","title":"\ud83c\udfc3 Using civrealm-tensor-baseline Repository","text":"<p>The civrelam-tensor-baseline repository is a collection of code and utilities that provide a baseline implementation for training reinforcement learning agents using tensor-based algorithms.</p> <p>It includes an implementation of the PPO algorithm, which we will use to train our agents in the Civrealm Tensor Environment.</p>"},{"location":"advanced_materials/tensor_agent.html#getting-started","title":"\ud83c\udfcc\ufe0f Getting Started","text":"<p>To get started, follow these steps:</p> <ol> <li> <p>Clone the civrealm-tensor-baseline repository from GitHub and enter the directory:</p> <pre><code>cd civrealm-tensor-baseline\n</code></pre> </li> <li> <p>Install the required dependencies by running:</p> <pre><code>pip install -e .\n</code></pre> </li> <li> <p>Training     PPO baseline for fullgame</p> <pre><code>cd examples\npython train.py\n</code></pre> <p>In default, this would start a runner with the config specified in <code>civrealm-tensor-baseline/civtensor/configs/</code>.</p> </li> <li> <p>OR Train PPO baseline for minitasks:</p> <pre><code>cd examples\npython run.py\n</code></pre> <p>In default, this would start a sequence of runners each with a minitask config specified in <code>civrealm-tensor-baseline/examples/run_configs</code>. Either will start the training process, allowing the agent to interact with the environment, collect experiences, and update its policy using the PPO algorithm.</p> </li> <li> <p>Monitor the training progress and evaluate the agent's performance,     using the provided metrics and visualization tools in     the civrealm-tensor-baseline repository.</p> <p><pre><code>cd examples/results/freeciv_tensor_env/$game_type/ppo/installtest/seed-XXXXXXXXX\n# where $game_type = fullgame or minitask\ntensorboard --logdir logs/\n</code></pre> The output of the last command should return a url.  Visit this url with your favorite web browser, and you can view your agent performance in real time. </p> </li> </ol> <p>Congratulations! You have successfully set up the Civrealm Tensor Agent and started training a PPO agent on the Civrealm Tensor Environment, using the civrealm-tensor-baseline repository.</p>"},{"location":"advanced_materials/tensor_agent.html#runner-configuration","title":"Runner Configuration","text":"<p>The default configs reside in <code>civtensor/configs/</code></p> <p><code>freeciv_tensor_env.yaml</code> defines environment-related properties. You may specify which task to run by specifying <code>task_name</code>. civtensor/configs/env_cfgs/freeciv_tensor_env.yaml<pre><code>task_name: fullgame\nenv_args:\n</code></pre></p> <ul> <li>Acceptable <code>task_name</code> are <code>\"fullgame\"</code> or <code>\"$minitask_type $minitask_difficulty\"</code>. </li> </ul> <p>Note</p> <p>For available mini-task types and difficulties, please check minigame</p> <p><code>ppo.yaml</code> defines environment-related properties. You may specify which task to run by specifying <code>task_name</code>.</p> Details of <code>ppo.yaml</code> civtensor/configs/algos_cfgs/ppo.yaml<pre><code>seed:\n  # whether to use the specified seed\n  seed_specify: False\n  # seed\n  seed: 1\ndevice:\n  # whether to use CUDA\n  cuda: True\n  # whether to set CUDA deterministic\n  cuda_deterministic: True\n  # arg to torch.set_num_threads\n  torch_threads: 4\ntrain:\n  # number of parallel environments for training data collection\n  n_rollout_threads: 8\n  # number of total training steps\n  num_env_steps: 10000000\n  # number of steps per environment per training data collection\n  episode_length: 125\n  # logging interval\n  log_interval: 1\n  # evaluation interval\n  eval_interval: 5\n  # whether to use ValueNorm\n  use_valuenorm: True\n  # whether to use linear learning rate decay\n  use_linear_lr_decay: False\n  # whether to consider the case of truncation when an episode is done\n  use_proper_time_limits: True\n  # if set, load models from this directory; otherwise, randomly initialise the models\n  model_dir: ~\neval:\n  # whether to use evaluation\n  use_eval: True\n  # number of parallel environments for evaluation\n  n_eval_rollout_threads: 1\n  # number of episodes per evaluation\n  eval_episodes: 20\nrender:\n  # whether to use render\n  use_render: False\n  # number of episodes to render\n  render_episodes: 10\nmodel:\n  # hidden dimension\n  hidden_dim: 256\n  # hidden dimension for rnn\n  rnn_hidden_dim: 1024\n  # number of heads in transformer\n  n_head: 2\n  # number of layers in transformer\n  n_layers: 2\n  # dropout probability\n  drop_prob: 0\n  # number of rnn layers\n  n_rnn_layers: 2\n  # initialization method for network parameters, choose from xavier_uniform_, orthogonal_, ...\n  initialization_method: orthogonal_\n  # gain of the output layer of the network.\n  gain: 0.01\n  # length of data chunk; only useful when use_recurrent_policy is True; episode_length has to be a multiple of data_chunk_length\n  data_chunk_length: 10\n  # actor learning rate\n  lr: 0.0005\n  # eps in Adam\n  opti_eps: 0.00001\n  # weight_decay in Adam\n  weight_decay: 0\nalgo:\n  # ppo parameters\n  # number of epochs for actor update\n  ppo_epoch: 5\n  # whether to use clipped value loss\n  use_clipped_value_loss: True\n  # clip parameter\n  clip_param: 0.2\n  # number of mini-batches per epoch\n  num_mini_batch: 1\n  # coefficient for entropy term in actor loss\n  entropy_coef: 0.01\n  # coefficient for value loss\n  value_loss_coef: 0.001\n  # whether to clip gradient norm\n  use_max_grad_norm: True\n  # max gradient norm (0.5?)\n  max_grad_norm: 10.0\n  # whether to use Generalized Advantage Estimation (GAE)\n  use_gae: True\n  # discount factor\n  gamma: 0.99\n  # GAE lambda\n  gae_lambda: 0.95\n  # whether to use huber loss\n  use_huber_loss: True\n  # huber delta\n  huber_delta: 10.0\nlogger:\n  # logging directory\n  log_dir: \"./results\"\n</code></pre>"},{"location":"advanced_materials/tensor_agent.html#conclusion","title":"Conclusion","text":"<p>In this guide, we introduced the Civrealm Tensor Environment and explained how to use the civrealm-tensor-baseline repository to train a PPO agent on this environment.</p> <p>We encourage you to explore the various features and customization options available, and experiment with different reinforcement learning algorithms to further enhance your agent's performance. Happy training!</p>"},{"location":"api_reference/environments.html","title":"Environments","text":""},{"location":"api_reference/environments.html#base-environment","title":"Base Environment","text":""},{"location":"api_reference/environments.html#envs.freeciv_base_env.FreecivBaseEnv","title":"<code>envs.freeciv_base_env.FreecivBaseEnv</code>","text":"<p>             Bases: <code>Env</code>, <code>EzPickle</code></p> <p>Basic CivRealm environment</p> Source code in <code>src/civrealm/envs/freeciv_base_env.py</code> <pre><code>class FreecivBaseEnv(gymnasium.Env, utils.EzPickle):\n    \"\"\" Basic CivRealm environment \"\"\"\n    metadata = {'render_modes': ['human']}\n\n    def __init__(\n            self, username: str = fc_args['username'],\n            client_port=None,\n            is_minitask=False):\n        self.username = username\n        self.is_minitask = is_minitask\n        # Record whether the env is currently running.\n        self.running = False\n\n        # Create dummy controller to retrieve action_space and observation_space.\n        self.civ_controller = CivController(username=self.username,\n                                            visualize=fc_args['debug.take_screenshot'] or fc_args['debug.get_webpage_image'],\n                                            is_minitask=self.is_minitask)\n        self._action_space = self.civ_controller.action_space\n        self._observation_space = self.civ_controller.observation_space\n        self.set_up_recording()\n        utils.EzPickle.__init__(self, self.username,\n                                client_port, self.is_minitask)\n\n    def set_up_screenshots(self):\n        self._screenshot_step_count = 0\n        curr_date_time = str(datetime.date.today()) + \"_\" + \\\n            str(datetime.datetime.now().time().strftime('%H-%M-%S.%f'))\n        self.screenshot_dir = os.path.join(\n            os.path.dirname(fc_logger.handlers[0].baseFilename),\n            'screenshots', self.username + \"_\" + str(self.get_port()) + \"_\" + curr_date_time)\n        os.makedirs(self.screenshot_dir, exist_ok=True)\n\n    def set_up_recording(self):\n        # For recording purposes. self.record_step_count only increases when recording is enabled.\n        self._record_step_count = 0\n        self.recording_dir = os.path.join(\n            os.path.dirname(fc_logger.handlers[0].baseFilename),\n            'recordings', fc_args['username'])\n        os.makedirs(self.recording_dir, exist_ok=True)\n\n    @property\n    def action_space(self):\n        self._action_space = self.civ_controller.action_space\n        return self._action_space\n\n    @property\n    def observation_space(self):\n        self._observation_space = self.civ_controller.observation_space\n        return self._observation_space\n\n    def _take_screenshot(self):\n        if not fc_args['debug.take_screenshot']:\n            return\n        turn = self.civ_controller.get_turn()\n        screenshot_filename = os.path.join(\n            self.screenshot_dir, f'turn_{turn:03d}_step_{self._screenshot_step_count:04d}.png')\n        self.civ_controller.take_screenshot(screenshot_filename)\n        self._screenshot_step_count += 1\n\n    def _record_to_file(self, name, content, default_json_encoder=None):\n        if fc_args['debug.record_action_and_observation'] is False:\n            return\n\n        turn = self.civ_controller.get_turn()\n        self._recording_base_filename = os.path.join(\n            self.recording_dir, f'turn_{turn:03d}_step_{self._record_step_count:04d}')\n        with open(f'{self._recording_base_filename}_{name}.json', 'w') as f:\n            json.dump(content, f, skipkeys=True, sort_keys=True,\n                      default=default_json_encoder)\n\n    def _record_observation(self, observation):\n        self._record_to_file('state', observation, lambda x: x.get_bitvector_in_ascii()\n                             if isinstance(x, BitVector) else x.tolist())\n\n    def _record_action(self, available_actions, action):\n        self._record_to_file('available_action',\n                             available_actions, lambda x: x.encode_to_json())\n        if action:\n            self._record_to_file('chosen_action', action,\n                                 lambda x: x.encode_to_json())\n        self._record_step_count += 1\n\n    def _get_info_and_observation(self):\n        info, observation = self.civ_controller.get_info_and_observation()\n        self._record_observation(observation)\n        return info, observation\n\n    def _get_reward(self):\n        return self.civ_controller.get_reward()\n\n    def _get_terminated(self):\n        return self.civ_controller.game_has_terminated()\n\n    def _get_truncated(self):\n        return self.civ_controller.game_has_truncated()\n\n    def step(self, action):\n        self.civ_controller.perform_action(action)\n        try:\n            info, observation = self._get_info_and_observation()\n            reward = self._get_reward()\n            terminated = self._get_terminated()\n            truncated = self._get_truncated()\n\n            available_actions = info['available_actions']\n            self._record_action(available_actions, action)\n            self._take_screenshot()\n        except (ServerTimeoutException, BeginTurnTimeoutException) as server_problem:\n            fc_logger.error(repr(server_problem))\n            reward = 0\n            info = {}\n            observation = {}\n            terminated = False\n            truncated = True\n\n        except Exception as e:\n            # print(traceback.format_exc())\n            # fc_logger.error(repr(e))\n            # reward = 0\n            # info = None\n            # observation = None\n            # terminated = False\n            # truncated = True\n            raise e\n\n        return observation, reward, terminated, truncated, info\n\n    def get_port(self):\n        return self.civ_controller.client_port\n\n    def get_username(self):\n        return self.civ_controller.clstate.username\n\n    def get_playerid(self):\n        return self.civ_controller.player_ctrl.my_player_id\n\n    def reset(self, seed=None, options=None, client_port=None, **kwargs):\n        # If call reset when the env is still running, we close it first.\n        if self.running:\n            print('Close running environment before reset.')\n            self.close()\n        if client_port is None:\n            client_port = Ports.get()\n        print(f'Reset with port: {client_port}')\n        fc_logger.debug(f'Reset with port: {client_port}')\n        # self.civ_controller = CivController(username=self.username, client_port=client_port, visualize=fc_args['debug.take_screenshot'], is_minitask=self.is_minitask)\n        # self._action_space = self.civ_controller.action_space\n        # self._observation_space = self.civ_controller.observation_space\n        self.civ_controller.reset_civ_controller(client_port)\n\n        if fc_args['debug.take_screenshot']:\n            self.set_up_screenshots()\n\n        if seed is not None:\n            fc_args['debug.randomly_generate_seeds'] = False\n            fc_args['debug.mapseed'] = seed\n            fc_args['debug.agentseed'] = seed\n\n        # fc_logger.debug(f'begin_logged: {self.civ_controller.clstate.begin_logged}, turn_active: {self.civ_controller.turn_manager.turn_active}')\n        # Log in and get the first info and observation\n        self.civ_controller.init_network()\n        info, observation = self._get_info_and_observation()\n        # Log in success, set running as True\n        self.running = True\n        return observation, info\n\n    def get_game_results(self):\n        game_results = self.civ_controller.game_ctrl.game_results\n        return dict(sorted(game_results.items()))\n\n    def evaluate_game(self):\n        game_scores = self.civ_controller.request_scorelog()\n        return self.civ_controller.game_ctrl.get_game_scores(game_scores)\n\n    def plot_game_scores(self):\n        players, tags, turns, evaluations = self.evaluate_game()\n        if evaluations is None:\n            return\n\n        plot_game_scores_folder = (f\"plot_game_scores/{time.strftime('%Y-%m-%d-%H-%M-%S')}-\"\n                                   f\"{self.civ_controller.client_port}\")\n        if not os.path.exists(plot_game_scores_folder):\n            os.makedirs(plot_game_scores_folder)\n\n        player_colors = self.civ_controller.player_ctrl.get_player_colors()\n        for ptag in EVALUATION_TAGS:\n            if ptag not in evaluations:\n                continue\n\n            plt.figure()\n            for player_id in evaluations[ptag].keys():\n                scores = evaluations[ptag][player_id]\n                x_1 = players[player_id]['start_turn']\n                x_axis = range(x_1, x_1 + len(scores))\n                plt.plot(\n                    x_axis, scores, color=player_colors[player_id], label='player' + '_' + str(player_id))\n\n            plt.legend()\n            pfile = os.path.join(plot_game_scores_folder, ptag + '.png')\n            plt.savefig(pfile)\n            plt.close()\n\n    def get_final_score(self):\n        _, _, _, evaluations = self.evaluate_game()\n        score = {}\n        if evaluations != None:\n            for tag in EVALUATION_TAGS:\n                score[tag] = evaluations[tag][self.civ_controller.player_ctrl.my_player_id][-1]\n        return score\n\n    def render(self):\n        \"\"\"Render the environment based on freeciv-web.\n        \"\"\"\n        pass\n\n    def close(self):\n        # fc_logger.info(f'Env port: {self.get_port()} closes ....')\n        self.civ_controller.close()\n        self.running = False\n</code></pre>"},{"location":"api_reference/environments.html#envs.freeciv_base_env.FreecivBaseEnv.render","title":"<code>render()</code>","text":"<p>Render the environment based on freeciv-web.</p> Source code in <code>src/civrealm/envs/freeciv_base_env.py</code> <pre><code>def render(self):\n    \"\"\"Render the environment based on freeciv-web.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api_reference/environments.html#minitask-environment","title":"MiniTask Environment","text":""},{"location":"api_reference/environments.html#envs.freeciv_minitask_env.FreecivMinitaskEnv","title":"<code>envs.freeciv_minitask_env.FreecivMinitaskEnv</code>","text":"<p>             Bases: <code>FreecivBaseEnv</code></p> <p>CivRealm environment for mini-game.</p> Source code in <code>src/civrealm/envs/freeciv_minitask_env.py</code> <pre><code>class FreecivMinitaskEnv(FreecivBaseEnv):\n    \"\"\" CivRealm environment for mini-game. \"\"\"\n\n    def __init__(self, username: str = DEFAULT_TASK, client_port: int = fc_args['client_port']):\n        super().__init__(username=username, client_port=client_port, is_minitask=True)\n        fc_args['username'] = username\n        self.filename = None\n        self.task_type = None\n        fc_args['debug.autosave'] = False\n        self._last_minitask_score = None\n        self.overall_mini_score = 0\n\n    @staticmethod\n    def get_minitask(name, minitask_pattern, max_id):\n        if not isinstance(minitask_pattern, dict):\n            minitask_pattern = dict()\n\n        minitask_id = minitask_pattern.get('id', random.randint(0, max_id))\n        minitask_level = minitask_pattern.get(\n            'level', random.choice(MinitaskDifficulty.list()))\n        minitask_type = minitask_pattern.get(\n            'type', random.choice(MinitaskType.list()))\n\n        if isinstance(minitask_type, list):\n            minitask_type = random.choice(minitask_type)\n\n        if minitask_type not in MinitaskType.list():\n            raise ValueError(\n                f\"Not supported type as {minitask_pattern}. The suppported list is {MinitaskType.list()}!\")\n        if minitask_id &gt; max_id or minitask_id &lt; 0:\n            raise ValueError(\n                f\"Not supported id as {minitask_id}. The suppported range is [0, {max_id}]!\")\n        if minitask_level not in MinitaskDifficulty.list():\n            raise ValueError(\n                f\"Not supported diffculty as {minitask_level}. The suppported list is {MinitaskDifficulty.list()}!\")\n\n        minitask = '{}_T1_task_{}_level_{}_id_{}'.format(\n            name, minitask_type, minitask_level, minitask_id)\n        set_logging_file('minitask', minitask)\n        fc_logger.warning(f\"Randomly selected minitask {minitask}!\")\n        return minitask\n\n    def _get_info_and_observation(self):\n        info, observation = super()._get_info_and_observation()\n        if 'player' in info['available_actions'] and self.task_type in BATTLE_MINITASK_LIST:\n            del info['available_actions']['player']\n        return info, observation\n\n    def _set_minitask_info(self, info):\n        info['minitask'] = {\n            'status': self._get_game_status(),\n            'success': self._get_success(),\n        }\n        info['minitask'].update(self._get_detail())\n        return\n\n    def reset(self, seed=None, options=None, minitask_pattern=None, max_id=MAX_ID):\n        \"\"\"\n        Reset the mini-game environment as fully random game or specific game.\n\n        Parameters\n        ----------\n        seed : int\n            Random seed for game.\n        options : dict\n            Env configuration.\n        minitask_pattern : dict\n            Assignment the following fields to return a specified game:\\n\n            `type`: the type of mini-game, see the available options MinitaskType;\\n\n            `level`: the difficulty of mini-game, see the available options MinitaskDifficulty;\\n\n            `id`: the id of mini-game, the available range is 0 to MAX_ID.\\n\n            If a field is not assigned a value, the field will be randomly selected within the feasible domain.\n        max_id : int\n            The max id of mini-game.\n        \"\"\"\n        self.overall_mini_score = 0\n        self.set_minitask(seed, minitask_pattern, max_id)\n        observations, info = super().reset(seed, options)\n        self._set_minitask_info(info)\n        self._last_minitask_score = None\n        return observations, info\n\n    def set_minitask(self, seed, minitask_pattern, max_id):\n        random.seed(seed)\n        minitask = self.get_minitask(\n            fc_args['username'], minitask_pattern, max_id)\n        self.filename = minitask\n        self.task_type = re.match(\n            r\"{}_T\\d+_task_([a-z]+)_.*\".format(fc_args['username']), minitask)[1]\n        self.civ_controller.set_parameter('debug.load_game', minitask)\n        return\n\n    def minitask_has_terminated(self):\n        \"\"\"\n        In addition to the game termination judgment of the full game, \n        the mini-game has additional conditions for the end of the game process.\n        \"\"\"\n        minitask_info = self.civ_controller.get_turn_message()\n        if any([msg.get(\"status\") == MinitaskGameStatus.MGS_END_GAME.value for msg in minitask_info]):\n            return True\n        return False\n\n    def _get_terminated(self):\n        return self.civ_controller.game_has_terminated() or self.minitask_has_terminated()\n\n    def _get_step_msg(self, key):\n        minitask_results = self.civ_controller.get_turn_message()\n        for msg in minitask_results[::-1]:\n            if key in msg:\n                if key == 'metrics':\n                    return msg[key][-1]\n                return msg[key]\n        return\n\n    def _get_reward(self):\n        metrics = self._get_step_msg('metrics')\n        current_score = 0.0\n        if metrics is None:\n            return current_score\n        if self._last_minitask_score is None:\n            self._last_minitask_score = metrics['mini_score']\n        current_score = metrics['mini_score'] - self._last_minitask_score\n        self._last_minitask_score = metrics['mini_score']\n        self.overall_mini_score = metrics['mini_score']\n        return current_score\n\n    def _get_game_status(self):\n        status = self._get_step_msg('status')\n        if status is None:\n            return MinitaskGameStatus.MGS_IN_GAME.value\n        return status\n\n    def _get_success(self):\n        metrics = self._get_step_msg('metrics')\n        if metrics is None:\n            return MinitaskPlayerStatus.MPS_UNKNOWN.value\n        return metrics.get('is_mini_success')\n\n    def _get_detail(self):\n        metrics = self._get_step_msg('metrics')\n        if metrics is None:\n            return dict()\n        return metrics\n\n    def step(self, action):\n        fc_logger.debug(f\"mini-env step action: {action}\")\n        observation, reward, terminated, truncated, info = super().step(action)\n        self._set_minitask_info(info)\n        return observation, reward, terminated, truncated, info\n\n    def get_game_results(self):\n        game_results = self.civ_controller.game_ctrl.game_results\n        minitask_results = self.civ_controller.get_turn_message()\n        results = dict(sorted(game_results.items()))\n        results.update({\"minitask_sav\": self.filename})\n        results.update({\"minitask_type\": self.task_type})\n        results.update(dict(minitask=minitask_results))\n        return results\n\n    def get_final_score(self):\n        score = {}\n        score['mini_score'] = self.overall_mini_score\n        return score\n</code></pre>"},{"location":"api_reference/environments.html#envs.freeciv_minitask_env.FreecivMinitaskEnv.minitask_has_terminated","title":"<code>minitask_has_terminated()</code>","text":"<p>In addition to the game termination judgment of the full game,  the mini-game has additional conditions for the end of the game process.</p> Source code in <code>src/civrealm/envs/freeciv_minitask_env.py</code> <pre><code>def minitask_has_terminated(self):\n    \"\"\"\n    In addition to the game termination judgment of the full game, \n    the mini-game has additional conditions for the end of the game process.\n    \"\"\"\n    minitask_info = self.civ_controller.get_turn_message()\n    if any([msg.get(\"status\") == MinitaskGameStatus.MGS_END_GAME.value for msg in minitask_info]):\n        return True\n    return False\n</code></pre>"},{"location":"api_reference/environments.html#envs.freeciv_minitask_env.FreecivMinitaskEnv.reset","title":"<code>reset(seed=None, options=None, minitask_pattern=None, max_id=MAX_ID)</code>","text":"<p>Reset the mini-game environment as fully random game or specific game.</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>int</code> <p>Random seed for game.</p> <code>None</code> <code>options</code> <code>dict</code> <p>Env configuration.</p> <code>None</code> <code>minitask_pattern</code> <code>dict</code> <p>Assignment the following fields to return a specified game:</p> <p><code>type</code>: the type of mini-game, see the available options MinitaskType;</p> <p><code>level</code>: the difficulty of mini-game, see the available options MinitaskDifficulty;</p> <p><code>id</code>: the id of mini-game, the available range is 0 to MAX_ID.</p> <p>If a field is not assigned a value, the field will be randomly selected within the feasible domain.</p> <code>None</code> <code>max_id</code> <code>int</code> <p>The max id of mini-game.</p> <code>MAX_ID</code> Source code in <code>src/civrealm/envs/freeciv_minitask_env.py</code> <pre><code>def reset(self, seed=None, options=None, minitask_pattern=None, max_id=MAX_ID):\n    \"\"\"\n    Reset the mini-game environment as fully random game or specific game.\n\n    Parameters\n    ----------\n    seed : int\n        Random seed for game.\n    options : dict\n        Env configuration.\n    minitask_pattern : dict\n        Assignment the following fields to return a specified game:\\n\n        `type`: the type of mini-game, see the available options MinitaskType;\\n\n        `level`: the difficulty of mini-game, see the available options MinitaskDifficulty;\\n\n        `id`: the id of mini-game, the available range is 0 to MAX_ID.\\n\n        If a field is not assigned a value, the field will be randomly selected within the feasible domain.\n    max_id : int\n        The max id of mini-game.\n    \"\"\"\n    self.overall_mini_score = 0\n    self.set_minitask(seed, minitask_pattern, max_id)\n    observations, info = super().reset(seed, options)\n    self._set_minitask_info(info)\n    self._last_minitask_score = None\n    return observations, info\n</code></pre>"},{"location":"api_reference/environments.html#tensor-environment","title":"Tensor Environment","text":""},{"location":"api_reference/environments.html#envs.freeciv_tensor_env.FreecivTensorEnv","title":"<code>envs.freeciv_tensor_env.FreecivTensorEnv</code>","text":"<p>             Bases: <code>Wrapper</code></p> <p>CivRealm environment with Tensor actions</p> Source code in <code>src/civrealm/envs/freeciv_tensor_env.py</code> <pre><code>class FreecivTensorEnv(Wrapper):\n    \"\"\"CivRealm environment with Tensor actions\"\"\"\n\n    metadata = FreecivBaseEnv.metadata\n\n    def __init__(\n        self,\n        username: str = fc_args[\"username\"],\n        client_port: int = fc_args[\"client_port\"],\n        config: dict = default_tensor_config,\n    ):\n        tensor_env = GameOverScoreInfo(\n            TensorWrapper(\n                env=PenalizeConsecutiveTurnDoneReward(\n                    FreecivBaseEnv(username=username, client_port=client_port),\n                    penalty=-1,\n                ),\n                config=config,\n            )\n        )\n        super().__init__(tensor_env)\n        self._cached_reset_result = super().reset()\n        # reset during init to get valid obs space\n        self.first_reset = True\n\n    def reset(self, **kwargs):\n        if self.first_reset and len(kwargs) == 0:\n            # use cached reset during init for first reset\n            obs, info = self._cached_reset_result\n            self.first_reset = False\n            return obs, info\n        return super().reset(**kwargs)\n</code></pre>"},{"location":"api_reference/environments.html#llm-environment","title":"LLM Environment","text":""},{"location":"api_reference/environments.html#envs.freeciv_llm_env.FreecivLLMEnv","title":"<code>envs.freeciv_llm_env.FreecivLLMEnv</code>","text":"<p>             Bases: <code>Wrapper</code></p> <p>CivRealm environment with llm actions</p> Source code in <code>src/civrealm/envs/freeciv_llm_env.py</code> <pre><code>class FreecivLLMEnv(Wrapper):\n    \"\"\"CivRealm environment with llm actions\"\"\"\n\n    metadata = FreecivBaseEnv.metadata\n\n    def __init__(self,\n                 username: str = fc_args[\"username\"],\n                 client_port: int = fc_args[\"client_port\"]):\n\n        llm_env = LLMWrapper(FreecivBaseEnv(\n            username=username, client_port=client_port))\n        super().__init__(llm_env)\n\n    def reset(self, **kwargs):\n        return self.env.reset(**kwargs)\n</code></pre>"},{"location":"api_reference/observations.html","title":"Observation Space","text":"<p>The Gymnasium definition for the observation space. At the root is a <code>Dict</code> space with the following keys: <code>['game', 'rules', 'map', 'player', 'city', 'tech', 'unit', 'options', 'dipl', 'gov', 'client']</code>. We describe the important state spaces below.</p> <p>Click on the source code below to show the space definition.</p>"},{"location":"api_reference/observations.html#map-state","title":"Map State","text":"Source code in <code>src/civrealm/freeciv/map/map_state.py</code> <pre><code>def get_observation_space(self):\n    map_shape = self._state['status'].shape\n    self._observation_space = gymnasium.spaces.Dict({\n        'status': gymnasium.spaces.Box(\n            low=0, high=2, shape=map_shape, dtype=np.uint8),\n        'terrain': gymnasium.spaces.Box(\n            low=0, high=len(self.rule_ctrl.terrains) - 1,\n            shape=map_shape, dtype=np.uint8),\n        'extras': gymnasium.spaces.Box(\n            low=0, high=1, shape=(*map_shape, self._extra_num),\n            dtype=np.uint8),\n        'output': gymnasium.spaces.Box(\n            low=0, high=255, shape=(*map_shape, 6),\n            dtype=np.uint8),\n        'tile_owner': gymnasium.spaces.Box(\n            low=0, high=255, shape=map_shape, dtype=np.uint8),\n        'city_owner': gymnasium.spaces.Box(\n            low=0, high=255, shape=map_shape, dtype=np.uint8),\n        'unit': gymnasium.spaces.Box(\n            low=0, high=255, shape=(*map_shape, self._unit_type_num),\n            dtype=np.uint8),\n        'unit_owner': gymnasium.spaces.Box(\n            low=0, high=255, shape=map_shape, dtype=np.uint8), })\n    return self._observation_space\n</code></pre>"},{"location":"api_reference/observations.html#city-state","title":"City State","text":"Source code in <code>src/civrealm/freeciv/city/city_state.py</code> <pre><code>def get_observation_space(self):\n    city_space = gymnasium.spaces.Dict({\n        # Common city fields\n        'id': gymnasium.spaces.Box(low=-1, high=32767, shape=(1,), dtype=np.int16),\n        'owner': gymnasium.spaces.Box(low=0, high=255, shape=(1,), dtype=np.uint8),\n        'size': gymnasium.spaces.Box(low=0, high=255, shape=(1,), dtype=np.uint8),\n        # TODO: may change this to actual map size\n        'x': gymnasium.spaces.Box(low=0, high=255, shape=(1,), dtype=np.uint8),\n        'y': gymnasium.spaces.Box(low=0, high=255, shape=(1,), dtype=np.uint8),\n        'name': gymnasium.spaces.Text(max_length=100),\n\n        # My city fields\n        'food_stock': gymnasium.spaces.Box(low=-1, high=32767, shape=(1,), dtype=np.int16),\n        'granary_size': gymnasium.spaces.Box(low=-1, high=32767, shape=(1,), dtype=np.int16),\n        'granary_turns': gymnasium.spaces.Box(low=-32768, high=32767, shape=(1,), dtype=np.int16),\n        'production_kind': gymnasium.spaces.Box(low=-1, high=127, shape=(1,), dtype=np.int8),\n        'production_value': gymnasium.spaces.Box(low=-1, high=127, shape=(1,), dtype=np.int8),\n        'city_radius_sq': gymnasium.spaces.Box(low=-1, high=127, shape=(1,), dtype=np.int8),\n        'buy_cost': gymnasium.spaces.Box(low=-1, high=32767, shape=(1,), dtype=np.int16),\n        'shield_stock': gymnasium.spaces.Box(low=-1, high=32767, shape=(1,), dtype=np.int16),\n        'disbanded_shields': gymnasium.spaces.Box(low=-1, high=32767, shape=(1,), dtype=np.int16),\n        'caravan_shields': gymnasium.spaces.Box(low=-1, high=32767, shape=(1,), dtype=np.int16),\n        'last_turns_shield_surplus': gymnasium.spaces.Box(low=-32768, high=32767, shape=(1,), dtype=np.int16),\n        'luxury': gymnasium.spaces.Box(low=-1, high=32767, shape=(1,), dtype=np.int16),\n        'science': gymnasium.spaces.Box(low=-1, high=32767, shape=(1,), dtype=np.int16),\n        'prod_food': gymnasium.spaces.Box(low=-1, high=32767, shape=(1,), dtype=np.int16),\n        'surplus_food': gymnasium.spaces.Box(low=-32768, high=32767, shape=(1,), dtype=np.int16),\n        'prod_gold': gymnasium.spaces.Box(low=-1, high=32767, shape=(1,), dtype=np.int16),\n        'surplus_gold': gymnasium.spaces.Box(low=-32768, high=32767, shape=(1,), dtype=np.int16),\n        'prod_shield': gymnasium.spaces.Box(low=-1, high=32767, shape=(1,), dtype=np.int16),\n        'surplus_shield': gymnasium.spaces.Box(low=-32768, high=32767, shape=(1,), dtype=np.int16),\n        'prod_trade': gymnasium.spaces.Box(low=-1, high=32767, shape=(1,), dtype=np.int16),\n        'surplus_trade': gymnasium.spaces.Box(low=-32768, high=32767, shape=(1,), dtype=np.int16),\n        'bulbs': gymnasium.spaces.Box(low=-1, high=32767, shape=(1,), dtype=np.int16),\n        'city_waste': gymnasium.spaces.Box(low=-1, high=32767, shape=(1,), dtype=np.int16),\n        'city_corruption': gymnasium.spaces.Box(low=-1, high=32767, shape=(1,), dtype=np.int16),\n        'city_pollution': gymnasium.spaces.Box(low=-1, high=32767, shape=(1,), dtype=np.int16),\n        # -1: None, 1: Disorder, 2: Peace, 3: Celebrating\n        'state': gymnasium.spaces.Box(low=-1, high=3, shape=(1,), dtype=np.int8),\n        'growth_in': gymnasium.spaces.Text(max_length=100),\n        'turns_to_prod_complete': gymnasium.spaces.Box(low=-32768, high=32767, shape=(1,), dtype=np.int16),\n        'prod_process': gymnasium.spaces.Box(low=-32768, high=32767, shape=(1,), dtype=np.int16),\n        'ppl_angry': gymnasium.spaces.Box(low=-1, high=127, shape=(1,), dtype=np.int8),\n        'ppl_unhappy': gymnasium.spaces.Box(low=-1, high=127, shape=(1,), dtype=np.int8),\n        'ppl_content': gymnasium.spaces.Box(low=-1, high=127, shape=(1,), dtype=np.int8),\n        'ppl_happy': gymnasium.spaces.Box(low=-1, high=127, shape=(1,), dtype=np.int8),\n        # Boolean vector\n        'can_build_unit': gymnasium.spaces.Box(low=0, high=1, shape=(self.rule_ctrl.ruleset_control['num_unit_types'],), dtype=np.int8),\n        # Boolean vector\n        'improvements': gymnasium.spaces.Box(low=0, high=1, shape=(self.rule_ctrl.ruleset_control['num_impr_types'],), dtype=np.int8),\n        'turn_last_built': gymnasium.spaces.Box(low=1, high=32767, shape=(1,), dtype=np.int16),\n    })\n\n    return gymnasium.spaces.Dict({city_id: city_space for city_id in self.city_dict.keys()})\n</code></pre>"},{"location":"api_reference/observations.html#unit-state","title":"Unit State","text":"Source code in <code>src/civrealm/freeciv/units/unit_state.py</code> <pre><code>def get_observation_space(self):\n    unit_space = gymnasium.spaces.Dict({\n        # Common unit fields\n        'owner': gymnasium.spaces.Box(low=0, high=255, shape=(1,), dtype=np.uint8),\n        'health': gymnasium.spaces.Box(low=0, high=100, shape=(1,), dtype=np.uint8),\n        'veteran': gymnasium.spaces.Box(low=0, high=1, shape=(1,), dtype=np.uint8),\n        # TODO: may change this to actual map size\n        'x': gymnasium.spaces.Box(low=0, high=255, shape=(1,), dtype=np.uint8),\n        'y': gymnasium.spaces.Box(low=0, high=255, shape=(1,), dtype=np.uint8),\n\n        # Unit type fields\n        'type_rule_name': gymnasium.spaces.Box(low=0, high=len(self.rule_ctrl.unit_types)-1, shape=(1,), dtype=np.uint8),\n        'type_attack_strength': gymnasium.spaces.Box(low=0, high=65535, shape=(1,), dtype=np.uint16),\n        'type_defense_strength': gymnasium.spaces.Box(low=0, high=65535, shape=(1,), dtype=np.uint16),\n        'type_firepower': gymnasium.spaces.Box(low=0, high=65535, shape=(1,), dtype=np.uint16),\n        'type_build_cost': gymnasium.spaces.Box(low=0, high=65535, shape=(1,), dtype=np.uint16),\n        'type_convert_time': gymnasium.spaces.Box(low=0, high=65535, shape=(1,), dtype=np.uint16),\n        'type_converted_to': gymnasium.spaces.Box(low=0, high=len(self.rule_ctrl.unit_types)-1, shape=(1,), dtype=np.uint8),\n        'type_obsoleted_by': gymnasium.spaces.Box(low=0, high=len(self.rule_ctrl.unit_types)-1, shape=(1,), dtype=np.uint8),\n        'type_hp': gymnasium.spaces.Box(low=0, high=65535, shape=(1,), dtype=np.uint16),\n        'type_move_rate': gymnasium.spaces.Box(low=0, high=65535, shape=(1,), dtype=np.uint16),\n        'type_vision_radius_sq': gymnasium.spaces.Box(low=0, high=65535, shape=(1,), dtype=np.uint16),\n        'type_worker': gymnasium.spaces.Discrete(1),  # Boolean\n        'type_can_transport': gymnasium.spaces.Discrete(1),  # Boolean\n\n        # My unit specific fields\n        'home_city': gymnasium.spaces.Box(low=-1, high=len(self.city_ctrl.cities)-1, shape=(1,), dtype=np.int16),\n        'moves_left': gymnasium.spaces.Box(low=-1, high=32767, shape=(1,), dtype=np.int16),\n        'upkeep_food': gymnasium.spaces.Box(low=-1, high=32767, shape=(1,), dtype=np.int16),\n        'upkeep_shield': gymnasium.spaces.Box(low=-1, high=32767, shape=(1,), dtype=np.int16),\n        'upkeep_gold': gymnasium.spaces.Box(low=-1, high=32767, shape=(1,), dtype=np.int16),\n    })\n\n    return gymnasium.spaces.Dict({unit_id: unit_space for unit_id in self.unit_ctrl.units.keys()})\n</code></pre>"},{"location":"api_reference/observations.html#tech-state","title":"Tech State","text":"<p>Get observation space.</p> <p>Returns:</p> Type Description <code>gymnasium.space.Dict(</code> <p>\"tech_status\": Box, \"current_tech\": Box</p> <code>)</code> <code>\"tech_status\": Box of shape (reqtree_size,)</code> <p>list status of all techs, with values of each entry: -1: obtained,  0: under research,  1: can be researched,  2: need other prerequest tech(s),</p> <code>\"current_tech\": Box(tech_id: Int, current_bulbs_on_it: Int)</code> Source code in <code>src/civrealm/freeciv/tech/tech_state.py</code> <pre><code>def get_observation_space(self) -&gt; Dict:\n    \"\"\"\n    Get observation space.\n\n    Returns\n    -------\n    gymnasium.space.Dict(\n        \"tech_status\": Box,\n        \"current_tech\": Box\n    )\n    \"tech_status\": Box of shape (reqtree_size,)\n                   list status of all techs, with values of each entry:\n                   -1: obtained,\n                    0: under research,\n                    1: can be researched,\n                    2: need other prerequest tech(s),\n    \"current_tech\": Box(tech_id: Int, current_bulbs_on_it: Int)\n    \"\"\"\n    return Dict({\n        \"tech_status\":\n        Box(np.ones(self.reqtree_size) * (-1),\n            np.ones(self.reqtree_size) * self.UPPER_TECH_STATUS,\n            dtype=int),\n        \"current_tech\":\n        Tuple(Discrete(self.reqtree_size), Discrete(self.UPPER_BULB_BOUND),\n              Box(0, self.UPPER_BULB_BOUND, dtype=float))\n    })\n</code></pre>"},{"location":"api_reference/observations.html#player-state","title":"Player State","text":"Source code in <code>src/civrealm/freeciv/players/player_state.py</code> <pre><code>def get_observation_space(self):\n    player_space = gymnasium.spaces.Dict({\n        **{\n            # Common player fields\n            'player_id': gymnasium.spaces.Box(low=0, high=255, shape=(1,), dtype=int),\n            'name': gymnasium.spaces.Text(max_length=100),\n            'score': gymnasium.spaces.Box(low=-1, high=65535, shape=(1,), dtype=int),\n            'team': gymnasium.spaces.Box(low=0, high=255, shape=(1,), dtype=int),\n            'is_alive': gymnasium.spaces.Discrete(2),  # Boolean\n            'nation': gymnasium.spaces.Box(low=0, high=list(self.rule_ctrl.nations.keys())[-1], shape=(1,), dtype=int),\n            'turns_alive': gymnasium.spaces.Box(low=0, high=65535, shape=(1,), dtype=int),\n            'government': gymnasium.spaces.Box(low=0, high=len(self.rule_ctrl.governments)-1, shape=(1,), dtype=int),\n            'target_government': gymnasium.spaces.Box(low=0, high=len(self.rule_ctrl.governments)-1, shape=(1,), dtype=int),\n            'government_name': gymnasium.spaces.Text(max_length=100),\n            'researching': gymnasium.spaces.Box(low=0, high=len(self.rule_ctrl.techs)-1, shape=(1,), dtype=int),\n            'research_name': gymnasium.spaces.Text(max_length=100),\n            # Tax, science, luxury are percentages, should sum to 100\n            'tax': gymnasium.spaces.Box(low=0, high=100, shape=(1,), dtype=int),\n            'science': gymnasium.spaces.Box(low=0, high=100, shape=(1,), dtype=int),\n            'luxury': gymnasium.spaces.Box(low=0, high=100, shape=(1,), dtype=int),\n\n            # My player fields\n            'gold': gymnasium.spaces.Box(low=0, high=65535, shape=(1,), dtype=int),\n            'culture': gymnasium.spaces.Box(low=0, high=65535, shape=(1,), dtype=int),\n            # mood_type, values are MOOD_PEACEFUL and MOOD_COMBAT\n            'mood': gymnasium.spaces.Discrete(2),\n            # The turn when the revolution finishes\n            'revolution_finishes': gymnasium.spaces.Box(low=-1, high=65535, shape=(1,), dtype=int),\n            'science_cost': gymnasium.spaces.Box(low=0, high=65535, shape=(1,), dtype=int),\n            'bulbs_researched': gymnasium.spaces.Box(low=0, high=65535, shape=(1,), dtype=int),\n            'researching_cost': gymnasium.spaces.Box(low=0, high=65535, shape=(1,), dtype=int),\n            'tech_goal': gymnasium.spaces.Box(low=0, high=len(self.rule_ctrl.techs)-1, shape=(1,), dtype=int),\n            'tech_upkeep': gymnasium.spaces.Box(low=0, high=65535, shape=(1,), dtype=int),\n            'techs_researched': gymnasium.spaces.Box(low=0, high=len(self.rule_ctrl.techs)-1, shape=(1,), dtype=int),\n            'total_bulbs_prod': gymnasium.spaces.Box(low=0, high=65535, shape=(1,), dtype=int),\n            'embassy_txt': gymnasium.spaces.Text(max_length=100),\n\n            # Other player fields\n            # Possible values are player_const.ATTITUDE_TXT\n            'love': gymnasium.spaces.Text(max_length=100),\n        },\n        **{\n            f'tech_{tech_id}': gymnasium.spaces.Discrete(2) for tech_id in self.rule_ctrl.techs.keys()\n        }\n    })\n\n    return gymnasium.spaces.Dict({player_id: player_space for player_id in self.player_ctrl.players.keys()})\n</code></pre>"},{"location":"api_reference/observations.html#diplomatic-state","title":"Diplomatic state","text":"Source code in <code>src/civrealm/freeciv/players/diplomacy_state_ctrl.py</code> <pre><code>def get_observation_space(self):\n    diplomacy_space = gymnasium.spaces.Dict({\n        'diplomatic_state': gymnasium.spaces.Discrete(player_const.DS_LAST),\n        # TODO: to be specified\n        'diplomacy_clause_map': gymnasium.spaces.Sequence(gymnasium.spaces.Dict()),\n        'meeting_initializers': gymnasium.spaces.Discrete(255),\n    })\n    return gymnasium.spaces.Dict({player_id: diplomacy_space for player_id in self.diplomatic_state.keys()})\n</code></pre>"},{"location":"api_reference/wrappers.html","title":"Wrappers","text":""},{"location":"api_reference/wrappers.html#envs.freeciv_wrapper.tensor_wrapper.TensorWrapper","title":"<code>envs.freeciv_wrapper.tensor_wrapper.TensorWrapper</code>","text":"<p>             Bases: <code>Wrapper</code></p> <p>TensorWrapper is used to make Civrealm environment tensorized by converting observations from FreecivBaseEnv into tensors and tensor actions back to actions compatible with FreecivBaseEnv.</p> <p>TensorWrapper is composed <code>TensorBase</code>, <code>TensorAction</code>, <code>TensorObservation</code> and <code>CacheLastObs</code>.</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>FreecivBaseEnv</code> required <code>config</code> <code>dict</code> <p>tensor env configuration</p> <code>default_tensor_config</code> <p>Attributes:</p> Name Type Description <code>config</code> <code>dict</code> <p>tensor wrapper configuration</p> Source code in <code>src/civrealm/envs/freeciv_wrapper/tensor_wrapper.py</code> <pre><code>class TensorWrapper(Wrapper):\n    \"\"\"\n    TensorWrapper is used to make Civrealm environment tensorized by converting\n    observations from FreecivBaseEnv into tensors and tensor actions back to actions compatible with\n    FreecivBaseEnv.\n\n    TensorWrapper is composed `TensorBase`, `TensorAction`, `TensorObservation`\n    and `CacheLastObs`.\n\n    Parameters\n    ----------\n    env\n    config:\n        tensor env configuration\n\n    Attributes\n    ----------\n    config: dict\n        tensor wrapper configuration\n\n    \"\"\"\n\n    def __init__(self, env: FreecivBaseEnv, config: dict = default_tensor_config):\n        self.config = config\n        super().__init__(\n            CacheLastObs(\n                TensorObservation(TensorAction(TensorBase(env, config=config)))\n            )\n        )\n</code></pre>"},{"location":"api_reference/wrappers.html#envs.freeciv_wrapper.tensor_wrapper.TensorBase","title":"<code>envs.freeciv_wrapper.tensor_wrapper.TensorBase</code>","text":"<p>             Bases: <code>Wrapper</code></p> <p>A basic wrapper that deals with config loading and entity id recording,  required by all tensor-related wrappers.</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>FreecivBaseEnv</code> required <code>config</code> <code>dict</code> <p>tensor env configuration</p> <code>default_tensor_config</code> <p>Attributes:</p> Name Type Description <code>config</code> <code>dict</code> <p>A dict that specifies all configurations related to tensor wrapper.</p> <code>my_player_id</code> <code>int</code> <p>My player id.</p> <code>unit_ids</code> <code>list</code> <p>A sorted list of my unit ids.</p> <code>city_ids</code> <code>list</code> <p>A sorted list of my city ids.</p> <code>others_unit_ids</code> <code>list</code> <p>A sorted list of others unit ids.</p> <code>others_city_ids</code> <code>list</code> <p>A sorted list of others city ids.</p> <code>dipl_ids</code> <code>list</code> <p>A list of others player ids.</p> <code>units</code> <code>dict</code> <p>ruleset information about units.</p> <code>unit_types</code> <code>list</code> <p>A list of all unit types.</p> <code>unit_costs</code> <code>list</code> <p>A list of int indicating unit costs.</p> <code>improvements</code> <code>dict</code> <p>Ruleset information about city improvements.</p> <code>impr_costs</code> <code>list</code> <p>A list of int indicating city improvements costs.</p> Source code in <code>src/civrealm/envs/freeciv_wrapper/tensor_base_wrapper.py</code> <pre><code>class TensorBase(Wrapper):\n    \"\"\"\n    A basic wrapper that deals with config loading and entity id recording, \n    required by all tensor-related wrappers.\n\n\n    Parameters\n    ----------\n    env: FreecivBaseEnv\n    config: dict\n        tensor env configuration\n\n    Attributes\n    ---------\n    config: dict\n        A dict that specifies all configurations related to tensor wrapper.\n    my_player_id: int\n        My player id.\n    unit_ids: list\n        A sorted list of my unit ids.\n    city_ids: list\n        A sorted list of my city ids.\n    others_unit_ids: list\n        A sorted list of others unit ids.\n    others_city_ids: list\n        A sorted list of others city ids.\n    dipl_ids : list\n        A list of others player ids.\n    units : dict\n        ruleset information about units.\n    unit_types :list\n        A list of all unit types.\n    unit_costs : list\n        A list of int indicating unit costs.\n    improvements : dict\n        Ruleset information about city improvements.\n    impr_costs :list\n        A list of int indicating city improvements costs.\n\n    \"\"\"\n\n    def __init__(self, env: FreecivBaseEnv, config: dict = default_tensor_config):\n        self.config = config\n        self.my_player_id = -1\n\n        # mutable ids\n        self.unit_ids = []\n        self.city_ids = []\n        self.others_unit_ids = []\n        self.others_city_ids = []\n        self.dipl_ids = []\n\n        # ruleset\n        self.units = {}\n        self.unit_types = []\n        self.unit_costs = []\n        self.improvements = {}\n        self.impr_costs = []\n\n        super().__init__(env)\n\n    def update_sequence_ids(self, observation):\n        \"\"\"\n        Use city, unit and dipl information in observation to update ids.\n        \"\"\"\n        self.unit_ids = sorted(\n            list(\n                k\n                for k in observation.get(\"unit\", {}).keys()\n                if observation[\"unit\"][k][\"owner\"] == self.my_player_id\n            )\n        )\n        self.others_unit_ids = sorted(\n            list(\n                k\n                for k in observation.get(\"unit\", {}).keys()\n                if observation[\"unit\"][k][\"owner\"] != self.my_player_id\n            )\n        )\n        self.city_ids = sorted(\n            list(\n                k\n                for k in observation.get(\"city\", {}).keys()\n                if observation[\"city\"][k][\"owner\"] == self.my_player_id\n            )\n        )\n        self.others_city_ids = sorted(\n            list(\n                k\n                for k in observation.get(\"city\", {}).keys()\n                if observation[\"city\"][k][\"owner\"] != self.my_player_id\n            )\n        )\n        self.dipl_ids = [\n            player\n            for player in sorted(observation.get(\"dipl\", {}).keys())\n            if player != self.my_player_id\n        ]\n\n    def update_config(self):\n        \"\"\"\n        Update config using ruleset information at the start of the turn.\n        \"\"\"\n        self.units = self.unwrapped.civ_controller.rule_ctrl.unit_types\n        self.unit_types = [self.units[i][\"name\"]\n                           for i in range(len(self.units))]\n        self.unit_costs = [self.units[i][\"build_cost\"]\n                           for i in range(len(self.units))]\n        self.improvements = self.unwrapped.civ_controller.rule_ctrl.improvements\n        self.impr_costs = [\n            self.improvements[i][\"build_cost\"] for i in range(len(self.improvements))\n        ]\n        self.config[\"obs_ops\"][\"unit\"][\"type_rule_name\"] = onehotifier_maker(\n            self.unit_types\n        )\n        self.config[\"obs_ops\"][\"rules\"][\"build_cost\"] = lambda _: np.array(\n            self.unit_costs + self.impr_costs\n        )\n\n    def reset(self, *args, **kwargs):\n        obs, info = self.env.reset(*args, **kwargs)\n        self.my_player_id = self.unwrapped.civ_controller.player_ctrl.my_player_id\n\n        self.update_config()\n        self.update_sequence_ids(obs)\n        return obs, info\n\n    def step(self, *args, **kwargs):\n        obs, reward, terminated, truncated, info = self.env.step(\n            *args, **kwargs)\n        self.update_sequence_ids(obs)\n        return obs, reward, terminated, truncated, info\n</code></pre>"},{"location":"api_reference/wrappers.html#envs.freeciv_wrapper.tensor_wrapper.TensorBase.update_config","title":"<code>update_config()</code>","text":"<p>Update config using ruleset information at the start of the turn.</p> Source code in <code>src/civrealm/envs/freeciv_wrapper/tensor_base_wrapper.py</code> <pre><code>def update_config(self):\n    \"\"\"\n    Update config using ruleset information at the start of the turn.\n    \"\"\"\n    self.units = self.unwrapped.civ_controller.rule_ctrl.unit_types\n    self.unit_types = [self.units[i][\"name\"]\n                       for i in range(len(self.units))]\n    self.unit_costs = [self.units[i][\"build_cost\"]\n                       for i in range(len(self.units))]\n    self.improvements = self.unwrapped.civ_controller.rule_ctrl.improvements\n    self.impr_costs = [\n        self.improvements[i][\"build_cost\"] for i in range(len(self.improvements))\n    ]\n    self.config[\"obs_ops\"][\"unit\"][\"type_rule_name\"] = onehotifier_maker(\n        self.unit_types\n    )\n    self.config[\"obs_ops\"][\"rules\"][\"build_cost\"] = lambda _: np.array(\n        self.unit_costs + self.impr_costs\n    )\n</code></pre>"},{"location":"api_reference/wrappers.html#envs.freeciv_wrapper.tensor_wrapper.TensorBase.update_sequence_ids","title":"<code>update_sequence_ids(observation)</code>","text":"<p>Use city, unit and dipl information in observation to update ids.</p> Source code in <code>src/civrealm/envs/freeciv_wrapper/tensor_base_wrapper.py</code> <pre><code>def update_sequence_ids(self, observation):\n    \"\"\"\n    Use city, unit and dipl information in observation to update ids.\n    \"\"\"\n    self.unit_ids = sorted(\n        list(\n            k\n            for k in observation.get(\"unit\", {}).keys()\n            if observation[\"unit\"][k][\"owner\"] == self.my_player_id\n        )\n    )\n    self.others_unit_ids = sorted(\n        list(\n            k\n            for k in observation.get(\"unit\", {}).keys()\n            if observation[\"unit\"][k][\"owner\"] != self.my_player_id\n        )\n    )\n    self.city_ids = sorted(\n        list(\n            k\n            for k in observation.get(\"city\", {}).keys()\n            if observation[\"city\"][k][\"owner\"] == self.my_player_id\n        )\n    )\n    self.others_city_ids = sorted(\n        list(\n            k\n            for k in observation.get(\"city\", {}).keys()\n            if observation[\"city\"][k][\"owner\"] != self.my_player_id\n        )\n    )\n    self.dipl_ids = [\n        player\n        for player in sorted(observation.get(\"dipl\", {}).keys())\n        if player != self.my_player_id\n    ]\n</code></pre>"},{"location":"api_reference/wrappers.html#envs.freeciv_wrapper.action_wrapper.TensorAction","title":"<code>envs.freeciv_wrapper.action_wrapper.TensorAction</code>","text":"<p>             Bases: <code>Wrapper</code></p> <p>A wrapper that defines tensor action spaces,  transforms tensor actions into actions that could be handeled by FreecivBaseEnv instance, and adds masks to observations.</p> <p>TensorAction wrapper is composed of five wrappers, including <code>TruncateDiplCity</code>, <code>DiplomacyLoop</code>, <code>CombineTechResearchGoal</code>, <code>PersistentCityProduction</code>, and <code>EmbarkWrapper</code>.</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>TensorBase</code> <p>A FreecivBaseEnv instance that has been wrapped by TensorBase.</p> required <p>Attributes:</p> Name Type Description <code>aciton_config</code> <code>dict</code> <p>a dict that configs that specify sizes of mutable entities and action layout.</p> <code>mask</code> <code>dict</code> <p>a dict of masks of type numpy ndarray indicating available actions and entities. 0-&gt; unavilalbe, 1-&gt;availble.</p> <code>available_actions</code> <code>dict</code> <p>cached info['available_actions'], a dict that indicates available actions.</p> <code>action_space</code> <code>Dict</code> <p>a gymnasium.spaces.Dict with keys <code>['actor_type','city_id','unit_id', 'dipl_id','city_action_type','unit_action_type','dipl_action_type', 'gov_action_type','tech_action_type']</code></p> Source code in <code>src/civrealm/envs/freeciv_wrapper/action_wrapper.py</code> <pre><code>class TensorAction(Wrapper):\n    \"\"\"\n    A wrapper that defines tensor action spaces,  transforms tensor actions into\n    actions that could be handeled by FreecivBaseEnv instance, and adds masks to\n    observations.\n\n    TensorAction wrapper is composed of five wrappers, including `TruncateDiplCity`,\n    `DiplomacyLoop`, `CombineTechResearchGoal`, `PersistentCityProduction`, and `EmbarkWrapper`.\n\n\n\n    Parameters\n    ----------\n    env: TensorBase\n        A FreecivBaseEnv instance that has been wrapped by TensorBase.\n\n    Attributes\n    ----------\n    aciton_config: dict\n        a dict that configs that specify sizes of mutable entities and action layout.\n    mask: dict\n        a dict of masks of type numpy ndarray indicating available actions and entities. 0-&gt; unavilalbe, 1-&gt;availble.\n    available_actions: dict\n        cached info['available_actions'], a dict that indicates available actions.\n    action_space: gymnasium.spaces.Dict\n        a gymnasium.spaces.Dict with keys `['actor_type','city_id','unit_id',\n        'dipl_id','city_action_type','unit_action_type','dipl_action_type',\n        'gov_action_type','tech_action_type']`\n    \"\"\"\n\n    def __init__(self, env: TensorBase):\n        self.action_config = env.get_wrapper_attr(\"config\")\n        self.action_config[\"resize\"][\"dipl\"] = self.action_config[\"resize\"][\n            \"others_player\"\n        ]\n        self.actor_type_list = self.action_config[\"actor_type_list\"]\n        self.available_actions = {}\n        self.mask = {}\n        self.__turn = -1\n        self.__dealing_with_incoming = False\n\n        super().__init__(\n            TruncateDiplCity(\n                DiplomacyLoop(\n                    CombineTechResearchGoal(\n                        PersistentCityProduction(EmbarkWrapper(env))\n                    )\n                )\n            )\n        )\n\n        self.action_space = spaces.Dict(\n            {\n                \"actor_type\": spaces.Discrete(len(self.actor_type_list)),\n                \"city_id\": spaces.Discrete(self.action_config[\"resize\"][\"city\"]),\n                \"city_action_type\": spaces.Discrete(\n                    sum(self.action_config[\"action_layout\"][\"city\"].values())\n                ),\n                \"unit_id\": spaces.Discrete(self.action_config[\"resize\"][\"unit\"]),\n                \"unit_action_type\": spaces.Discrete(\n                    sum(self.action_config[\"action_layout\"][\"unit\"].values())\n                ),\n                \"dipl_id\": spaces.Discrete(self.action_config[\"resize\"][\"dipl\"]),\n                \"dipl_action_type\": spaces.Discrete(\n                    sum(self.action_config[\"action_layout\"][\"dipl\"].values())\n                ),\n                \"gov_action_type\": spaces.Discrete(\n                    sum(self.action_config[\"action_layout\"][\"gov\"].values())\n                ),\n                \"tech_action_type\": spaces.Discrete(\n                    sum(self.action_config[\"action_layout\"][\"tech\"].values())\n                ),\n            }\n        )\n\n    def step(self, action):\n        # Get {k:value.item()} if value is array\n        action = {\n            k: (v.item() if isinstance(v, np.ndarray) else v) for k, v in action.items()\n        }\n\n        base_action = self.action(action)\n        if tensor_debug:\n            print(base_action)\n        obs, reward, terminated, truncated, info = self.env.step(base_action)\n        if tensor_debug:\n            print(f\"reward:{reward},done:{terminated or truncated}\")\n\n        obs = self.update_obs_with_mask(obs, info, action)\n        return obs, reward, terminated, truncated, info\n\n    def reset(\n        self,\n        *,\n        seed: Optional[int] = None,\n        options: Optional[Dict[str, Any]] = None,\n        **kwargs,\n    ):\n        obs, info = self.env.reset(seed=seed, options=options, **kwargs)\n        obs = self.update_obs_with_mask(obs, info)\n        return obs, info\n\n    def action(self, action):\n        \"\"\"\n        Translate tensor action, a dict of keys `['actor_type','city_id','unit_id',\n        'dipl_id','city_action_type','unit_action_type','dipl_action_type',\n        'gov_action_type','tech_action_type']` to `FreecivBaseEnv` action,\n        a tuple `(actor_type, entity_id, action_name)`.\n\n        \"\"\"\n        if tensor_debug:\n            self._check_action_layout()\n\n        actor_type = action[\"actor_type\"]\n        actor_name = self.actor_type_list[actor_type]\n\n        if actor_name == \"turn done\":\n            return None\n        if actor_name in [\"gov\", \"tech\"]:\n            entity_pos = None\n            entity_id = self.get_wrapper_attr(\"my_player_id\")\n            action_index = action[actor_name + \"_action_type\"]\n        else:\n            entity_pos, action_index = (\n                action[actor_name + \"_id\"],\n                action[actor_name + \"_action_type\"],\n            )\n            entity_id = self.get_wrapper_attr(actor_name + \"_ids\")[\n                action[actor_name + \"_id\"]\n            ]\n\n        if tensor_debug:\n            assert (\n                self.mask[actor_name +\n                          \"_action_type_mask\"][entity_pos, action_index]\n                == 1\n            ), f\"{actor_name} action of id pos {entity_pos}, \\\n                    action type index {action_index} is masked\"\n\n        action_name = sorted(\n            list(self.available_actions[actor_name][entity_id].keys())\n        )[action_index]\n\n        return (actor_name, entity_id, action_name)\n\n    def update_obs_with_mask(self, observation, info, action=None):\n        \"\"\"\n        Update self.mask using observation, info and action from the unwrapped env,\n        and add self.mask to the observation of the wrapped env.\n        \"\"\"\n        if info[\n            \"turn\"\n        ] != self.__turn or self.__dealing_with_incoming != self.get_wrapper_attr(\n            \"dealing_with_incoming\"\n        ):\n            self.reset_mask()\n        self.available_actions = deepcopy(info[\"available_actions\"])\n        self.__turn = info[\"turn\"]\n        self.__dealing_with_incoming = self.get_wrapper_attr(\n            \"dealing_with_incoming\")\n        self._update_mask(observation, info, action)\n\n        return update(observation, deepcopy(self.mask))\n\n    def reset_mask(self):\n        \"\"\"\n        Reset self.mask\n\n        This is usually called at the start of a new turn to reset masks.\n        \"\"\"\n        # Reset mask\n        sizes = self.action_config[\"resize\"]\n        self.mask[\"actor_type_mask\"] = np.ones(\n            len(self.actor_type_list), dtype=np.int32\n        )\n\n        # Units/Cities/Players and others Masks\n        for field in [\"unit\", \"city\", \"others_unit\", \"others_city\", \"others_player\"]:\n            self.mask[field + \"_mask\"] = np.ones(sizes[field], dtype=np.int32)[\n                ..., np.newaxis\n            ]\n\n        # Units/Cities Id Masks same as their Masks\n        self.mask[\"unit_id_mask\"] = self.mask[\"unit_mask\"]\n        self.mask[\"city_id_mask\"] = self.mask[\"city_mask\"]\n\n        # Dipl id mask\n        self.mask[\"dipl_id_mask\"] = np.ones(sizes[\"dipl\"], dtype=np.int32)[\n            ..., np.newaxis\n        ]\n\n        # Action type mask\n        for field in [\"city\", \"unit\", \"dipl\"]:\n            self.mask[field + \"_action_type_mask\"] = np.ones(\n                (\n                    sizes[field],\n                    sum(self.action_config[\"action_layout\"][field].values()),\n                ),\n                dtype=np.int32,\n            )\n        for field in [\"gov\", \"tech\"]:\n            self.mask[field + \"_action_type_mask\"] = np.ones(\n                (sum(self.action_config[\"action_layout\"][field].values()),),\n                dtype=np.int32,\n            )\n\n    def _update_mask(self, observation, info, action):\n        # update self.mask using action, observation and info\n        if action:\n            self._mask_from_action(action)\n        self._mask_from_obs(observation)\n        self._mask_from_info(info)\n\n    def _mask_from_action(self, action):\n        # Mask out actions that have been performed in this turn.\n        actor_type = action[\"actor_type\"]\n        actor_name = self.actor_type_list[actor_type]\n        if actor_name == \"unit\":\n            # self.mask[\"unit_action_type_mask\"][\n            #     action[\"unit_id\"], action[\"unit_action_type\"]\n            # ] = 0\n            pass\n        elif actor_name == \"city\":\n            # self.mask[\"city_action_type_mask\"][action[\"city_id\"], :] = 0\n            pass\n        elif actor_name == \"gov\":\n            self.mask[\"gov_action_type_mask\"][:] &amp;= 0\n        elif actor_name == \"tech\":\n            self.mask[\"tech_action_type_mask\"][:] &amp;= 0\n\n    def _mask_from_obs(self, observation):\n        # Mask mutable entities using observation\n\n        # Mask out trailing spaces for unit and city\n        self.mask[\"unit_id_mask\"][len(\n            self.get_wrapper_attr(\"unit_ids\"))::, :] = 0\n        self.mask[\"city_id_mask\"][len(\n            self.get_wrapper_attr(\"city_ids\"))::, :] = 0\n        self.mask[\"dipl_id_mask\"][len(\n            self.get_wrapper_attr(\"dipl_ids\"))::, :] = 0\n        self.mask[\"unit_mask\"] = self.mask[\"unit_id_mask\"].copy()\n        self.mask[\"city_mask\"] = self.mask[\"city_id_mask\"].copy()\n\n        self.mask[\"unit_action_type_mask\"][\n            len(self.get_wrapper_attr(\"unit_ids\"))::, :\n        ] = 0\n        self.mask[\"city_action_type_mask\"][\n            len(self.get_wrapper_attr(\"city_ids\"))::, :\n        ] = 0\n\n        # Mask Unit\n        for pos, unit_id in enumerate(\n            self.get_wrapper_attr(\"unit_ids\")[\n                : self.action_config[\"resize\"][\"unit\"]]\n        ):\n            unit = observation[\"unit\"][unit_id]\n            if unit[\"moves_left\"] == 0 or self.unwrapped.civ_controller.unit_ctrl.units[\n                unit_id\n            ][\"activity\"] not in [\n                ACTIVITY_IDLE,\n                ACTIVITY_FORTIFIED,\n                ACTIVITY_SENTRY,\n                ACTIVITY_FORTIFYING,\n            ]:  # agent busy or fortified\n                self.mask[\"unit_id_mask\"][pos] &amp;= 0\n                self.mask[\"unit_action_type_mask\"][pos, :] &amp;= 0\n\n        self.mask[\"others_unit_mask\"][\n            len(self.get_wrapper_attr(\"others_unit_ids\"))::, :\n        ] &amp;= 0\n        self.mask[\"others_city_mask\"][\n            len(self.get_wrapper_attr(\"others_city_ids\"))::, :\n        ] &amp;= 0\n\n        if self.get_wrapper_attr(\"researching\"):\n            self.mask[\"tech_action_type_mask\"][:] &amp;= 0\n        if not self.get_wrapper_attr(\"researching\") and tensor_debug:\n            print(\n                f\"techs_researched: {self.get_wrapper_attr('techs_researched')}\")\n\n    def _mask_from_info(self, info):\n        others_player_num = len(\n            info[\"available_actions\"].get(\"player\", {}).keys())\n        self.mask[\"others_player_mask\"][others_player_num::, :] &amp;= 0\n\n        # Mask City and Unit\n        for mutable in [\"city\", \"unit\", \"dipl\"]:\n            entities = info[\"available_actions\"].get(mutable, {})\n            if len(entities) == 0:\n                self.mask[mutable + \"_action_type_mask\"][:, :] &amp;= 0\n                self.mask[mutable + \"_id_mask\"][:] &amp;= 0\n                continue\n            for i, entity_id in enumerate(\n                self.env.get_wrapper_attr(mutable + \"_ids\")[\n                    : self.action_config[\"resize\"][mutable]\n                ]\n            ):\n                actions = entities.get(entity_id, {})\n                if len(actions) == 0:\n                    self.mask[mutable + \"_action_type_mask\"][i, :] &amp;= 0\n                    self.mask[mutable + \"_id_mask\"][i] &amp;= 0\n                    continue\n                for action_id, act_name in enumerate(sorted(list(actions.keys()))):\n                    self.mask[mutable + \"_action_type_mask\"][i, action_id] &amp;= int(\n                        actions[act_name]\n                    )\n                self.mask[mutable + \"_id_mask\"][i] &amp;= int(\n                    any(self.mask[mutable + \"_action_type_mask\"][i])\n                )\n        for mutable in [\"city\", \"unit\", \"dipl\"]:\n            actor_type_index = self.actor_type_list.index(mutable)\n            self.mask[\"actor_type_mask\"][actor_type_index] &amp;= int(\n                any(self.mask[mutable + \"_id_mask\"])\n            )\n\n        # Mask Gov and Tech\n        for immutable in [\"gov\", \"tech\"]:\n            options = info[\"available_actions\"].get(immutable, {})\n            if len(options) == 0:\n                self.mask[immutable + \"_action_type_mask\"][:] &amp;= 0\n                continue\n            my_player_id = self.get_wrapper_attr(\"my_player_id\")\n            for action_id, act_name in enumerate(\n                sorted(list(options[my_player_id].keys()))\n            ):\n                self.mask[immutable + \"_action_type_mask\"][action_id] &amp;= int(\n                    options[my_player_id][act_name]\n                )\n        for immutable in [\"gov\", \"tech\"]:\n            actor_type_index = self.actor_type_list.index(immutable)\n            self.mask[\"actor_type_mask\"][actor_type_index] &amp;= int(\n                any(self.mask[immutable + \"_action_type_mask\"])\n            )\n\n    def _check_action_layout(self):\n        action_layout = self.action_config[\"action_layout\"]\n        for field in [\"city\", \"unit\"]:\n            for id, entity in self.available_actions.get(field, {}).items():\n                assert len(entity) == sum(action_layout[field].values())\n        assert len(\n            self.available_actions[\"gov\"][self.get_wrapper_attr(\n                \"my_player_id\")]\n        ) == sum(action_layout[\"gov\"].values())\n</code></pre>"},{"location":"api_reference/wrappers.html#envs.freeciv_wrapper.action_wrapper.TensorAction.action","title":"<code>action(action)</code>","text":"<p>Translate tensor action, a dict of keys <code>['actor_type','city_id','unit_id', 'dipl_id','city_action_type','unit_action_type','dipl_action_type', 'gov_action_type','tech_action_type']</code> to <code>FreecivBaseEnv</code> action, a tuple <code>(actor_type, entity_id, action_name)</code>.</p> Source code in <code>src/civrealm/envs/freeciv_wrapper/action_wrapper.py</code> <pre><code>def action(self, action):\n    \"\"\"\n    Translate tensor action, a dict of keys `['actor_type','city_id','unit_id',\n    'dipl_id','city_action_type','unit_action_type','dipl_action_type',\n    'gov_action_type','tech_action_type']` to `FreecivBaseEnv` action,\n    a tuple `(actor_type, entity_id, action_name)`.\n\n    \"\"\"\n    if tensor_debug:\n        self._check_action_layout()\n\n    actor_type = action[\"actor_type\"]\n    actor_name = self.actor_type_list[actor_type]\n\n    if actor_name == \"turn done\":\n        return None\n    if actor_name in [\"gov\", \"tech\"]:\n        entity_pos = None\n        entity_id = self.get_wrapper_attr(\"my_player_id\")\n        action_index = action[actor_name + \"_action_type\"]\n    else:\n        entity_pos, action_index = (\n            action[actor_name + \"_id\"],\n            action[actor_name + \"_action_type\"],\n        )\n        entity_id = self.get_wrapper_attr(actor_name + \"_ids\")[\n            action[actor_name + \"_id\"]\n        ]\n\n    if tensor_debug:\n        assert (\n            self.mask[actor_name +\n                      \"_action_type_mask\"][entity_pos, action_index]\n            == 1\n        ), f\"{actor_name} action of id pos {entity_pos}, \\\n                action type index {action_index} is masked\"\n\n    action_name = sorted(\n        list(self.available_actions[actor_name][entity_id].keys())\n    )[action_index]\n\n    return (actor_name, entity_id, action_name)\n</code></pre>"},{"location":"api_reference/wrappers.html#envs.freeciv_wrapper.action_wrapper.TensorAction.reset_mask","title":"<code>reset_mask()</code>","text":"<p>Reset self.mask</p> <p>This is usually called at the start of a new turn to reset masks.</p> Source code in <code>src/civrealm/envs/freeciv_wrapper/action_wrapper.py</code> <pre><code>def reset_mask(self):\n    \"\"\"\n    Reset self.mask\n\n    This is usually called at the start of a new turn to reset masks.\n    \"\"\"\n    # Reset mask\n    sizes = self.action_config[\"resize\"]\n    self.mask[\"actor_type_mask\"] = np.ones(\n        len(self.actor_type_list), dtype=np.int32\n    )\n\n    # Units/Cities/Players and others Masks\n    for field in [\"unit\", \"city\", \"others_unit\", \"others_city\", \"others_player\"]:\n        self.mask[field + \"_mask\"] = np.ones(sizes[field], dtype=np.int32)[\n            ..., np.newaxis\n        ]\n\n    # Units/Cities Id Masks same as their Masks\n    self.mask[\"unit_id_mask\"] = self.mask[\"unit_mask\"]\n    self.mask[\"city_id_mask\"] = self.mask[\"city_mask\"]\n\n    # Dipl id mask\n    self.mask[\"dipl_id_mask\"] = np.ones(sizes[\"dipl\"], dtype=np.int32)[\n        ..., np.newaxis\n    ]\n\n    # Action type mask\n    for field in [\"city\", \"unit\", \"dipl\"]:\n        self.mask[field + \"_action_type_mask\"] = np.ones(\n            (\n                sizes[field],\n                sum(self.action_config[\"action_layout\"][field].values()),\n            ),\n            dtype=np.int32,\n        )\n    for field in [\"gov\", \"tech\"]:\n        self.mask[field + \"_action_type_mask\"] = np.ones(\n            (sum(self.action_config[\"action_layout\"][field].values()),),\n            dtype=np.int32,\n        )\n</code></pre>"},{"location":"api_reference/wrappers.html#envs.freeciv_wrapper.action_wrapper.TensorAction.update_obs_with_mask","title":"<code>update_obs_with_mask(observation, info, action=None)</code>","text":"<p>Update self.mask using observation, info and action from the unwrapped env, and add self.mask to the observation of the wrapped env.</p> Source code in <code>src/civrealm/envs/freeciv_wrapper/action_wrapper.py</code> <pre><code>def update_obs_with_mask(self, observation, info, action=None):\n    \"\"\"\n    Update self.mask using observation, info and action from the unwrapped env,\n    and add self.mask to the observation of the wrapped env.\n    \"\"\"\n    if info[\n        \"turn\"\n    ] != self.__turn or self.__dealing_with_incoming != self.get_wrapper_attr(\n        \"dealing_with_incoming\"\n    ):\n        self.reset_mask()\n    self.available_actions = deepcopy(info[\"available_actions\"])\n    self.__turn = info[\"turn\"]\n    self.__dealing_with_incoming = self.get_wrapper_attr(\n        \"dealing_with_incoming\")\n    self._update_mask(observation, info, action)\n\n    return update(observation, deepcopy(self.mask))\n</code></pre>"},{"location":"api_reference/wrappers.html#envs.freeciv_wrapper.action_wrapper.EmbarkWrapper","title":"<code>envs.freeciv_wrapper.action_wrapper.EmbarkWrapper</code>","text":"<p>             Bases: <code>Wrapper</code></p> <p>Unify embark actions of all units to 'embark_{dir8}' where dir8 in <code>[0,...7]</code> indicating 8 directions.</p> <p>Sometimes a unit can embark multiple carrier on the same direction. In that case, the wrapper automatically choose the carrier with the smallest unit id.</p> <p>Attributes:</p> Name Type Description <code>embarkable_units</code> <code>dict</code> <p>a dict of embarkable units with key=(embarking_unit_id, dir8) and value=[carrier_ids]</p> Source code in <code>src/civrealm/envs/freeciv_wrapper/embark_wrapper.py</code> <pre><code>@wrapper_override([\"action\", \"info\"])\nclass EmbarkWrapper(Wrapper):\n    \"\"\"\n    Unify embark actions of all units to 'embark_{dir8}' where dir8 in `[0,...7]`\n    indicating 8 directions.\n\n    Sometimes a unit can embark multiple carrier on the same direction. In that\n    case, the wrapper automatically choose the carrier with the smallest unit id.\n\n    Attributes\n    ----------\n    embarkable_units : dict\n        a dict of embarkable units with key=(embarking_unit_id, dir8) and value=[carrier_ids]\n    \"\"\"\n\n    def __init__(self, env):\n        self.embarkable_units = {}\n        super().__init__(env)\n\n    def action(self, action):\n        \"\"\"\n        Translate `embark_{dir8}` action into embark actions that can be handled by FreecivBaseEnv.\n        \"\"\"\n        if action is None:\n            return action\n        (actor_name, entity_id, action_name) = action\n        if actor_name != \"unit\":\n            return action\n        if action_name[:6] != \"embark\":\n            return action\n\n        dir8 = int(action_name.split(\"_\")[-1])\n\n        if len(self.embarkable_units.get((entity_id, dir8), [])) &gt; 0:\n            assert dir8 &lt;= 8\n            target_id = sorted(self.embarkable_units[(entity_id, dir8)])[0]\n            action_name = f\"embark_{dir8}_{target_id}\"\n\n        return (actor_name, entity_id, action_name)\n\n    def info(self, info):\n        \"\"\"\n        Complete or modify embark actions in info['availble_actions']['unit']\n\n        If a unit has no `embark_.*` action, then set all `embark_{dir8}` action to False\n\n        If a unit has `embark_{dir}=True`, set all `embark_{other_dirs}` action to False\n\n        If a unit has `embark_{carrier_id}_{dir}=True`, store that carrier_id\n        and set its `embark_{dir8}` accordingly.\n        \"\"\"\n\n        self.embarkable_units = {}\n        unit_actions = info[\"available_actions\"].get(\"unit\", {})\n\n        if len(unit_actions) == 0:\n            return info\n\n        for unit_id, actions in unit_actions.items():\n            unavailable_embarks = [\"embark_\" + f\"{i}\" for i in range(8)]\n            for action in list(actions.keys()):\n                if action[:6] != \"embark\":\n                    continue\n\n                args = action.split(\"_\")\n\n                if len(args) == 3:\n                    # action ==  embark_dir_id\n                    [dir8, target_id] = map(int, args[1::])\n                    if (unit_dir := (unit_id, dir8)) not in self.embarkable_units:\n                        self.embarkable_units[unit_dir] = [target_id]\n                    else:\n                        self.embarkable_units[unit_dir].append(target_id)\n                    actions.pop(action)\n                    embark_action = f\"embark_{dir8}\"\n                else:\n                    # action ==  embark_dir\n                    assert (\n                        len(args) == 2\n                    ), f\"Expected embark_{{dir}}_{{target_id}},\\\n                            but got unsupported embark action name {action}\"\n                    dir8 = int(action.split(\"_\")[-1])\n                    embark_action = f\"embark_{dir8}\"\n                actions[f\"embark_{dir8}\"] = True\n                if embark_action in unavailable_embarks:\n                    unavailable_embarks.remove(embark_action)\n\n            for embark_action in unavailable_embarks:\n                # set unavailable embark actions to False\n                actions[embark_action] = False\n\n        info[\"available_actions\"][\"unit\"] = unit_actions\n\n        return info\n</code></pre>"},{"location":"api_reference/wrappers.html#envs.freeciv_wrapper.action_wrapper.EmbarkWrapper.action","title":"<code>action(action)</code>","text":"<p>Translate <code>embark_{dir8}</code> action into embark actions that can be handled by FreecivBaseEnv.</p> Source code in <code>src/civrealm/envs/freeciv_wrapper/embark_wrapper.py</code> <pre><code>def action(self, action):\n    \"\"\"\n    Translate `embark_{dir8}` action into embark actions that can be handled by FreecivBaseEnv.\n    \"\"\"\n    if action is None:\n        return action\n    (actor_name, entity_id, action_name) = action\n    if actor_name != \"unit\":\n        return action\n    if action_name[:6] != \"embark\":\n        return action\n\n    dir8 = int(action_name.split(\"_\")[-1])\n\n    if len(self.embarkable_units.get((entity_id, dir8), [])) &gt; 0:\n        assert dir8 &lt;= 8\n        target_id = sorted(self.embarkable_units[(entity_id, dir8)])[0]\n        action_name = f\"embark_{dir8}_{target_id}\"\n\n    return (actor_name, entity_id, action_name)\n</code></pre>"},{"location":"api_reference/wrappers.html#envs.freeciv_wrapper.action_wrapper.EmbarkWrapper.info","title":"<code>info(info)</code>","text":"<p>Complete or modify embark actions in info'availble_actions'</p> <p>If a unit has no <code>embark_.*</code> action, then set all <code>embark_{dir8}</code> action to False</p> <p>If a unit has <code>embark_{dir}=True</code>, set all <code>embark_{other_dirs}</code> action to False</p> <p>If a unit has <code>embark_{carrier_id}_{dir}=True</code>, store that carrier_id and set its <code>embark_{dir8}</code> accordingly.</p> Source code in <code>src/civrealm/envs/freeciv_wrapper/embark_wrapper.py</code> <pre><code>def info(self, info):\n    \"\"\"\n    Complete or modify embark actions in info['availble_actions']['unit']\n\n    If a unit has no `embark_.*` action, then set all `embark_{dir8}` action to False\n\n    If a unit has `embark_{dir}=True`, set all `embark_{other_dirs}` action to False\n\n    If a unit has `embark_{carrier_id}_{dir}=True`, store that carrier_id\n    and set its `embark_{dir8}` accordingly.\n    \"\"\"\n\n    self.embarkable_units = {}\n    unit_actions = info[\"available_actions\"].get(\"unit\", {})\n\n    if len(unit_actions) == 0:\n        return info\n\n    for unit_id, actions in unit_actions.items():\n        unavailable_embarks = [\"embark_\" + f\"{i}\" for i in range(8)]\n        for action in list(actions.keys()):\n            if action[:6] != \"embark\":\n                continue\n\n            args = action.split(\"_\")\n\n            if len(args) == 3:\n                # action ==  embark_dir_id\n                [dir8, target_id] = map(int, args[1::])\n                if (unit_dir := (unit_id, dir8)) not in self.embarkable_units:\n                    self.embarkable_units[unit_dir] = [target_id]\n                else:\n                    self.embarkable_units[unit_dir].append(target_id)\n                actions.pop(action)\n                embark_action = f\"embark_{dir8}\"\n            else:\n                # action ==  embark_dir\n                assert (\n                    len(args) == 2\n                ), f\"Expected embark_{{dir}}_{{target_id}},\\\n                        but got unsupported embark action name {action}\"\n                dir8 = int(action.split(\"_\")[-1])\n                embark_action = f\"embark_{dir8}\"\n            actions[f\"embark_{dir8}\"] = True\n            if embark_action in unavailable_embarks:\n                unavailable_embarks.remove(embark_action)\n\n        for embark_action in unavailable_embarks:\n            # set unavailable embark actions to False\n            actions[embark_action] = False\n\n    info[\"available_actions\"][\"unit\"] = unit_actions\n\n    return info\n</code></pre>"},{"location":"api_reference/wrappers.html#envs.freeciv_wrapper.observation_wrapper.TensorObservation","title":"<code>envs.freeciv_wrapper.observation_wrapper.TensorObservation</code>","text":"<p>             Bases: <code>Wrapper</code></p> <p>A wrapper that defines tensor observation space, transforms observations got from FreecivBaseEnv into tensor observations.</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>TensorBase</code> <p>A FreecivBaseEnv wrapped by TensorBase wrapper</p> required <p>Attributes:</p> Name Type Description <code>observation_config</code> <code>dict</code> <p>tensor observation configuration</p> <code>observation_space</code> <code>Dict</code> <p>a gymnasium.spaces.Dict with keys speficified in configuration; observation with keywords <code>mask</code> would not be removed.</p> <code>obs_initialized</code> <code>bool</code> <p>whether observation spaces has been initialized</p> <code>obs_layout</code> <code>dict</code> <p>a dict that specify shapes of flattened numpy arrays in observation</p> Source code in <code>src/civrealm/envs/freeciv_wrapper/observation_wrapper.py</code> <pre><code>@wrapper_override([\"observation\"])\nclass TensorObservation(Wrapper):\n    \"\"\"\n    A wrapper that defines tensor observation space, transforms observations got from\n    FreecivBaseEnv into tensor observations.\n\n    Parameters\n    ----------\n    env:\n        A FreecivBaseEnv wrapped by TensorBase wrapper\n\n    Attributes\n    ---------\n    observation_config: dict\n        tensor observation configuration\n    observation_space: gymnasium.spaces.Dict\n        a gymnasium.spaces.Dict with keys speficified in configuration;\n        observation with keywords `mask` would not be removed.\n    obs_initialized: bool\n        whether observation spaces has been initialized\n    obs_layout: dict\n        a dict that specify shapes of flattened numpy arrays in observation\n    \"\"\"\n\n    mutable_fields = [\n        \"city\",\n        \"unit\",\n        \"others_city\",\n        \"others_unit\",\n        \"others_player\",\n        \"dipl\",\n    ]\n    immutable_fields = [\"map\", \"rules\", \"player\", \"gov\"]\n\n    def __init__(self, env: TensorBase):\n        self.obs_initialized = False\n        self.observation_config = env.get_wrapper_attr(\"config\")\n        self.observation_config[\"resize\"][\"dipl\"] = self.observation_config[\"resize\"][\n            \"others_player\"\n        ]\n        self.obs_layout = {}\n        self.others_player_ids = []\n        super().__init__(env)\n\n    def observation(self, observation):\n        \"\"\"\n        convert observations obtained from `FreecivBaseEnv` into a dict of flattend numpy arrays.\n        \"\"\"\n        # in case of gameover, return None as observation\n        if len(observation.get(\"player\", {})) == 0:\n            return None\n\n        observation = deepcopy(observation)\n        observation = self._merge_player_techs(observation)\n        obs_dict = self._handle_dict(observation)\n        obs = self._embed_immutable(deepcopy(obs_dict))\n        obs = self._embed_mutable(obs)\n\n        if not self.obs_initialized:\n            self.observation_space = self._infer_obs_space(obs)\n            self.obs_initialized = True\n        if tensor_debug:\n            self._check_obs_layout(obs)\n        return obs\n\n    def _handle_dict(self, obs):\n        obs[\"city\"] = obs.get(\"city\", {})\n        obs[\"unit\"] = obs.get(\"unit\", {})\n\n        # TODO: This should be the base env's reponsibility\n        # Add info to city and unit from civcontroller\n        update(obs[\"city\"], self.unwrapped.civ_controller.city_ctrl.cities)\n        update(obs[\"unit\"], self.unwrapped.civ_controller.unit_ctrl.units)\n        # update player info with dipl_state\n        update(obs[\"player\"], obs.get(\"dipl\", {}))\n\n        my_player_id = self.get_wrapper_attr(\"my_player_id\")\n\n        obs[\"dipl\"] = {\n            player: state[\"diplomacy_clause_map\"]\n            for player, state in obs.get(\"dipl\", {}).items()\n            if player != my_player_id\n        }\n        for player, treaty in obs[\"dipl\"].items():\n            obs[\"dipl\"][player] = self._encode_treaty(treaty, player)\n\n        # remove unused fields and keep mask if given\n        obs = {\n            k: v\n            for k, v in obs.items()\n            if k in self.observation_config[\"filter_observation\"] or k.endswith(\"mask\")\n        }\n\n        # Add others fields and initialize\n\n        obs[\"others_unit\"] = {}\n        obs[\"others_city\"] = {}\n\n        for field in [\"unit\", \"city\"]:\n            for key, val in list(obs[field].items()):\n                if val[\"owner\"] != my_player_id:\n                    # delete others' entity from unit and city\n                    obs[\"others_\" + field][key] = obs[field].pop(key)\n\n        obs[\"others_player\"] = {\n            key: obs[\"player\"].pop(key)\n            for key in list(obs[\"player\"].keys())\n            if key != my_player_id\n        }\n        obs[\"player\"] = obs[\"player\"][my_player_id]\n\n        # Initialize build_cost with 0 for now\n        obs[\"rules\"][\"build_cost\"] = 0\n\n        mutable_fields = [field for field in obs.keys() if field in self.mutable_fields]\n        immutable_fields = [\n            field for field in obs.keys() if field in self.immutable_fields\n        ]\n\n        ops = self.observation_config[\"obs_ops\"]\n\n        # Handle immutable\n        # delete unused keywords and transform useful keywords\n        def apply_ops(field):\n            for k, val in list(obs[field].items()):\n                if k in list(ops[field].keys()):\n                    obs[field][k] = ops[field][k](val)\n                else:\n                    obs[field].pop(k)\n\n        for field in immutable_fields:\n            apply_ops(field)\n\n        # Handle mutable\n        # delete unused keywords and transform useful keywords\n        def apply_ops_mutable(field):\n            for entity_id, entity in list(obs[field].items()):\n                for k, val in list(entity.items()):\n                    if k in list(ops[field].keys()):\n                        entity[k] = ops[field][k](val)\n                    else:\n                        entity.pop(k)\n\n        for field in mutable_fields:\n            apply_ops_mutable(field)\n\n        self.others_player_ids = sorted(obs[\"others_player\"].keys())\n\n        return obs\n\n    def _embed_immutable(self, obs):\n        immutable = {\n            field: obs[field] for field in obs if field in self.immutable_fields\n        }\n\n        if not self.obs_initialized:\n            for field, field_dict in immutable.items():\n                self.obs_layout[field] = OrderedDict(\n                    [(k, field_dict[k].shape) for k in sorted(list(field_dict.keys()))]\n                )\n\n        for field, field_dict in immutable.items():\n            # check field layout is correct\n            if tensor_debug:\n                assert self.obs_layout[field] == {\n                    k: v.shape for k, v in field_dict.items()\n                }\n\n            obs[field] = np.concatenate(\n                [field_dict[k] for k in sorted(list(field_dict.keys()))], axis=-1\n            ).astype(np.int32)\n        return obs\n\n    def _embed_mutable(self, obs):\n        mutable = {field: obs[field] for field in obs if field in self.mutable_fields}\n        mutable_layout = self.observation_config[\"obs_mutable_layout\"]\n\n        if not self.obs_initialized:\n            for field, entity_dict in mutable.items():\n                layout = mutable_layout[field]\n                self.obs_layout[field] = OrderedDict(\n                    [(key, layout[key]) for key in sorted(layout)]\n                )\n\n        for field, entity_dict in mutable.items():\n            # for empty field, fill with zero\n            if len(entity_dict) == 0:\n                mutable[field] = np.zeros(\n                    [\n                        self.observation_config[\"resize\"][field],\n                        *reduce(add_shape, self.obs_layout[field].values()),\n                    ],\n                    dtype=np.int32,\n                )\n                continue\n            if tensor_debug:\n                # check entity layout is correct\n                assert all(\n                    self.obs_layout[field] == {k: v.shape for k, v in entity.items()}\n                    for entity in entity_dict.values()\n                )\n            # combine every entity's properties into an array along the last axis\n            entity_dict = {\n                id: np.concatenate([entity[k] for k in sorted(entity.keys())], axis=-1)\n                for id, entity in entity_dict.items()\n            }\n            # combine all entities in a field into an array along the first axis\n            mutable[field] = np.stack(\n                [entity_dict[id] for id in self.get_wrapper_attr(field + \"_ids\")],\n                axis=0,\n            ).astype(np.int32)\n\n        # resize to maximum entity shape\n        for field in mutable:\n            size = self.observation_config[\"resize\"][field]\n            mutable[field] = resize_data(mutable[field], size).astype(np.int32)\n\n        update(obs, mutable)\n        return obs\n\n    def _infer_obs_space(self, observation) -&gt; spaces.Dict:\n        return spaces.Dict(\n            [\n                (key, spaces.Box(low=0, high=1000, shape=space.shape, dtype=np.int32))\n                for key, space in observation.items()\n            ]\n        )\n\n    def _check_obs_layout(self, obs):\n        for field, val in self.obs_layout.items():\n            shape = reduce(add_shape, val.values())\n            assert shape[-1] == obs[field].shape[-1]\n\n    def _merge_player_techs(self, obs):\n        for player in obs[\"player\"].values():\n            player[\"techs\"] = []\n            for tech in sorted(obs[\"tech\"]):\n                player_tech = player.pop(f\"tech_{tech}\")\n                player[\"techs\"].append(player_tech if player_tech is not None else 255)\n        return obs\n\n    def _encode_treaty(self, treaty, player):\n        encoded = {\n            \"type\": np.zeros(10 * 2, dtype=np.int32),\n            \"give_city\": np.zeros(\n                self.observation_config[\"resize\"][\"city\"], dtype=np.int32\n            ),\n            \"ask_city\": np.zeros(\n                self.observation_config[\"resize\"][\"others_city\"], dtype=np.int32\n            ),\n            \"give_gold\": 255,\n            \"ask_gold\": 255,\n        }\n\n        for clause in treaty:\n            value = clause[\"value\"]\n\n            if clause[\"type\"] == player_const.CLAUSE_GOLD:\n                gold = sum(int(value &gt;= level) for level in GOLD_SET)\n                if clause[\"giver\"] == player:\n                    encoded[\"ask_gold\"] = gold\n                else:\n                    encoded[\"give_gold\"] = gold\n            elif clause[\"type\"] == player_const.CLAUSE_CITY:\n                if clause[\"giver\"] == player:\n                    city_list = self.get_wrapper_attr(\"others_city_ids\")\n                    field = \"ask_city\"\n                else:\n                    city_list = self.get_wrapper_attr(\"city_ids\")\n                    field = \"give_city\"\n                if value in city_list:\n                    city_idx = city_list.index(value)\n                    encoded[field][city_idx] = 1\n\n            if clause[\"giver\"] == player:\n                encoded[\"type\"][clause[\"type\"]] = 1\n            else:\n                encoded[\"type\"][clause[\"type\"] + 10] = 1\n\n        return encoded\n</code></pre>"},{"location":"api_reference/wrappers.html#envs.freeciv_wrapper.observation_wrapper.TensorObservation.observation","title":"<code>observation(observation)</code>","text":"<p>convert observations obtained from <code>FreecivBaseEnv</code> into a dict of flattend numpy arrays.</p> Source code in <code>src/civrealm/envs/freeciv_wrapper/observation_wrapper.py</code> <pre><code>def observation(self, observation):\n    \"\"\"\n    convert observations obtained from `FreecivBaseEnv` into a dict of flattend numpy arrays.\n    \"\"\"\n    # in case of gameover, return None as observation\n    if len(observation.get(\"player\", {})) == 0:\n        return None\n\n    observation = deepcopy(observation)\n    observation = self._merge_player_techs(observation)\n    obs_dict = self._handle_dict(observation)\n    obs = self._embed_immutable(deepcopy(obs_dict))\n    obs = self._embed_mutable(obs)\n\n    if not self.obs_initialized:\n        self.observation_space = self._infer_obs_space(obs)\n        self.obs_initialized = True\n    if tensor_debug:\n        self._check_obs_layout(obs)\n    return obs\n</code></pre>"},{"location":"api_reference/wrappers.html#envs.freeciv_wrapper.observation_wrapper.CacheLastObs","title":"<code>envs.freeciv_wrapper.observation_wrapper.CacheLastObs</code>","text":"<p>             Bases: <code>Wrapper</code></p> <p>Cache last observation, and override observation with cached observation if terminated or truncated.</p> <p>Attributes:</p> Name Type Description <code>cached_last_obs</code> <code>dict</code> <p>observation cached from the last call of step() or reset()</p> Source code in <code>src/civrealm/envs/freeciv_wrapper/observation_wrapper.py</code> <pre><code>class CacheLastObs(Wrapper):\n    \"\"\"\n    Cache last observation, and override observation with cached observation\n    if terminated or truncated.\n\n    Attributes\n    -------------\n    cached_last_obs: dict\n        observation cached from the last call of step() or reset()\n    \"\"\"\n\n    def __init__(self, env):\n        self.cached_last_obs = None\n        super().__init__(env)\n\n    def reset(self, *args, **kwargs):\n        obs, info = self.env.reset(*args, **kwargs)\n        self.cached_last_obs = deepcopy(obs)\n        return obs, info\n\n    def step(self, action):\n        obs, reward, terminated, truncated, info = self.env.step(action)\n\n        if terminated or truncated:\n            obs = self.cached_last_obs\n            info = {} if info is None else info\n            return obs, reward, terminated, truncated, info\n\n        self.cached_last_obs = deepcopy(obs)\n        return obs, reward, terminated, truncated, info\n</code></pre>"},{"location":"api_reference/wrappers.html#envs.freeciv_wrapper.llm_wrapper.LLMWrapper","title":"<code>envs.freeciv_wrapper.llm_wrapper.LLMWrapper</code>","text":"<p>             Bases: <code>Wrapper</code></p> <p>A wrapper for llm. It tells the surrounding observations of each unit and city extracted from FreecivBaseEnv, based on which llm can generate actions for units and cities. It transforms action_keys of actions from FreecivBaseEnv to readable action_names such that llm can understand. After llm have chosen an action and return the action_name to env, this wrapper transforms the action_name to an action_key, and then execute the corresponding action.</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>FreecivBaseEnv</code> <p>A FreecivBaseEnv</p> required <p>Attributes:</p> Name Type Description <code>llm_default_settings</code> <code>dict</code> <p>settings for llm_wrapper.</p> <code>action_names</code> <code>dict</code> <p>a dict matches action_keys from FreecivBaseEnv to readable action_names</p> <code>tile_length_radius</code> <code>int</code> <p>(length of a tile - 1) / 2</p> <code>tile_width_radius</code> <code>int</code> <p>(width of a tile - 1) / 2</p> <code>tile_info_template</code> <code>dict</code> <p>a dict describes detailed surrounding observations of a unit or a city</p> <code>block_length_radius</code> <code>int</code> <p>(length of a block - 1) / 2</p> <code>block_width_radius</code> <code>int</code> <p>(width of a block - 1) / 2</p> <code>block_info_template</code> <code>dict</code> <p>a dict describes zoomed-out surrounding observations of a unit or a city</p> <code>ctrl_types</code> <code>list</code> <p>a list describes which components of the game to control by llm; we temporarily only consider unit and city in llm_wrapper</p> <code>ctrl_action_categories</code> <code>dict</code> <p>a dict describes which categories of actions llm can take; it can be seen as an action mask</p> Source code in <code>src/civrealm/envs/freeciv_wrapper/llm_wrapper.py</code> <pre><code>class LLMWrapper(Wrapper):\n    \"\"\"\n    A wrapper for llm. It tells the surrounding observations of each unit and city extracted from FreecivBaseEnv, based\n    on which llm can generate actions for units and cities. It transforms action_keys of actions from FreecivBaseEnv to\n    readable action_names such that llm can understand. After llm have chosen an action and return the action_name to\n    env, this wrapper transforms the action_name to an action_key, and then execute the corresponding action.\n\n    Parameters\n    ----------\n    env:\n        A FreecivBaseEnv\n\n    Attributes\n    ---------\n    llm_default_settings: dict\n        settings for llm_wrapper.\n    action_names: dict\n        a dict matches action_keys from FreecivBaseEnv to readable action_names\n    tile_length_radius: int\n        (length of a tile - 1) / 2\n    tile_width_radius: int\n        (width of a tile - 1) / 2\n    tile_info_template: dict\n        a dict describes detailed surrounding observations of a unit or a city\n    block_length_radius: int\n        (length of a block - 1) / 2\n    block_width_radius: int\n        (width of a block - 1) / 2\n    block_info_template: dict\n        a dict describes zoomed-out surrounding observations of a unit or a city\n    ctrl_types: list\n        a list describes which components of the game to control by llm; we temporarily only consider unit and city in\n        llm_wrapper\n    ctrl_action_categories: dict\n        a dict describes which categories of actions llm can take; it can be seen as an action mask\n    \"\"\"\n\n    def __init__(self, env: FreecivBaseEnv):\n        super().__init__(env)\n        self.llm_default_settings = load_config('llm_wrapper_settings.yaml')\n\n        (self.action_names, self.tile_length_radius, self.tile_width_radius, self.tile_info_template,\n         self.block_length_radius, self.block_width_radius, self.block_info_template, self.ctrl_types,\n         self.ctrl_action_categories) = self.llm_default_settings.values()\n\n        self.action_keys = {val: key for key, val in self.action_names.items()}\n        self.controller = self.unwrapped.civ_controller\n\n    def reset(self, seed=None, options=None, **kwargs):\n        if 'minitask_pattern' in kwargs:\n            observation, info = self.env.reset(\n                minitask_pattern=kwargs['minitask_pattern'])\n        else:\n            observation, info = self.env.reset()\n\n        info['llm_info'] = self.get_llm_info(observation, info)\n        info['my_player_id'] = self.controller.player_ctrl.my_player_id\n        return observation, info\n\n    def step(self, action):\n        if action is not None:\n            action_name = action[2]\n            action = (action[0], action[1], get_action_from_readable_name(\n                action_name, self.action_keys))\n\n        observation, reward, terminated, truncated, info = self.env.step(\n            action)\n        info['llm_info'] = self.get_llm_info(observation, info)\n        info['my_player_id'] = self.controller.player_ctrl.my_player_id\n        return observation, reward, terminated, truncated, info\n\n    def get_llm_info(self, obs, info):\n        \"\"\"\n        Convert observations and available actions of all actors from `FreecivBaseEnv` into a dict of natural language\n        \"\"\"\n        current_turn = info['turn']\n\n        llm_info = dict()\n        for ctrl_type, actors_can_act in info['available_actions'].items():\n            llm_info[ctrl_type] = dict()\n\n            if ctrl_type == 'unit':\n                units = self.controller.unit_ctrl.units\n                for unit_id in actors_can_act:\n                    if (units[unit_id]['type'] == 1 and units[unit_id]['activity'] not in\n                            [ACTIVITY_IDLE, ACTIVITY_FORTIFIED, ACTIVITY_SENTRY, ACTIVITY_FORTIFYING]):\n                        continue\n\n                    x = obs[ctrl_type][unit_id]['x']\n                    y = obs[ctrl_type][unit_id]['y']\n                    utype = obs[ctrl_type][unit_id]['type_rule_name']\n\n                    unit_dict = self.get_actor_info(\n                        x, y, obs, info, ctrl_type, unit_id, utype)\n                    if unit_dict:\n                        llm_info[ctrl_type][unit_id] = unit_dict\n\n            elif ctrl_type == 'city':\n                for city_id in actors_can_act:\n                    # The following two conditions are used to check if 1.  the city is just built or is building\n                    # coinage, and 2. the city has just built a unit or an improvement last turn and there are some\n                    # production points left in stock.\n                    if (obs[ctrl_type][city_id]['prod_process'] == 0 or\n                            current_turn == obs[ctrl_type][city_id]['turn_last_built'] + 1):\n                        x = obs[ctrl_type][city_id]['x']\n                        y = obs[ctrl_type][city_id]['y']\n\n                        city_dict = self.get_actor_info(\n                            x, y, obs, info, ctrl_type, city_id)\n                        if city_dict:\n                            llm_info[ctrl_type][city_id] = city_dict\n                    else:\n                        continue\n            else:\n                continue\n\n        return llm_info\n\n    def get_actor_info(self, x, y, obs, info, ctrl_type, actor_id, utype=None):\n        \"\"\"\n        Convert observations and available actions of a specific actor from `FreecivBaseEnv` into a dict of natural language\n        \"\"\"\n        actor_info = dict()\n\n        actor_name = None\n        if ctrl_type == 'unit':\n            actor_name = utype + ' ' + str(actor_id)\n        elif ctrl_type == 'city':\n            actor_name = ctrl_type + ' ' + str(actor_id)\n        actor_info['name'] = actor_name\n\n        available_actions = get_valid_actions(info, ctrl_type, actor_id)\n        if not available_actions or (len(available_actions) == 1 and available_actions[0] == 'keep_activity'):\n            return dict()\n        else:\n            if ctrl_type not in self.ctrl_action_categories:\n                actor_info['available_actions'] = make_action_list_readable(\n                    available_actions, self.action_names)\n            else:\n                actor_info['available_actions'] = make_action_list_readable(action_mask(\n                    self.ctrl_action_categories[ctrl_type], available_actions), self.action_names)\n\n        actor_info['observations'] = dict()\n        actor_info['observations']['minimap'] = self.get_mini_map_info(\n            x, y, self.tile_length_radius, self.tile_width_radius, self.tile_info_template)\n        actor_info['observations']['upper_map'] = self.get_mini_map_info(\n            x, y, self.block_length_radius, self.block_width_radius, self.block_info_template)\n\n        if ctrl_type == 'city':\n            actor_info['observations']['producing'] = self.get_city_producing(\n                obs[ctrl_type], actor_id)\n\n        fc_logger.debug(f'actor observations: {actor_info}')\n\n        return actor_info\n\n    def get_city_producing(self, obs, actor_id):\n        producing = None\n        if obs[actor_id]['production_kind'] == VUT_UTYPE:\n            producing = self.controller.rule_ctrl.unit_types_list[obs[actor_id]\n                                                                  ['production_value'] - self.controller.rule_ctrl.ruleset_control['num_impr_types']]\n        elif obs[actor_id]['production_kind'] == VUT_IMPROVEMENT:\n            producing = self.controller.rule_ctrl.improvement_types_list[\n                obs[actor_id]['production_value']]\n        return producing\n\n    def get_mini_map_info(self, x, y, length_r, width_r, template):\n        \"\"\"\n        Convert observations of a specific actor from `FreecivBaseEnv` into a dict of natural language\n        \"\"\"\n        mini_map_info = dict()\n\n        tile_id = 0\n        map_state = self.controller.map_ctrl.prop_state.get_state()\n        for ptile in template:\n            mini_map_info[ptile] = []\n            pdir = DIR[tile_id]\n            center_x = x + pdir[0] * (length_r * 2 + 1)\n            center_y = y + pdir[1] * (width_r * 2 + 1)\n\n            if not self.controller.map_ctrl.is_out_of_map(center_x, center_y):\n                \"\"\" consider map_const.TF_WRAPX == 1 \"\"\"\n                start_x = center_x - length_r\n                end_x = center_x + length_r + 1\n                start_y = center_y - width_r\n                end_y = center_y + width_r + 1\n\n                status_arr = read_sub_arr_with_wrap(\n                    map_state['status'], start_x, end_x, start_y, end_y)\n                terrain_arr = read_sub_arr_with_wrap(\n                    map_state['terrain'], start_x, end_x, start_y, end_y)\n                extras_arr = read_sub_arr_with_wrap(\n                    map_state['extras'], start_x, end_x, start_y, end_y)\n                unit_arr = read_sub_arr_with_wrap(\n                    map_state['unit'], start_x, end_x, start_y, end_y)\n                unit_owner_arr = read_sub_arr_with_wrap(\n                    map_state['unit_owner'], start_x, end_x, start_y, end_y)\n                city_owner_arr = read_sub_arr_with_wrap(\n                    map_state['city_owner'], start_x, end_x, start_y, end_y)\n\n                unexplored_tiles_num = len(list(status_arr[status_arr == 0]))\n                if unexplored_tiles_num &gt; 0:\n                    status_str = str(unexplored_tiles_num) + \\\n                        ' ' + 'tiles unexplored'\n                    mini_map_info[ptile].append(status_str)\n\n                for terrain_id, terrain in enumerate(TERRAIN_NAMES):\n                    terrains_num = len(\n                        list(terrain_arr[terrain_arr == terrain_id]))\n                    if terrains_num &gt; 0:\n                        terrain_str = str(terrains_num) + ' ' + terrain\n                        mini_map_info[ptile].append(terrain_str)\n\n                for extra_id, extra in enumerate(EXTRA_NAMES):\n                    extras_of_id = extras_arr[:, :, extra_id]\n                    extras_num = len(list(extras_of_id[extras_of_id != 0]))\n                    if extras_num &gt; 0:\n                        extra_str = str(extras_num) + ' ' + extra\n                        mini_map_info[ptile].append(extra_str)\n\n                for unit_id, unit in enumerate(self.controller.rule_ctrl.unit_types_list):\n                    units_of_id = unit_arr[:, :, unit_id]\n                    units_num = np.sum(units_of_id)\n                    if units_num &gt; 0:\n                        unit_str = str(int(units_num)) + ' ' + unit\n                        mini_map_info[ptile].append(unit_str)\n\n                unit_owners = list(unit_owner_arr[unit_owner_arr != 255])\n                if len(unit_owners) != 0:\n                    owner_set = []\n                    unit_owner_str = 'unit owners are:'\n                    for unit_owner in unit_owners:\n                        if unit_owner in owner_set:\n                            continue\n\n                        if unit_owner == self.controller.player_ctrl.my_player_id:\n                            unit_owner_str += ' myself player_' + \\\n                                str(int(unit_owner))\n                        else:\n                            ds_of_owner = self.controller.dipl_ctrl.diplstates[unit_owner]\n                            unit_owner_str += ' ' + \\\n                                DS_TXT[ds_of_owner] + ' player_' + \\\n                                str(int(unit_owner))\n                        owner_set.append(unit_owner)\n                    mini_map_info[ptile].append(unit_owner_str)\n\n                city_owners = list(city_owner_arr[city_owner_arr != 255])\n                for city_owner in self.controller.player_ctrl.players:\n                    owner_num = city_owners.count(city_owner)\n                    if owner_num == 0:\n                        continue\n\n                    if city_owner == self.controller.player_ctrl.my_player_id:\n                        city_owner_str = str(\n                            owner_num) + ' cities of myself player_' + str(int(city_owner))\n                    else:\n                        ds_of_owner = self.controller.dipl_ctrl.diplstates[city_owner]\n                        city_owner_str = (str(owner_num) + ' cities of a ' + DS_TXT[ds_of_owner] +\n                                          ' player_' + str(int(city_owner)))\n                    mini_map_info[ptile].append(city_owner_str)\n\n            tile_id += 1\n        return mini_map_info\n</code></pre>"},{"location":"api_reference/wrappers.html#envs.freeciv_wrapper.llm_wrapper.LLMWrapper.get_actor_info","title":"<code>get_actor_info(x, y, obs, info, ctrl_type, actor_id, utype=None)</code>","text":"<p>Convert observations and available actions of a specific actor from <code>FreecivBaseEnv</code> into a dict of natural language</p> Source code in <code>src/civrealm/envs/freeciv_wrapper/llm_wrapper.py</code> <pre><code>def get_actor_info(self, x, y, obs, info, ctrl_type, actor_id, utype=None):\n    \"\"\"\n    Convert observations and available actions of a specific actor from `FreecivBaseEnv` into a dict of natural language\n    \"\"\"\n    actor_info = dict()\n\n    actor_name = None\n    if ctrl_type == 'unit':\n        actor_name = utype + ' ' + str(actor_id)\n    elif ctrl_type == 'city':\n        actor_name = ctrl_type + ' ' + str(actor_id)\n    actor_info['name'] = actor_name\n\n    available_actions = get_valid_actions(info, ctrl_type, actor_id)\n    if not available_actions or (len(available_actions) == 1 and available_actions[0] == 'keep_activity'):\n        return dict()\n    else:\n        if ctrl_type not in self.ctrl_action_categories:\n            actor_info['available_actions'] = make_action_list_readable(\n                available_actions, self.action_names)\n        else:\n            actor_info['available_actions'] = make_action_list_readable(action_mask(\n                self.ctrl_action_categories[ctrl_type], available_actions), self.action_names)\n\n    actor_info['observations'] = dict()\n    actor_info['observations']['minimap'] = self.get_mini_map_info(\n        x, y, self.tile_length_radius, self.tile_width_radius, self.tile_info_template)\n    actor_info['observations']['upper_map'] = self.get_mini_map_info(\n        x, y, self.block_length_radius, self.block_width_radius, self.block_info_template)\n\n    if ctrl_type == 'city':\n        actor_info['observations']['producing'] = self.get_city_producing(\n            obs[ctrl_type], actor_id)\n\n    fc_logger.debug(f'actor observations: {actor_info}')\n\n    return actor_info\n</code></pre>"},{"location":"api_reference/wrappers.html#envs.freeciv_wrapper.llm_wrapper.LLMWrapper.get_llm_info","title":"<code>get_llm_info(obs, info)</code>","text":"<p>Convert observations and available actions of all actors from <code>FreecivBaseEnv</code> into a dict of natural language</p> Source code in <code>src/civrealm/envs/freeciv_wrapper/llm_wrapper.py</code> <pre><code>def get_llm_info(self, obs, info):\n    \"\"\"\n    Convert observations and available actions of all actors from `FreecivBaseEnv` into a dict of natural language\n    \"\"\"\n    current_turn = info['turn']\n\n    llm_info = dict()\n    for ctrl_type, actors_can_act in info['available_actions'].items():\n        llm_info[ctrl_type] = dict()\n\n        if ctrl_type == 'unit':\n            units = self.controller.unit_ctrl.units\n            for unit_id in actors_can_act:\n                if (units[unit_id]['type'] == 1 and units[unit_id]['activity'] not in\n                        [ACTIVITY_IDLE, ACTIVITY_FORTIFIED, ACTIVITY_SENTRY, ACTIVITY_FORTIFYING]):\n                    continue\n\n                x = obs[ctrl_type][unit_id]['x']\n                y = obs[ctrl_type][unit_id]['y']\n                utype = obs[ctrl_type][unit_id]['type_rule_name']\n\n                unit_dict = self.get_actor_info(\n                    x, y, obs, info, ctrl_type, unit_id, utype)\n                if unit_dict:\n                    llm_info[ctrl_type][unit_id] = unit_dict\n\n        elif ctrl_type == 'city':\n            for city_id in actors_can_act:\n                # The following two conditions are used to check if 1.  the city is just built or is building\n                # coinage, and 2. the city has just built a unit or an improvement last turn and there are some\n                # production points left in stock.\n                if (obs[ctrl_type][city_id]['prod_process'] == 0 or\n                        current_turn == obs[ctrl_type][city_id]['turn_last_built'] + 1):\n                    x = obs[ctrl_type][city_id]['x']\n                    y = obs[ctrl_type][city_id]['y']\n\n                    city_dict = self.get_actor_info(\n                        x, y, obs, info, ctrl_type, city_id)\n                    if city_dict:\n                        llm_info[ctrl_type][city_id] = city_dict\n                else:\n                    continue\n        else:\n            continue\n\n    return llm_info\n</code></pre>"},{"location":"api_reference/wrappers.html#envs.freeciv_wrapper.llm_wrapper.LLMWrapper.get_mini_map_info","title":"<code>get_mini_map_info(x, y, length_r, width_r, template)</code>","text":"<p>Convert observations of a specific actor from <code>FreecivBaseEnv</code> into a dict of natural language</p> Source code in <code>src/civrealm/envs/freeciv_wrapper/llm_wrapper.py</code> <pre><code>def get_mini_map_info(self, x, y, length_r, width_r, template):\n    \"\"\"\n    Convert observations of a specific actor from `FreecivBaseEnv` into a dict of natural language\n    \"\"\"\n    mini_map_info = dict()\n\n    tile_id = 0\n    map_state = self.controller.map_ctrl.prop_state.get_state()\n    for ptile in template:\n        mini_map_info[ptile] = []\n        pdir = DIR[tile_id]\n        center_x = x + pdir[0] * (length_r * 2 + 1)\n        center_y = y + pdir[1] * (width_r * 2 + 1)\n\n        if not self.controller.map_ctrl.is_out_of_map(center_x, center_y):\n            \"\"\" consider map_const.TF_WRAPX == 1 \"\"\"\n            start_x = center_x - length_r\n            end_x = center_x + length_r + 1\n            start_y = center_y - width_r\n            end_y = center_y + width_r + 1\n\n            status_arr = read_sub_arr_with_wrap(\n                map_state['status'], start_x, end_x, start_y, end_y)\n            terrain_arr = read_sub_arr_with_wrap(\n                map_state['terrain'], start_x, end_x, start_y, end_y)\n            extras_arr = read_sub_arr_with_wrap(\n                map_state['extras'], start_x, end_x, start_y, end_y)\n            unit_arr = read_sub_arr_with_wrap(\n                map_state['unit'], start_x, end_x, start_y, end_y)\n            unit_owner_arr = read_sub_arr_with_wrap(\n                map_state['unit_owner'], start_x, end_x, start_y, end_y)\n            city_owner_arr = read_sub_arr_with_wrap(\n                map_state['city_owner'], start_x, end_x, start_y, end_y)\n\n            unexplored_tiles_num = len(list(status_arr[status_arr == 0]))\n            if unexplored_tiles_num &gt; 0:\n                status_str = str(unexplored_tiles_num) + \\\n                    ' ' + 'tiles unexplored'\n                mini_map_info[ptile].append(status_str)\n\n            for terrain_id, terrain in enumerate(TERRAIN_NAMES):\n                terrains_num = len(\n                    list(terrain_arr[terrain_arr == terrain_id]))\n                if terrains_num &gt; 0:\n                    terrain_str = str(terrains_num) + ' ' + terrain\n                    mini_map_info[ptile].append(terrain_str)\n\n            for extra_id, extra in enumerate(EXTRA_NAMES):\n                extras_of_id = extras_arr[:, :, extra_id]\n                extras_num = len(list(extras_of_id[extras_of_id != 0]))\n                if extras_num &gt; 0:\n                    extra_str = str(extras_num) + ' ' + extra\n                    mini_map_info[ptile].append(extra_str)\n\n            for unit_id, unit in enumerate(self.controller.rule_ctrl.unit_types_list):\n                units_of_id = unit_arr[:, :, unit_id]\n                units_num = np.sum(units_of_id)\n                if units_num &gt; 0:\n                    unit_str = str(int(units_num)) + ' ' + unit\n                    mini_map_info[ptile].append(unit_str)\n\n            unit_owners = list(unit_owner_arr[unit_owner_arr != 255])\n            if len(unit_owners) != 0:\n                owner_set = []\n                unit_owner_str = 'unit owners are:'\n                for unit_owner in unit_owners:\n                    if unit_owner in owner_set:\n                        continue\n\n                    if unit_owner == self.controller.player_ctrl.my_player_id:\n                        unit_owner_str += ' myself player_' + \\\n                            str(int(unit_owner))\n                    else:\n                        ds_of_owner = self.controller.dipl_ctrl.diplstates[unit_owner]\n                        unit_owner_str += ' ' + \\\n                            DS_TXT[ds_of_owner] + ' player_' + \\\n                            str(int(unit_owner))\n                    owner_set.append(unit_owner)\n                mini_map_info[ptile].append(unit_owner_str)\n\n            city_owners = list(city_owner_arr[city_owner_arr != 255])\n            for city_owner in self.controller.player_ctrl.players:\n                owner_num = city_owners.count(city_owner)\n                if owner_num == 0:\n                    continue\n\n                if city_owner == self.controller.player_ctrl.my_player_id:\n                    city_owner_str = str(\n                        owner_num) + ' cities of myself player_' + str(int(city_owner))\n                else:\n                    ds_of_owner = self.controller.dipl_ctrl.diplstates[city_owner]\n                    city_owner_str = (str(owner_num) + ' cities of a ' + DS_TXT[ds_of_owner] +\n                                      ' player_' + str(int(city_owner)))\n                mini_map_info[ptile].append(city_owner_str)\n\n        tile_id += 1\n    return mini_map_info\n</code></pre>"},{"location":"getting_started/basic_usage.html","title":"Basic Usage","text":""},{"location":"getting_started/basic_usage.html#initializing-an-environment","title":"Initializing an Environment","text":"<p>Initializing a basic/LLM Freeciv environment is simple with the Gymnasium API:</p> Full GameMini-Game <pre><code>import gymnasium\nenv = gymnasium.make('civrealm/FreecivBase-v0')\n</code></pre> <pre><code>import gymnasium\nenv = gymnasium.make('civrealm/FreecivMinitask-v0')\n</code></pre> <p>LLM Environment</p> <p>To make the environment an LLM environment, you can further wrap it with the <code>LLMWrapper</code> class. This applies to both the full game and mini-games as well as their tensor versions. Please refer to the API Reference page for more details about these environments.</p> <pre><code>from civrealm.envs.freeciv_wrapper import LLMWrapper\nenv = LLMWrapper(env)\n</code></pre>"},{"location":"getting_started/basic_usage.html#interacting-with-the-environment","title":"Interacting with the Environment","text":"<p>Interactions can also be implemented in the Gymnasium style:</p> <pre><code>from civrealm.agents import RandomAgent\nagent = RandomAgent()\n\nobservations, info = env.reset()\ndone = False\nstep = 0\nwhile not done:\n    action = agent.act(observations, info)\n    observations, reward, terminated, truncated, info = env.step(action)\n    print(f'Step: {step}, Turn: {info[\"turn\"]}, Reward: {reward}, Terminated: {terminated}, Truncated: {truncated}, action: {action}')\n    step += 1\n    done = terminated or truncated\nenv.close()\n</code></pre> <p>LLM Random Agent</p> <p>You can use <code>RandomLLMAgent</code> to test the LLM environment.</p> <pre><code>from civrealm.agents import RandomLLMAgent\nagent = RandomLLMAgent()\n</code></pre>"},{"location":"getting_started/basic_usage.html#plot-the-game-results","title":"Plot the Game Results","text":"<p>The game results can be plotted with the following code. The figures can be found under the <code>plot_game_scores</code> folder.</p> <pre><code>env.plot_game_scores()\ngame_results = env.get_game_results()\nprint('game results:', game_results)\n</code></pre> <p>Success</p> <p>Now, if we run the script, we should see outputs similar to the command <code>test_civrealm</code>:</p> <pre><code>Reset with port: 6300\nStep: 0, Turn: 1, Reward: 0, Terminated: False, Truncated: False, action: ('unit', 102, 'build_city')\nStep: 1, Turn: 1, Reward: 0, Terminated: False, Truncated: False, action: ('unit', 109, 'goto_6')\nStep: 2, Turn: 1, Reward: 0, Terminated: False, Truncated: False, action: ('unit', 110, 'goto_0')\nStep: 3, Turn: 1, Reward: 0, Terminated: False, Truncated: False, action: ('unit', 111, 'goto_1')\nStep: 4, Turn: 1, Reward: 0, Terminated: False, Truncated: False, action: ('unit', 112, 'goto_5')\n</code></pre> <p>Customize the Environment</p> <p>We provide a set of configurations to customize the environment. For example, you can use the <code>--max_turns</code> argument to specify the maximum number of turns in a game. For more details, please refer to the Game Settings page.</p>"},{"location":"getting_started/basic_usage.html#putting-things-together","title":"Putting Things Together","text":"<p>To combine the above code snippets, we can write a simple script to initialize an (LLM) environment, interact with it using a random (LLM) agent, and plot the game results.</p> With a Base EnviornmentWith an LLM Environment <pre><code>from civrealm.agents import RandomAgent\nimport gymnasium\n\nenv = gymnasium.make('civrealm/FreecivBase-v0')\nagent = RandomAgent()\n\nobservations, info = env.reset()\ndone = False\nstep = 0\nwhile not done:\n    action = agent.act(observations, info)\n    observations, reward, terminated, truncated, info = env.step(\n        action)\n    print(f'Step: {step}, Turn: {info[\"turn\"]}, Reward: {reward}, Terminated: {terminated}, Truncated: {truncated}, action: {action}')\n    step += 1\n    done = terminated or truncated\nenv.close()\n\nenv.plot_game_scores()\ngame_results = env.get_game_results()\nprint('game results:', game_results)\n</code></pre> <pre><code>from civrealm.envs.freeciv_wrapper import LLMWrapper\nfrom civrealm.agents import RandomLLMAgent\nimport gymnasium\n\nenv = gymnasium.make('civrealm/FreecivBase-v0')\nenv = LLMWrapper(env)\nagent = RandomLLMAgent()\n\nobservations, info = env.reset()\ndone = False\nstep = 0\nwhile not done:\n    action = agent.act(observations, info)\n    observations, reward, terminated, truncated, info = env.step(\n        action)\n    print(f'Step: {step}, Turn: {info[\"turn\"]}, Reward: {reward}, Terminated: {terminated}, Truncated: {truncated}, action: {action}')\n    step += 1\n    done = terminated or truncated\nenv.close()\n\nenv.plot_game_scores()\ngame_results = env.get_game_results()\nprint('game results:', game_results)\n</code></pre>"},{"location":"getting_started/first_agent.html","title":"Write Your First Agent","text":""},{"location":"getting_started/first_agent.html#write-a-simple-rule-based-agent","title":"Write a simple rule-based agent","text":"<p>At each step, agent chooses the first valid actor who has done nothing yet in the current turn. If there is not such an actor, agent ends the current turn. Otherwise, if the chosen actor can build a city, agent generates an action \"build a city\" for the actor with probability 0.8; else, agent randomly chooses a valid \"move\" action for the actor.</p> <pre><code>import random\nfrom civrealm.agents.base_agent import BaseAgent\n\nclass RandomAgent(BaseAgent):\n    def __init__(self):\n        super().__init__()\n\n    def random_action_by_name(self, valid_action_dict, name):\n        # Assume input actions are valid, and return a random choice of the actions whose name contains the input name.\n        action_choices = [\n            key for key in valid_action_dict.keys() if name in key]\n        if action_choices:\n            return random.choice(action_choices)\n        else:\n            return None\n\n    def act(self, observations, info):\n        unit_actor, unit_action_dict = self.get_next_valid_actor(\n            observations, info, 'unit')\n        fc_logger.info(f'Valid actions: {unit_action_dict}')\n        if not unit_actor:\n            return None\n\n        # Try to build a city\n        build_action = self.random_action_by_name(unit_action_dict, 'build')\n        if build_action and random.random() &gt; 0.2:\n            return 'unit', unit_actor, build_action\n\n        # Try to move\n        return 'unit', unit_actor, self.random_action_by_name(unit_action_dict, 'goto')\n</code></pre> <p>Base Environment</p> <p>You should use \"Base Environment\" to test \"RandomAgent\"</p> <pre><code>import gymnasium\nenv = gymnasium.make('civrealm/FreecivBase-v0')\n</code></pre> <p>Run \"RandomAgent\" in CivRealm:</p> <pre><code>import gymnasium\nfrom civrealm.agents import RandomAgent\nfrom civrealm.configs import fc_args\n\n\ndef main():\n    env = gymnasium.make('civrealm/FreecivBase-v0')\n    agent = RandomAgent()\n\n    observations, info = env.reset(client_port=fc_args['client_port'])\n    done = False\n    step = 0\n    while not done:\n        try:\n            action = agent.act(observations, info)\n            observations, reward, terminated, truncated, info = env.step(\n                action)\n            print(\n                f'Step: {step}, Turn: {info[\"turn\"]}, Reward: {reward}, Terminated: {terminated}, '\n                f'Truncated: {truncated}, action: {action}')\n            step += 1\n            done = terminated or truncated\n        except Exception as e:\n            fc_logger.error(repr(e))\n            raise e\n    env.close()\n\n\nif __name__ == '__main__':\n    main()\n</code></pre> <p>Success</p> <p>Now, if we run the script, we should see outputs:</p> <pre><code>Step: 0, Turn: 1, Reward: 0, Terminated: False, Truncated: False, action: ('unit', 101, 'build_road')\nStep: 1, Turn: 1, Reward: 0, Terminated: False, Truncated: False, action: ('unit', 105, 'goto_2')\nStep: 2, Turn: 1, Reward: 0, Terminated: False, Truncated: False, action: ('unit', 106, 'build_road')\nStep: 3, Turn: 1, Reward: 0, Terminated: False, Truncated: False, action: ('unit', 107, 'build_road')\nStep: 4, Turn: 1, Reward: 0, Terminated: False, Truncated: False, action: ('unit', 108, 'goto_5')\nStep: 5, Turn: 2, Reward: 0, Terminated: False, Truncated: False, action: None\nStep: 6, Turn: 2, Reward: 0, Terminated: False, Truncated: False, action: ('unit', 101, 'build_city')\n</code></pre>"},{"location":"getting_started/first_agent.html#write-a-random-llm-agent","title":"Write a random LLM agent","text":"<p>At each step, agent chooses the first valid actor who has done nothing yet in the current turn. If there is not such an actor, agent ends the current turn. Otherwise, agent randomly chooses a valid action for the actor.</p> <pre><code>import random\nfrom civrealm.agents.base_agent import BaseAgent\n\nclass RandomLLMAgent(BaseAgent):\n    def __init__(self):\n        super().__init__()\n        if fc_args[\"debug.randomly_generate_seeds\"]:\n            agentseed = os.getpid()\n            self.set_agent_seed(agentseed)\n        else:\n            if \"debug.agentseed\" in fc_args:\n                self.set_agent_seed(fc_args[\"debug.agentseed\"])\n\n    def act(self, observation, info):\n        if info['turn'] != self.turn:\n            self.planned_actor_ids = []\n            self.turn = info['turn']\n\n        for ctrl_type, actors_dict in info['llm_info'].items():\n            for actor_id in actors_dict.keys():\n                if actor_id in self.planned_actor_ids:\n                    continue\n                available_actions = actors_dict[actor_id]['available_actions']\n                if available_actions:\n                    action_name = random.choice(available_actions)\n                    self.planned_actor_ids.append(actor_id)\n                    return (ctrl_type, actor_id, action_name)\n</code></pre> <p>LLM Environment</p> <p>You should Use \"LLM Environment\" to test \"RandomLLMAgent\"  </p> <pre><code>import gymnasium\nfrom civrealm.envs.freeciv_wrapper import LLMWrapper\nenv = gymnasium.make('civrealm/FreecivBase-v0')\nenv = LLMWrapper(env)\n</code></pre> <p>Run \"RandomLLMAgent\" in CivRealm:</p> <pre><code>import gymnasium\nfrom civrealm.envs.freeciv_wrapper import LLMWrapper\nfrom civrealm.agents import RandomLLMAgent\nfrom civrealm.configs import fc_args\n\n\ndef main():\n    env = gymnasium.make('civrealm/FreecivBase-v0')\n    env = LLMWrapper(env)\n    agent = RandomLLMAgent()\n\n    observations, info = env.reset(client_port=fc_args['client_port'])\n    done = False\n    step = 0\n    while not done:\n        try:\n            action = agent.act(observations, info)\n            observations, reward, terminated, truncated, info = env.step(\n                action)\n            print(\n                f'Step: {step}, Turn: {info[\"turn\"]}, Reward: {reward}, Terminated: {terminated}, '\n                f'Truncated: {truncated}, action: {action}')\n            step += 1\n            done = terminated or truncated\n        except Exception as e:\n            fc_logger.error(repr(e))\n            raise e\n    env.close()\n\n\nif __name__ == '__main__':\n    main()\n</code></pre> <p>Success</p> <p>Now, if we run the script, we should see outputs:</p> <pre><code>Step: 0, Turn: 1, Reward: 0, Terminated: False, Truncated: False, action: ('unit', 103, 'move East')\nStep: 1, Turn: 1, Reward: 0, Terminated: False, Truncated: False, action: ('unit', 113, 'move West')\nStep: 2, Turn: 1, Reward: 0, Terminated: False, Truncated: False, action: ('unit', 114, 'move North')\nStep: 3, Turn: 1, Reward: 0, Terminated: False, Truncated: False, action: ('unit', 115, 'move North')\nStep: 4, Turn: 1, Reward: 0, Terminated: False, Truncated: False, action: ('unit', 116, 'move NorthEast')\nStep: 5, Turn: 2, Reward: 0, Terminated: False, Truncated: False, action: None\nStep: 6, Turn: 2, Reward: 0, Terminated: False, Truncated: False, action: ('unit', 103, 'move South')\n</code></pre>"},{"location":"getting_started/installation.html","title":"Installation","text":""},{"location":"getting_started/installation.html#python-version","title":"Python Version","text":"<p>Civrealm requires Python version <code>&gt;=3.8</code> and tested until <code>3.11</code>.</p> <p>Python Environment</p> <p>We suggest using Anaconda to create a clean virtual environment for installation.</p>"},{"location":"getting_started/installation.html#virtual-environment","title":"Virtual Environment","text":"<p>If you are using Anaconda, you can create a new environment <code>civrealm</code> with Python 3.8 by running the following command:</p> <pre><code>conda create -n civrealm python=3.8\nconda activate civrealm\n</code></pre>"},{"location":"getting_started/installation.html#installation_1","title":"Installation","text":"<p>You can install the CivRealm stable version by:</p> <pre><code>pip install civrealm\n</code></pre> <p>For CivRealm developers, clone the CivRealm repository from GitHub and enter the directory. Then install through pip with the source code in the CivRealm folder:</p> <pre><code>cd civrealm\npip install -e .\n</code></pre>"},{"location":"getting_started/installation.html#test-the-installation","title":"Test the Installation","text":"<p>Before testing the installation, please make sure that the freeciv-web service is running. You can check the status of the freeciv-web service by running:</p> <pre><code>docker ps\n</code></pre> <p>You should see a docker container named <code>freeciv-web</code> running.</p>"},{"location":"getting_started/installation.html#single-player-mode-against-built-in-ais","title":"Single-Player Mode (Against Built-in AIs)","text":"<p>To test the installation, run the following command after installation. It starts a game with one customized player game against built-in AIs with the default settings.</p> <pre><code>test_civrealm\n</code></pre> <p>Success</p> <p>If the installation is successful, the output should be similar to the following:</p> <pre><code>Reset with port: 6300\nStep: 0, Turn: 1, Reward: 0, Terminated: False, Truncated: False, action: ('unit', 104, 'move NorthEast')\nStep: 1, Turn: 1, Reward: 0, Terminated: False, Truncated: False, action: ('unit', 117, 'move North')\nStep: 2, Turn: 1, Reward: 0, Terminated: False, Truncated: False, action: ('unit', 118, 'move North')\nStep: 3, Turn: 1, Reward: 0, Terminated: False, Truncated: False, action: ('unit', 119, 'move SouthEast')\nStep: 4, Turn: 1, Reward: 0, Terminated: False, Truncated: False, action: ('unit', 120, 'move SouthEast')\n</code></pre>"},{"location":"getting_started/installation.html#multi-player-mode","title":"Multi-Player Mode","text":"<p>To test with multiple players, run the following command in one terminal to start the game with player <code>myagent</code>:</p> <pre><code>test_civrealm --minp=2 --username=myagent --client_port=6001\n</code></pre> <p>Then start another terminal and join the game with player <code>myagent1</code>:</p> <pre><code>test_civrealm --username=myagent1 --client_port=6001\n</code></pre> <p>Connect to the same port</p> <p>Note that to run multiple agents in the same game, you need to make them connect to the same port (specified by client_port). The available client_port range is 6001, 6300~6331.</p> <p> 10 seconds delay to reuse a port</p> <p>Note that when a game finishes on a port, the server on that port will take some time (around 10 seconds) to restart itself. If you start a new game on that port before the server is ready, the program will encounter unexpected errors and may stop/halt.</p>"},{"location":"getting_started/requirements.html","title":"Requirements","text":""},{"location":"getting_started/requirements.html#operating-system","title":"Operating System","text":"<p>Civrealm works with the following operating systems:</p> <ul> <li> <p>Windows &gt;= <code>10</code></p> </li> <li> <p>Ubuntu &gt;= <code>20.0</code></p> </li> <li> <p>macOS X</p> </li> </ul>"},{"location":"getting_started/requirements.html#docker-version","title":"Docker Version","text":"<p>CivRealm provides an interface for programmatic control of the Freeciv-web game. To run CivRealm locally, you need to start our customized Freeciv-web server using docker, which requires docker version &gt;= <code>24.0.6</code>.</p> <p>Check docker version by</p> <pre><code>docker -v\n</code></pre> <p>Install Docker</p> <p>We suggest following the Docker Docs to install the latest version of docker.</p>"},{"location":"getting_started/requirements.html#running-freeciv-web-with-docker","title":"Running Freeciv-web with Docker","text":"<p>Do not use the original Freeciv-web</p> <p>Please do NOT use the image built based on the original Freeciv-web repo. The image has been customize to suit agent training functionalities. The latest commits in that repo might cause compatibility issues.</p> <p>There are 4 ways to download/build the customized Freeciv web image: 1. use CivRealm's built-in commands (recommended), 2. pull from the docker hub, 3. download and load our pre-built docker image, or 4. compile the docker image from source.</p> <p>Freeciv-Web Service</p> <p>After starting the Freeciv-web service, you can connect to the Freeciv-web server via the host machine localhost:8080 using a standard browser.</p>"},{"location":"getting_started/requirements.html#method-1-using-civrealms-built-in-commands-recommended","title":"Method 1: Using CivRealm's built-in commands (Recommended)","text":"<ol> <li> <p>Stop the existing freeciv-web service as follows. You can skip this step if you have not started the freeciv-web service before.</p> <pre><code>stop_freeciv_web_service\n</code></pre> <p>Stop Container</p> <p>This command keeps the image and only removes the container.</p> </li> <li> <p>Download the latest freeciv-web image by the following command. You can skip this step if you have already downloaded the latest image.</p> <pre><code>download_freeciv_web_image\n</code></pre> </li> <li> <p>Start the freeciv-web service by running:</p> <pre><code>start_freeciv_web_service\n</code></pre> </li> </ol> <p>We also provide a command <code>build_freeciv_web_service</code> that combines the above three commands for convenience. It automatically remove the existing freeciv-web service, fetch the latest freeciv-web image, and start the freeciv-web service.</p>"},{"location":"getting_started/requirements.html#method-2-pull-from-the-docker-hub","title":"Method 2: Pull from the Docker Hub","text":"<p>You can pull our pre-built docker image from the docker hub. Assume the image version is named `VERSION'.</p> <ol> <li> <p>Pull the docker image to your local machine:</p> <pre><code>docker pull civrealm/freeciv-web:VERSION\n</code></pre> </li> <li> <p>Tag the docker image:</p> <pre><code>docker tag civrealm/freeciv-web:VERSION freeciv/freeciv-web:VERSION\n</code></pre> </li> <li> <p>Run the following command to clone the civrealm repo and build the freeciv-web service from Docker:</p> <pre><code>git clone git@github.com:bigai-ai/civrealm.git civrealm\ncd civrealm/src/civrealm/configs\ndocker compose up -d freeciv-web\n</code></pre> </li> </ol> <p>Docker permission</p> <p>If the docker command complains about the sudo permission, please follow the instruction here.</p> <p>command not found: docker compose</p> <p>If the <code>docker compose</code> command is not found, please make sure that you have installed the docker version &gt;= <code>24.0.6</code>.</p>"},{"location":"getting_started/requirements.html#method-3-download-and-load-the-docker-image","title":"Method 3: Download and Load the Docker Image","text":"<p>You can use our pre-built docker image file to directly start the Freeciv-web server, the steps are as follows:</p> <ol> <li> <p>Download our customized docker image from here. Suppose the downloaded image file is named as <code>IMAGE_FILE_NAME</code>.</p> </li> <li> <p>Run the following command to load the downloaded docker image from the image file directory:</p> </li> </ol> <pre><code>docker load -i IMAGE_FILE_NAME\n</code></pre> <ol> <li>Follow the step 3 of Method 2 to start the docker service.</li> </ol>"},{"location":"getting_started/requirements.html#method-4-compile-the-docker-image-from-source-code","title":"Method 4: Compile the Docker Image from Source Code","text":"<p>You can also compile the source code to build the service follwing the instruction of Freeciv-web Repo from here. It has relatively large network overhead when building services, and could take a long time (up to 3 hours) to complete.</p>"},{"location":"getting_started/trouble_shooting.html","title":"Trouble Shooting","text":"<p>The following are some common issues that you may encounter when running the code. If you encounter any other issues, please feel free to open an issue.</p> <ul> <li> <p>Note that each game corresponds to one port on the server. If one game just stops and you immediately start a new game connecting to the same port as the stopped game, the new game may encounter errors and exit. Our training has used ''Ports.get()'' in ''civrealm/freeciv/utils/port_utils.py'' to avoid the situation. If you want to configure the client port and start a client manually, you need to find the available ports by checking the 'Online Games/MULTIPLAYER' tab in localhost:8080.</p> </li> <li> <p>If firefox keeps loading the page, please try to add the following line to <code>/etc/hosts</code>:</p> <pre><code>127.0.0.1 maxcdn.bootstrapcdn.com\n127.0.0.1 cdn.webglstats.com\n</code></pre> </li> </ul>"},{"location":"getting_started/visualization.html","title":"Visualization","text":"<p>Disclaimer</p> <p>The screenshots displayed on this website result from running the Freeciv game, and they may contain names of nations, players, leaders, or territories that could be politically sensitive. It is important to note that these names are purely hypothetical and are part of the game's design.</p>"},{"location":"getting_started/visualization.html#access-the-game","title":"Access The Game","text":"<p>To observe the game play, you can access the game through http://localhost:8080/ on a browser. Then, please click the \"Online Games\" button. You can find the running game under the \"MULTIPLAYER\" tab as shown below. Or alternatively, you can directly go to this page by clicking http://localhost:8080/game/list?v=multiplayer.</p>"},{"location":"getting_started/visualization.html#observe-the-game-play","title":"Observe the Game Play","text":"<ol> <li> <p>In the following page, you can click the \"info\" button pointed by the arrow and go to the information page.     </p> </li> <li> <p>In the information page, you can see the name of all players currently playing in the game. Then, you can click the \"Join/Observe\" button pointed by the arrow to join the game as an observer.     </p> </li> <li> <p>In the below, we use \"testcontroller\" as the username and click the \"Join Game\" button to join. Note that you may use another username to log in as long as the username is different from the player names that are already used in the game. The password is \"civrealm\" for all accounts by default.     </p> </li> <li> <p>Since the game has started before you join, you will see a black screen after you join. To observe the game play, you need to send the \"observe\" command through the console of the explorer. Taking Firefox explorer as an example, you may press \"ctrl+shift+I\" to start the console. Then, in the console, you can type \"send_message(\"/observe\")\" to send the command as pointed by the arrow in the above figure.     </p> <p>Tip</p> <p>You can start the game after the observer joins. Please see the next section for more details.</p> </li> <li> <p>You will be able to observe the game from a global view, i.e., you can see the game play of all players, as shown below.     </p> </li> <li> <p>To observe the game play of a certain player, you may type \"send_message(\"/observe PLAYER_NAME\")\" in the console. In the below, we observe the game play of the player whose player name is \"myagent\". The command we type is \"send_message('/observe myagent')\".     </p> </li> </ol>"},{"location":"getting_started/visualization.html#observe-the-game-play-before-the-game-starts","title":"Observe the Game Play Before the Game Starts","text":"<p>To prevent the game from starting before the observer joins, you can use the \"wait_for_observer\" configuration to force the game to wait.</p> <pre><code>test_civrealm --wait_for_observer=True\n</code></pre> <ol> <li> <p>Then, under the \"MULTIPLAYER\" tab, you will see the game status is \"Pregame\". In comparison, the game status will be \"Running\" if the game has started. Similarly, you can click the \"Info\" button to see the information page.     </p> </li> <li> <p>You may click the \"Join\" button to join as an observer by using the \"testcontroller\" account as before. Note that because the game is waiting, you will see the following pregame page instead of a black screen.     </p> </li> <li> <p>In the following page, you may send the \"observe\" command in the chatbox instead of the console. As pointed by the arrow, we type \"/observe myagent\" in the chatbox. After we press \"Enter\" to send the command, the game will start and we can observe the game play of \"myagent\".     </p> </li> <li> <p>Note that you may also send the \"observe\" command in the chatbox during the game play. As pointed by the arrow in the following page, we type \"/observe\" in the chatbox.      </p> </li> <li> <p>After we send the command, the observation becomes the global view.     </p> </li> <li> <p>Similarly, if we type \"/observe PLAYER_NAME\" in the chatbox, we will see the individual player's view. Note that there could be empty spaces inside a player name as shown in the below.          In the above case, to observe its game play, you have to send the \"observe\" command through the console of explorer. Moreover, you need to decorate the empty spaces inside the player name with ' ' as shown below. Otherwise, the server cannot read the player name correctly. Following this format, the command we type in the console is \"send_message(\"/observe Philippe' 'le' 'Bon\")\".     </p> <p>As shown below, by sending the \"observe\" command, we are able to observe the game play of AI player \"Philippe le Bon\". </p> </li> </ol>"},{"location":"misc/faq.html","title":"FAQ","text":""},{"location":"misc/faq.html#image-questions","title":"Image Questions","text":"\ud83e\udd14 1. When using the latest code from the official Freeciv-web GitHub repository to generate an image and executing the civrealm code, some unknown exceptions raise, how to solve this problem? <p>To enhance the functionality of the game, such as compatibility for loading saved files and adding script control during gameplay, we have undertaken development and optimization of freeciv-web. We\u2019ve forked a new branch to maximize compatibility with civrealm development. Using the official freeciv-web image from the website without compatibility testing may lead to unexpected errors. To improve your user experience, please utilize our branch\u2019s code to generate the image. Here\u2019s how: Open the releases page and select the appropriate freeciv-web tag based on the civrealm version.</p>"},{"location":"misc/resources.html","title":"Resources","text":"<ul> <li>The official website for Freeciv, an open-source empire-building strategy game inspired by the history of human civilization, can be found at Freeciv.org.</li> <li>If you are new to freeciv, Freeciv Fandom is a nice tutorial to start with.</li> <li>If you are new to pytorch, pytorch tutorial is a official tutorial to start with.</li> </ul>"},{"location":"notes/contribute.html","title":"Contribute to CivRealm","text":""},{"location":"notes/contribute.html#development-process","title":"Development Process","text":"<ul> <li>For bugfix, we recommend that you raise them in the issue section, and have them discussed and verified by the developers.</li> </ul>"},{"location":"notes/contribute.html#coding-styles","title":"Coding Styles","text":"<p>We follow the PEP8 style guide for python code development. The python comments follow NumPy style python docstrings.</p>"},{"location":"releases/releases.html","title":"Releases","text":"CivRealm Version Freeciv-web Version Mini-Game Dataset 1.0 tag 1.3: File minigame.zip branch: dev tag 1.4: Docker Hub Built in image"},{"location":"releases/releases.html#version-update-announcement","title":"Version update announcement","text":""},{"location":"releases/releases.html#freeciv-web-v14","title":"Freeciv-web V1.4","text":"Function Description Document AI-assistant access Accessing the AI-assistant entails leveraging the rule-based AI interface embedded within the server to offer users strategic guidance on subsequent actions. Significant enhancements include: (1) The introduction of a new packet and process identifier (PID) to facilitate AI assistant action requests and responses;(2) The incorporation of assistant fields within the unit structure to track planning status;  Usage in mini-game"}]}